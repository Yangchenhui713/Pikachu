{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e2281b",
   "metadata": {},
   "source": [
    "# **使用 LangGraph 和 Qwen 模型实现上下文工程四大策略**\n",
    "\n",
    "### **目标**\n",
    "本 Notebook 将作为一份详细的技术指南，演示如何使用 LangGraph 框架和通义千问（Qwen）模型，一步步实现“上下文工程”的四大核心策略。\n",
    "\n",
    "四大策略包括：\n",
    "1.  **写入 (Write):** 为智能体构建一个“外部大脑”（暂存区），以在长任务中保持状态。\n",
    "2.  **选择 (Select):** 使用检索增强生成（RAG）从知识库中精准调取信息。\n",
    "3.  **压缩 (Compress):** 智能地总结对话历史，以节省成本和Token。\n",
    "4.  **隔离 (Isolate):** 使用多智能体（Multi-agent）架构，将复杂任务分解给专家处理。\n",
    "\n",
    "---\n",
    "### **第一步：环境设置与模型初始化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6ddefae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.cloud.aliyuncs.com/pypi/simple/\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-qwq in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.5.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
      "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.27)\n",
      "Requirement already satisfied: dashscope in /usr/local/lib/python3.10/dist-packages (1.23.8)\n",
      "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.11.0.post1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.69)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.4.6)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.70.0 in /usr/local/lib/python3.10/dist-packages (from langchain-qwq) (1.97.0)\n",
      "Requirement already satisfied: json-repair<0.41.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from langchain-qwq) (0.40.0)\n",
      "Requirement already satisfied: langchain-openai<0.4.0,>=0.3.11 in /usr/local/lib/python3.10/dist-packages (from langchain-qwq) (0.3.28)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph) (2.1.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.5.2)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.1.73)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.12.14)\n",
      "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from dashscope) (1.8.0)\n",
      "Requirement already satisfied: cryptography in /usr/lib/python3/dist-packages (from dashscope) (3.4.8)\n",
      "Requirement already satisfied: packaging in /root/.local/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (21.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /root/.local/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai<0.4.0,>=0.3.11->langchain-qwq) (0.9.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.70.0->langchain-qwq) (4.67.1)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.70.0->langchain-qwq) (1.3.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.70.0->langchain-qwq) (0.10.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.70.0->langchain-qwq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.70.0->langchain-qwq) (1.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (1.26.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.70.0->langchain-qwq) (1.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/lib/python3/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (2.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai<0.4.0,>=0.3.11->langchain-qwq) (2024.11.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install langchain langchain-qwq langgraph pandas python-dotenv langchain_community dashscope faiss-cpu pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0417ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import json\n",
    "import operator\n",
    "from typing import List, TypedDict, Annotated\n",
    "\n",
    "import tiktoken\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, ToolMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_qwq import ChatQwen\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1547b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 设置API密钥 ---\n",
    "# 请注意：这里需要的是 DashScope 的 API Key\n",
    "if \"DASHSCOPE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"DASHSCOPE_API_KEY\"] = getpass.getpass(\"请输入您的DashScope API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ef5d7428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen 模型初始化成功！\n"
     ]
    }
   ],
   "source": [
    "# --- 2. 初始化Qwen模型 ---\n",
    "# 我们将使用 qwen3-32b 模型作为我们智能体的“大脑”\n",
    "try:\n",
    "    model = ChatQwen(model=\"qwen3-32b\", base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",  enable_thinking=False)\n",
    "    print(\"Qwen 模型初始化成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"模型初始化失败，请检查API Key或网络连接: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bc73c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 初始化Token计算器 ---\n",
    "# 这将帮助我们量化“压缩”策略带来的效果\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a80f1e5",
   "metadata": {},
   "source": [
    "## **策略一：写入 (Write) - 构建智能体的“草稿纸”**\n",
    "\n",
    "**核心思想:** 不把所有中间步骤和思考都塞进主对话历史（`messages`），而是将它们“写入”到一个独立的“暂存区”（`scratchpad`）。这可以保持主对话的清晰，并为智能体提供一个可靠的短期记忆，防止在长任务中“失忆”。\n",
    "\n",
    "**实现:** 我们将在`AgentState`中增加一个`scratchpad`字段，并通过添加`SystemMessage`来指导模型的行为，防止无限循环。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "63a46ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 定义状态 ---\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List, Annotated\n",
    "import operator\n",
    "\n",
    "class ToolCallRecord(TypedDict):\n",
    "    step: int\n",
    "    tool_name: str\n",
    "    args: dict\n",
    "    result: str\n",
    "\n",
    "class WriteStrategyState(TypedDict):\n",
    "    messages: Annotated[list, operator.add]\n",
    "    # 结构化 scratchpad，保留完整历史\n",
    "    scratchpad: dict  # {\"history\": List[ToolCallRecord], \"final_answer\": str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "436e02ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. 定义工具 ---\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def simple_calculator(operation: str, a: int, b: int) -> int:\n",
    "    \"\"\"一个简单的计算器工具，执行加减乘除。\"\"\"\n",
    "    if operation == \"add\":\n",
    "        return a + b\n",
    "    if operation == \"subtract\":\n",
    "        return a - b\n",
    "    if operation == \"multiply\":\n",
    "        return a * b\n",
    "    if operation == \"divide\" and b != 0:\n",
    "        return a // b\n",
    "    return \"无效操作\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a7d01195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 定义图的节点 ---\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import END\n",
    "\n",
    "tools = [simple_calculator]\n",
    "tool_node = ToolNode(tools)\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "def agent_with_scratchpad(state: WriteStrategyState):\n",
    "    \"\"\"\n",
    "    Agent 节点：决定下一步动作，并更新暂存区。\n",
    "    \"\"\"\n",
    "    print(\"---AGENT NODE---\")\n",
    "    response = model_with_tools.invoke(state['messages'])\n",
    "\n",
    "    if response.tool_calls:\n",
    "        # 暂存当前待执行的工具\n",
    "        state['scratchpad']['pending_tool'] = response.tool_calls[0]\n",
    "        print(f\"🧠 Agent Action: Call tool `{response.tool_calls[0]['name']}` \"\n",
    "              f\"with arguments `{response.tool_calls[0]['args']}`\")\n",
    "    else:\n",
    "        # 全部完成，保存最终答案\n",
    "        state['scratchpad']['final_answer'] = response.content\n",
    "        print(f\"✅ Final Answer: {response.content}\")\n",
    "\n",
    "    return {\"messages\": [response], \"scratchpad\": state['scratchpad']}\n",
    "\n",
    "def tool_node_with_scratchpad(state: WriteStrategyState):\n",
    "    \"\"\"\n",
    "    Tool 节点：执行工具，并把结果记录到 history。\n",
    "    \"\"\"\n",
    "    print(\"---TOOL NODE---\")\n",
    "    last_message = state['messages'][-1]\n",
    "    tool_messages = tool_node.invoke([last_message])\n",
    "\n",
    "    # 取出待处理的工具调用\n",
    "    pending = state['scratchpad']['pending_tool']\n",
    "    record = ToolCallRecord(\n",
    "        step=len(state['scratchpad'].get(\"history\", [])) + 1,\n",
    "        tool_name=pending['name'],\n",
    "        args=pending['args'],\n",
    "        result=str(tool_messages[0].content)\n",
    "    )\n",
    "    # 追加到历史\n",
    "    state['scratchpad'].setdefault(\"history\", []).append(record)\n",
    "    print(f\"📝 Recorded Tool Call: {record}\")\n",
    "    state['scratchpad'].pop(\"pending_tool\", None)  # 清理\n",
    "\n",
    "    #print(f\"🛠️ Tool Result: `{record['result']}`\")\n",
    "    return {\"messages\": tool_messages, \"scratchpad\": state['scratchpad']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4be3a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. 构建图 ---\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "write_graph_builder = StateGraph(WriteStrategyState)\n",
    "write_graph_builder.add_node(\"agent\", agent_with_scratchpad)\n",
    "write_graph_builder.add_node(\"action\", tool_node_with_scratchpad)\n",
    "write_graph_builder.set_entry_point(\"agent\")\n",
    "\n",
    "# 条件边：检查是否还有未完成的工具\n",
    "def should_continue(state: WriteStrategyState) -> str:\n",
    "    # 若最终答案已存在，直接结束\n",
    "    if state['scratchpad'].get(\"final_answer\"):\n",
    "        return END\n",
    "    return \"action\"\n",
    "\n",
    "write_graph_builder.add_conditional_edges(\"agent\", should_continue, {\"action\": \"action\", END: END})\n",
    "write_graph_builder.add_edge(\"action\", \"agent\")\n",
    "write_graph = write_graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3aa372ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 演示“写入”策略 ###\n",
      "---AGENT NODE---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Agent Action: Call tool `simple_calculator` with arguments `{'a': 128, 'b': 72, 'operation': 'add'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "📝 Recorded Tool Call: {'step': 1, 'tool_name': 'simple_calculator', 'args': {'a': 128, 'b': 72, 'operation': 'add'}, 'result': '200'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "🧠 Agent Action: Call tool `simple_calculator` with arguments `{'a': 200, 'b': 3, 'operation': 'multiply'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "📝 Recorded Tool Call: {'step': 2, 'tool_name': 'simple_calculator', 'args': {'a': 200, 'b': 3, 'operation': 'multiply'}, 'result': '600'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "🧠 Agent Action: Call tool `simple_calculator` with arguments `{'a': 600, 'b': 100, 'operation': 'divide'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "📝 Recorded Tool Call: {'step': 3, 'tool_name': 'simple_calculator', 'args': {'a': 600, 'b': 100, 'operation': 'divide'}, 'result': '6'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "🧠 Agent Action: Call tool `simple_calculator` with arguments `{'a': 6, 'b': 20, 'operation': 'multiply'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "📝 Recorded Tool Call: {'step': 4, 'tool_name': 'simple_calculator', 'args': {'a': 6, 'b': 20, 'operation': 'multiply'}, 'result': '120'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "🧠 Agent Action: Call tool `simple_calculator` with arguments `{'a': 120, 'b': 222, 'operation': 'subtract'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "📝 Recorded Tool Call: {'step': 5, 'tool_name': 'simple_calculator', 'args': {'a': 120, 'b': 222, 'operation': 'subtract'}, 'result': '-102'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "✅ Final Answer: 5) 最终从风险敞口中一次性扣除 222 元固定准备金后的结果是 -102 元。\n",
      "\n",
      "最终结果：-102\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# --- 5. 演示 ---\n",
    "print(\"### 演示“写入”策略 ###\")\n",
    "task = (\n",
    "    \"1) 初始现金流 128 元与预算追加 72 元先进行合并；\\n\"\n",
    "    \"2) 合并后的资金按季度复利 3 倍杠杆放大；\\n\"\n",
    "    \"3) 放大后的资金因汇率折算需除以 100 得到基准单位值；\\n\"\n",
    "    \"4) 基准单位值再按 20 倍风险系数放大，形成风险敞口；\\n\"\n",
    "    \"5) 最终从风险敞口中一次性扣除 222 元的固定准备金。\\n\"\n",
    "    \"请列出每一步的数值结果，并以『最终结果：{数值}』的格式给出答案。\"\n",
    ")\n",
    "\n",
    "system_prompt = (\n",
    "    \"你是一个计算助手。请按步骤使用 `simple_calculator` 工具来回答用户的问题。 \"\n",
    ")\n",
    "initial_messages = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(content=task)\n",
    "]\n",
    "initial_state = {\"messages\": initial_messages, \"scratchpad\": {\"history\": [], \"final_answer\": None}}\n",
    "\n",
    "# 使用 .stream() 观察每一步\n",
    "for step in write_graph.stream(initial_state, {\"recursion_limit\": 20}):\n",
    "    #print(step)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e126c53",
   "metadata": {},
   "source": [
    "## **策略二：选择 (Select) - 精准的\"信息调取\"**\n",
    "\n",
    "**核心思想：** 使用RAG（检索增强生成）技术，从外部知识库中精准检索最相关的信息片段，只将必要信息注入上下文。\n",
    "\n",
    "**实现步骤：**\n",
    "1. 创建产品知识库（模拟向量数据库）\n",
    "2. 构建RAG检索器\n",
    "3. 设计智能体流程：问题 → 检索 → 生成答案\n",
    "4. 可视化Token节省效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8d67324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 创建模拟产品知识库 ---\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "\n",
    "# 创建嵌入模型\n",
    "embeddings = DashScopeEmbeddings(model=\"text-embedding-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "29f0b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 产品知识文档（实际应用中会从数据库加载）\n",
    "product_docs = [\n",
    "    Document(page_content=\"\"\"机械键盘 X1 Pro 技术规格：\n",
    "- 轴体：定制青轴，60g触发压力\n",
    "- 连接：三模（蓝牙5.1/2.4G/USB-C）\n",
    "- 电池：4000mAh，续航200小时\n",
    "- 特点：热插拔轴体，PBT双色键帽，全键无冲\n",
    "- 价格：699元（限时优惠599元）\"\"\", \n",
    "             metadata={\"product\": \"机械键盘 X1 Pro\", \"category\": \"键盘\"}),\n",
    "    \n",
    "    Document(page_content=\"\"\"游戏鼠标 M800 旗舰版：\n",
    "- 传感器：原相PAW3395，26000DPI\n",
    "- 微动：欧姆龙光学微动，1亿次寿命\n",
    "- 重量：58g（超轻量化设计）\n",
    "- RGB：1680万色，10区域独立控光\n",
    "- 价格：399元（套装优惠价）\"\"\", \n",
    "             metadata={\"product\": \"游戏鼠标 M800\", \"category\": \"鼠标\"}),\n",
    "    \n",
    "    Document(page_content=\"\"\"促销邮件写作指南：\n",
    "1. 标题要吸引眼球，包含优惠信息\n",
    "2. 开头用痛点场景引发共鸣\n",
    "3. 突出产品核心优势（性能>参数）\n",
    "4. 限时优惠制造紧迫感\n",
    "5. 清晰的行动召唤按钮\"\"\", \n",
    "             metadata={\"doc_type\": \"writing_guide\"}),\n",
    "    \n",
    "    Document(page_content=\"\"\"用户偏好分析：\n",
    "科技产品消费者最关注：\n",
    "- 性能参数（75%用户）\n",
    "- 性价比（68%用户）\n",
    "- 耐用性（52%用户）\n",
    "- 外观设计（48%用户）\"\"\", \n",
    "             metadata={\"doc_type\": \"user_insight\"}),\n",
    "]\n",
    "\n",
    "# 创建向量数据库\n",
    "vector_db = FAISS.from_documents(product_docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "259408e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. 构建RAG检索器 ---\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 创建检索器\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"格式化检索到的文档\"\"\"\n",
    "    return \"\\n\\n\".join(f\"## 来源 {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(docs))\n",
    "\n",
    "# 创建RAG提示模板\n",
    "rag_template = \"\"\"\n",
    "你是一位专业的产品文案助手。请根据提供的背景信息回答用户问题。\n",
    "\n",
    "<背景信息>\n",
    "{context}\n",
    "</背景信息>\n",
    "\n",
    "用户问题：{question}\n",
    "\n",
    "请用专业、简洁的语言回答，突出产品核心优势：\n",
    "\"\"\"\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_template)\n",
    "\n",
    "# 创建RAG链\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | RunnableLambda(format_docs), \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b04e7dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 设计智能体流程 ---\n",
    "class SelectStrategyState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    context: str  # 存储检索到的上下文\n",
    "\n",
    "def retrieve_context(state: SelectStrategyState):\n",
    "    \"\"\"检索节点：从知识库获取相关信息\"\"\"\n",
    "    print(\"\\n--- RETRIEVE CONTEXT ---\")\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    \n",
    "    # 执行检索\n",
    "    docs = retriever.invoke(last_message)\n",
    "    context = format_docs(docs)\n",
    "    \n",
    "    # 计算Token节省\n",
    "    orig_token_count = sum(len(encoding.encode(doc.page_content)) for doc in docs)\n",
    "    context_token_count = len(encoding.encode(context))\n",
    "    savings = orig_token_count - context_token_count\n",
    "    \n",
    "    print(f\"🔍 检索到 {len(docs)} 条相关文档\")\n",
    "    print(f\"📉 Token节省: {savings} (原始: {orig_token_count} -> 压缩: {context_token_count})\")\n",
    "    print(f\"📝 注入上下文:\\n{context[:300]}...\")\n",
    "    \n",
    "    return {\"context\": context}\n",
    "\n",
    "def generate_with_context(state: SelectStrategyState):\n",
    "    \"\"\"生成节点：使用检索到的上下文生成回答\"\"\"\n",
    "    print(\"\\n--- GENERATE WITH CONTEXT ---\")\n",
    "    question = state[\"messages\"][-1].content\n",
    "    \n",
    "    # 使用RAG链生成回答\n",
    "    response = rag_chain.invoke(question)\n",
    "    \n",
    "    # 创建消息对象\n",
    "    response_message = HumanMessage(content=response)\n",
    "    \n",
    "    # 输出结果\n",
    "    print(f\"💡 生成的回答: {response}\")\n",
    "    return {\"messages\": [response_message]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c58e344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. 构建选择策略图 ---\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# 定义状态\n",
    "class SelectState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    context: str\n",
    "\n",
    "# 创建图\n",
    "select_graph = StateGraph(SelectState)\n",
    "\n",
    "# 添加节点\n",
    "select_graph.add_node(\"retrieve\", retrieve_context)\n",
    "select_graph.add_node(\"generate\", generate_with_context)\n",
    "\n",
    "# 设置入口点\n",
    "select_graph.set_entry_point(\"retrieve\")\n",
    "\n",
    "# 添加边\n",
    "select_graph.add_edge(\"retrieve\", \"generate\")\n",
    "select_graph.add_edge(\"generate\", END)\n",
    "\n",
    "# 编译图\n",
    "select_workflow = select_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6bd425e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### 演示'选择'策略 ###\n",
      "\n",
      "--- RETRIEVE CONTEXT ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 检索到 2 条相关文档\n",
      "📉 Token节省: -14 (原始: 223 -> 压缩: 237)\n",
      "📝 注入上下文:\n",
      "## 来源 1:\n",
      "机械键盘 X1 Pro 技术规格：\n",
      "- 轴体：定制青轴，60g触发压力\n",
      "- 连接：三模（蓝牙5.1/2.4G/USB-C）\n",
      "- 电池：4000mAh，续航200小时\n",
      "- 特点：热插拔轴体，PBT双色键帽，全键无冲\n",
      "- 价格：699元（限时优惠599元）\n",
      "\n",
      "## 来源 2:\n",
      "促销邮件写作指南：\n",
      "1. 标题要吸引眼球，包含优惠信息\n",
      "2. 开头用痛点场景引发共鸣\n",
      "3. 突出产品核心优势（性能>参数）\n",
      "4. 限时优惠制造紧迫感\n",
      "5. 清晰的行动召唤按钮...\n",
      "{'retrieve': {'context': '## 来源 1:\\n机械键盘 X1 Pro 技术规格：\\n- 轴体：定制青轴，60g触发压力\\n- 连接：三模（蓝牙5.1/2.4G/USB-C）\\n- 电池：4000mAh，续航200小时\\n- 特点：热插拔轴体，PBT双色键帽，全键无冲\\n- 价格：699元（限时优惠599元）\\n\\n## 来源 2:\\n促销邮件写作指南：\\n1. 标题要吸引眼球，包含优惠信息\\n2. 开头用痛点场景引发共鸣\\n3. 突出产品核心优势（性能>参数）\\n4. 限时优惠制造紧迫感\\n5. 清晰的行动召唤按钮'}}\n",
      "---\n",
      "\n",
      "--- GENERATE WITH CONTEXT ---\n",
      "💡 生成的回答: **主题：限时特惠！旗舰机械键盘 X1 Pro 仅需599元，打工人必备神器！**\n",
      "\n",
      "亲爱的用户：\n",
      "\n",
      "你是否还在为敲字卡顿、手感生硬、续航短而烦恼？  \n",
      "X1 Pro 机械键盘，专为追求极致体验的你而来！\n",
      "\n",
      "**定制青轴 | 热插拔设计 | 200小时超长续航**  \n",
      "X1 Pro 配备60g触发压力的定制青轴，清脆顺滑，回馈感十足；支持热插拔，轻松更换轴体。搭配PBT双色键帽，耐磨不打油，手感更出色。全键无冲设计，游戏办公两不误。\n",
      "\n",
      "三模连接（蓝牙5.1 / 2.4G / USB-C），稳定快速响应，兼容多设备使用。内置4000mAh大电池，续航长达200小时，告别频繁充电烦恼。\n",
      "\n",
      "**现在下单立享限时优惠价：599元！**  \n",
      "原价699元，仅限前100名下单用户，错过不再！\n",
      "\n",
      "👉 **立即抢购，享受高效打字新体验！**\n",
      "\n",
      "祝您工作愉快，  \n",
      "[您的品牌团队]\n",
      "{'generate': {'messages': [HumanMessage(content='**主题：限时特惠！旗舰机械键盘 X1 Pro 仅需599元，打工人必备神器！**\\n\\n亲爱的用户：\\n\\n你是否还在为敲字卡顿、手感生硬、续航短而烦恼？  \\nX1 Pro 机械键盘，专为追求极致体验的你而来！\\n\\n**定制青轴 | 热插拔设计 | 200小时超长续航**  \\nX1 Pro 配备60g触发压力的定制青轴，清脆顺滑，回馈感十足；支持热插拔，轻松更换轴体。搭配PBT双色键帽，耐磨不打油，手感更出色。全键无冲设计，游戏办公两不误。\\n\\n三模连接（蓝牙5.1 / 2.4G / USB-C），稳定快速响应，兼容多设备使用。内置4000mAh大电池，续航长达200小时，告别频繁充电烦恼。\\n\\n**现在下单立享限时优惠价：599元！**  \\n原价699元，仅限前100名下单用户，错过不再！\\n\\n👉 **立即抢购，享受高效打字新体验！**\\n\\n祝您工作愉快，  \\n[您的品牌团队]', additional_kwargs={}, response_metadata={})]}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# --- 5. 演示选择策略 ---\n",
    "print(\"\\n### 演示'选择'策略 ###\")\n",
    "question = \"请为我们的旗舰机械键盘X1 Pro写一封促销邮件，突出其核心优势\"\n",
    "\n",
    "# 初始状态\n",
    "initial_state = SelectState(\n",
    "    messages=[HumanMessage(content=question)],\n",
    "    context=\"\"\n",
    ")\n",
    "\n",
    "# 执行工作流\n",
    "for step in select_workflow.stream(initial_state):\n",
    "    if \"__end__\" not in step:\n",
    "        print(step)\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b78e84",
   "metadata": {},
   "source": [
    "## **策略三：压缩 (Compress) - 为上下文\"瘦身减负\"**\n",
    "\n",
    "**核心思想：** 使用总结(summarization)和裁剪(trimming)技术减少上下文长度，节省Token并提高效率。\n",
    "\n",
    "**实现两种压缩技术：**\n",
    "1. **总结压缩**：将长文本提炼为简洁摘要\n",
    "2. **裁剪压缩**：智能保留对话中最相关的部分\n",
    "\n",
    "**场景演示：** 智能体需要阅读一篇长文章并回答问题，我们通过总结压缩文章内容；同时展示对话历史裁剪技术。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a1022bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 准备长文本示例 ---\n",
    "long_article = \"\"\"\n",
    "在人工智能领域，大语言模型（LLM）的发展正以前所未有的速度推进。2023年，OpenAI发布了GPT-4模型，其上下文窗口扩展到32K tokens，大大增强了处理长文档的能力。随后，Anthropic推出了Claude 2.1模型，支持200K tokens的上下文窗口，创下了当时的新纪录。\n",
    "\n",
    "然而，2024年，这一纪录被中国科技公司深度求索（DeepSeek）打破。他们发布了DeepSeek-R1模型，不仅支持128K tokens的上下文窗口，还创新性地引入了\"上下文压缩\"技术。该技术通过智能总结和关键信息提取，可以将长文档压缩到原长度的20%-30%，同时保留95%以上的核心信息。\n",
    "\n",
    "DeepSeek-R1的技术创新主要体现在三个方面：\n",
    "1. 分层总结架构：模型首先对文档进行分段总结，然后对分段摘要进行二次总结，形成层次化的压缩结构。\n",
    "2. 语义密度优化：通过强化学习训练，模型学会识别并保留信息密度最高的内容。\n",
    "3. 自适应压缩率：根据用户任务类型动态调整压缩强度，平衡信息保留与效率。\n",
    "\n",
    "在实际测试中，DeepSeek-R1处理一篇10,000字的科技论文时，将其压缩到1,500字的关键摘要，同时准确回答了论文中的核心问题。更令人印象深刻的是，压缩后的Token使用量仅为原始的18%，而任务完成质量仅下降2%。\n",
    "\n",
    "这项技术的商业应用前景广阔：\n",
    "- 法律行业：快速分析冗长的法律文件\n",
    "- 金融领域：高效处理年度财报和招股书\n",
    "- 学术研究：加速文献综述过程\n",
    "- 客户服务：快速理解长篇客户反馈\n",
    "\n",
    "DeepSeek团队表示，他们下一步将探索\"动态上下文压缩\"，即在对话过程中实时调整压缩率，进一步优化智能体的长期记忆管理。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6e07de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. 定义压缩工具 ---\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 总结压缩工具\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"请将以下文本总结为不超过{max_words}字的关键要点，保留所有核心技术和数据：\\n\\n{text}\"\n",
    ")\n",
    "\n",
    "summarizer_chain = (\n",
    "    summary_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 裁剪压缩函数\n",
    "def trim_messages(messages: List[BaseMessage], max_messages=5) -> List[BaseMessage]:\n",
    "    \"\"\"裁剪对话历史，保留系统消息和最新的几条消息\"\"\"\n",
    "    # 始终保留第一条系统消息\n",
    "    system_message = messages[0] if messages and isinstance(messages[0], SystemMessage) else None\n",
    "    \n",
    "    # 保留最近的max_messages条消息（排除系统消息）\n",
    "    recent_messages = messages[-max_messages:] if len(messages) > 1 else messages\n",
    "    \n",
    "    # 重新组合\n",
    "    trimmed = []\n",
    "    if system_message:\n",
    "        trimmed.append(system_message)\n",
    "    trimmed.extend(recent_messages)\n",
    "    \n",
    "    return trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "59937644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 定义状态和节点 ---\n",
    "class CompressState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    original_text: str  # 原始长文本\n",
    "    compressed_text: str  # 压缩后的文本\n",
    "    token_savings: int  # 节省的Token数量\n",
    "\n",
    "def compress_long_text(state: CompressState):\n",
    "    \"\"\"总结压缩节点：将长文本压缩为摘要\"\"\"\n",
    "    print(\"\\n--- COMPRESSING LONG TEXT ---\")\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # 从用户消息中提取问题\n",
    "    question = last_message.content\n",
    "    \n",
    "    # 压缩长文本\n",
    "    summary = summarizer_chain.invoke({\"text\": state[\"original_text\"], \"max_words\": 300})\n",
    "    \n",
    "    # 计算Token节省\n",
    "    orig_tokens = len(encoding.encode(state[\"original_text\"]))\n",
    "    comp_tokens = len(encoding.encode(summary))\n",
    "    savings = orig_tokens - comp_tokens\n",
    "    \n",
    "    print(f\"📉 文本压缩: {orig_tokens} tokens → {comp_tokens} tokens (节省 {savings} tokens)\")\n",
    "    print(f\"📝 压缩摘要:\\n{summary[:200]}...\")\n",
    "    \n",
    "    # 更新状态\n",
    "    return {\n",
    "        \"compressed_text\": summary,\n",
    "        \"token_savings\": savings,\n",
    "        \"messages\": [HumanMessage(content=f\"基于以下摘要回答问题:\\n{summary}\\n\\n问题: {question}\")]\n",
    "    }\n",
    "\n",
    "def answer_with_compressed_text(state: CompressState):\n",
    "    \"\"\"回答节点：基于压缩文本回答问题\"\"\"\n",
    "    print(\"\\n--- ANSWERING WITH COMPRESSED TEXT ---\")\n",
    "    \n",
    "    # 调用模型生成答案\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    answer = response.content\n",
    "    \n",
    "    print(f\"💡 生成的回答: {answer[:200]}...\")\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def trim_context(state: CompressState):\n",
    "    \"\"\"裁剪节点：压缩对话历史\"\"\"\n",
    "    print(\"\\n--- TRIMMING CONTEXT ---\")\n",
    "    \n",
    "    # 计算裁剪前的Token\n",
    "    all_messages = \"\".join(m.content for m in state[\"messages\"])\n",
    "    before_tokens = len(encoding.encode(all_messages))\n",
    "    \n",
    "    # 执行裁剪\n",
    "    trimmed_messages = trim_messages(state[\"messages\"], max_messages=3)\n",
    "    \n",
    "    # 计算裁剪后的Token\n",
    "    trimmed_content = \"\".join(m.content for m in trimmed_messages)\n",
    "    after_tokens = len(encoding.encode(trimmed_content))\n",
    "    savings = before_tokens - after_tokens\n",
    "    \n",
    "    print(f\"✂️ 裁剪历史: {len(state['messages'])}条 → {len(trimmed_messages)}条消息\")\n",
    "    print(f\"📉 Token节省: {savings} (原始: {before_tokens} -> 裁剪后: {after_tokens})\")\n",
    "    \n",
    "    return {\"messages\": trimmed_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "047924db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. 构建压缩策略图 ---\n",
    "compress_graph = StateGraph(CompressState)\n",
    "\n",
    "# 添加节点\n",
    "compress_graph.add_node(\"compress\", compress_long_text)\n",
    "compress_graph.add_node(\"answer\", answer_with_compressed_text)\n",
    "compress_graph.add_node(\"trim\", trim_context)\n",
    "\n",
    "# 设置入口点\n",
    "compress_graph.set_entry_point(\"compress\")\n",
    "\n",
    "# 添加边\n",
    "compress_graph.add_edge(\"compress\", \"answer\")\n",
    "compress_graph.add_edge(\"answer\", END)\n",
    "\n",
    "# 添加条件边用于裁剪\n",
    "def should_trim(state: CompressState):\n",
    "    \"\"\"当消息超过5条时触发裁剪\"\"\"\n",
    "    if len(state[\"messages\"]) > 5:\n",
    "        return \"trim\"\n",
    "    return END\n",
    "\n",
    "compress_graph.add_conditional_edges(\"answer\", should_trim, {\"trim\": \"trim\", END: END})\n",
    "compress_graph.add_edge(\"trim\", END)\n",
    "\n",
    "# 编译图\n",
    "compress_workflow = compress_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bd584237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### 演示'总结压缩'技术 ###\n",
      "\n",
      "--- COMPRESSING LONG TEXT ---\n",
      "📉 文本压缩: 682 tokens → 275 tokens (节省 407 tokens)\n",
      "📝 压缩摘要:\n",
      "2023年，GPT-4支持32K tokens上下文窗口；2024年，Claude 2.1扩展至200K tokens。同年，中国公司深度求索发布DeepSeek-R1模型，支持128K tokens，并引入“上下文压缩”技术，可将长文档压缩至原长度的20%-30%，保留95%以上核心信息。\n",
      "\n",
      "其技术创新包括：分层总结架构、语义密度优化和自适应压缩率。测试显示，处理一篇10,000字论文时，模型压...\n",
      "{'compress': {'compressed_text': '2023年，GPT-4支持32K tokens上下文窗口；2024年，Claude 2.1扩展至200K tokens。同年，中国公司深度求索发布DeepSeek-R1模型，支持128K tokens，并引入“上下文压缩”技术，可将长文档压缩至原长度的20%-30%，保留95%以上核心信息。\\n\\n其技术创新包括：分层总结架构、语义密度优化和自适应压缩率。测试显示，处理一篇10,000字论文时，模型压缩至1,500字，仅使用18%的原始Token，任务质量下降仅2%。\\n\\n该技术适用于法律、金融、学术及客户服务等领域。团队未来计划探索“动态上下文压缩”，实现对话中的实时压缩率调整，提升智能体长期记忆管理能力。', 'token_savings': 407, 'messages': [HumanMessage(content='基于以下摘要回答问题:\\n2023年，GPT-4支持32K tokens上下文窗口；2024年，Claude 2.1扩展至200K tokens。同年，中国公司深度求索发布DeepSeek-R1模型，支持128K tokens，并引入“上下文压缩”技术，可将长文档压缩至原长度的20%-30%，保留95%以上核心信息。\\n\\n其技术创新包括：分层总结架构、语义密度优化和自适应压缩率。测试显示，处理一篇10,000字论文时，模型压缩至1,500字，仅使用18%的原始Token，任务质量下降仅2%。\\n\\n该技术适用于法律、金融、学术及客户服务等领域。团队未来计划探索“动态上下文压缩”，实现对话中的实时压缩率调整，提升智能体长期记忆管理能力。\\n\\n问题: DeepSeek-R1在文本压缩方面有哪些技术创新？压缩效果如何？', additional_kwargs={}, response_metadata={})]}}\n",
      "---\n",
      "\n",
      "--- ANSWERING WITH COMPRESSED TEXT ---\n",
      "💡 生成的回答: DeepSeek-R1在文本压缩方面引入了以下三大技术创新：\n",
      "\n",
      "1. **分层总结架构**：该技术通过多层次的信息提取和整合，逐步提炼出文本的核心内容。这种方式可以有效保留关键信息，同时去除冗余部分。\n",
      "\n",
      "2. **语义密度优化**：模型通过对语义的深入理解，优先保留高价值的语义单元，从而提升压缩后文本的信息密度，确保核心意义不丢失。\n",
      "\n",
      "3. **自适应压缩率**：根据输入文本的特点和用户需求，自动...\n",
      "{'answer': {'messages': [AIMessage(content='DeepSeek-R1在文本压缩方面引入了以下三大技术创新：\\n\\n1. **分层总结架构**：该技术通过多层次的信息提取和整合，逐步提炼出文本的核心内容。这种方式可以有效保留关键信息，同时去除冗余部分。\\n\\n2. **语义密度优化**：模型通过对语义的深入理解，优先保留高价值的语义单元，从而提升压缩后文本的信息密度，确保核心意义不丢失。\\n\\n3. **自适应压缩率**：根据输入文本的特点和用户需求，自动调整压缩比例，在保证信息完整性的前提下，实现灵活高效的压缩效果。\\n\\n---\\n\\n**压缩效果方面**，测试数据显示：\\n\\n- DeepSeek-R1能够将长文档压缩至原长度的**20%-30%**。\\n- 在处理一篇10,000字论文时，压缩后的结果为1,500字，仅使用原始Token的**18%**。\\n- 压缩后仍能保留**95%以上的核心信息**。\\n- 任务质量（如摘要准确性、关键信息完整性）仅下降**2%**，说明其压缩能力对任务性能影响极小。\\n\\n综上所述，DeepSeek-R1在文本压缩方面表现出色，具备高效、精准、低损等优势，适用于法律、金融、学术及客户服务等多个领域。', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-32b'}, id='run--97c14254-311e-400c-98e4-a51bddb36adc-0', usage_metadata={'input_tokens': 249, 'output_tokens': 281, 'total_tokens': 530, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# --- 5. 演示总结压缩 ---\n",
    "print(\"\\n### 演示'总结压缩'技术 ###\")\n",
    "question = \"DeepSeek-R1在文本压缩方面有哪些技术创新？压缩效果如何？\"\n",
    "\n",
    "# 初始状态\n",
    "initial_state = CompressState(\n",
    "    messages=[SystemMessage(content=\"你是一个AI技术分析师\"), HumanMessage(content=question)],\n",
    "    original_text=long_article,\n",
    "    compressed_text=\"\",\n",
    "    token_savings=0\n",
    ")\n",
    "\n",
    "# 执行工作流\n",
    "for step in compress_workflow.stream(initial_state):\n",
    "    if \"__end__\" not in step:\n",
    "        print(step)\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "77dc2c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### 演示'裁剪压缩'技术 ###\n",
      "\n",
      "--- TRIMMING CONTEXT ---\n",
      "✂️ 裁剪历史: 10条 → 4条消息\n",
      "📉 Token节省: 92 (原始: 150 -> 裁剪后: 58)\n",
      "\n",
      "裁剪前消息:\n",
      "🤖 你是一个专业的旅行助手\n",
      "👤 我想计划一次去日本的旅行\n",
      "👤 时间大概是明年3月下旬，10天左右\n",
      "👤 我对京都的文化景点特别感兴趣\n",
      "👤 另外也想体验一下东京的现代化都市\n",
      "👤 预算方面希望控制在2万元以内\n",
      "👤 请帮我规划一个行程\n",
      "👤 对了，我还想体验一次温泉旅馆\n",
      "👤 最好是那种传统的日式旅馆\n",
      "👤 现在请给我具体的行程建议\n",
      "\n",
      "裁剪后消息:\n",
      "🤖 你是一个专业的旅行助手\n",
      "👤 对了，我还想体验一次温泉旅馆\n",
      "👤 最好是那种传统的日式旅馆\n",
      "👤 现在请给我具体的行程建议\n"
     ]
    }
   ],
   "source": [
    "# --- 6. 演示对话历史裁剪 ---\n",
    "print(\"\\n### 演示'裁剪压缩'技术 ###\")\n",
    "\n",
    "# 创建一个长对话历史\n",
    "long_chat_history = [\n",
    "    SystemMessage(content=\"你是一个专业的旅行助手\"),\n",
    "    HumanMessage(content=\"我想计划一次去日本的旅行\"),\n",
    "    HumanMessage(content=\"时间大概是明年3月下旬，10天左右\"),\n",
    "    HumanMessage(content=\"我对京都的文化景点特别感兴趣\"),\n",
    "    HumanMessage(content=\"另外也想体验一下东京的现代化都市\"),\n",
    "    HumanMessage(content=\"预算方面希望控制在2万元以内\"),\n",
    "    HumanMessage(content=\"请帮我规划一个行程\"),\n",
    "    HumanMessage(content=\"对了，我还想体验一次温泉旅馆\"),\n",
    "    HumanMessage(content=\"最好是那种传统的日式旅馆\"),\n",
    "    HumanMessage(content=\"现在请给我具体的行程建议\")\n",
    "]\n",
    "\n",
    "# 初始状态（无文本压缩）\n",
    "trim_demo_state = CompressState(\n",
    "    messages=long_chat_history,\n",
    "    original_text=\"\",\n",
    "    compressed_text=\"\",\n",
    "    token_savings=0\n",
    ")\n",
    "\n",
    "# 执行裁剪\n",
    "trimmed_state = trim_context(trim_demo_state)\n",
    "\n",
    "# 显示裁剪效果\n",
    "print(\"\\n裁剪前消息:\")\n",
    "for i, msg in enumerate(long_chat_history):\n",
    "    prefix = \"🤖\" if isinstance(msg, SystemMessage) else \"👤\"\n",
    "    print(f\"{prefix} {msg.content[:50]}{'...' if len(msg.content) > 50 else ''}\")\n",
    "\n",
    "print(\"\\n裁剪后消息:\")\n",
    "for i, msg in enumerate(trimmed_state['messages']):\n",
    "    prefix = \"🤖\" if isinstance(msg, SystemMessage) else \"👤\"\n",
    "    print(f\"{prefix} {msg.content[:50]}{'...' if len(msg.content) > 50 else ''}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa94b02",
   "metadata": {},
   "source": [
    "## **策略四：隔离 (Isolate) - \"分而治之\"的架构智慧**\n",
    "\n",
    "**核心思想：** 将复杂任务分解为多个子任务，由专门的智能体在隔离环境中处理，避免上下文污染。\n",
    "\n",
    "**实现多智能体架构：** 创建专家智能体团队（分析师+文案）\n",
    "\n",
    "**场景演示：** 用户上传销售数据CSV，要求分析销售冠军并撰写营销文案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ca6ab70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 准备数据 ---\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# 创建示例销售数据CSV\n",
    "sales_data = \"\"\"\n",
    "日期,产品,销售额,销售量\n",
    "2024-01-01,机械键盘,12800,32\n",
    "2024-01-01,游戏鼠标,9800,49\n",
    "2024-01-02,机械键盘,14500,36\n",
    "2024-01-02,游戏鼠标,10200,51\n",
    "2024-01-03,机械键盘,16200,40\n",
    "2024-01-03,游戏鼠标,10800,54\n",
    "2024-01-04,机械键盘,13800,34\n",
    "2024-01-04,游戏鼠标,11200,56\n",
    "2024-01-05,机械键盘,17500,42\n",
    "2024-01-05,游戏鼠标,11800,59\n",
    "\"\"\"\n",
    "\n",
    "# 保存为CSV文件\n",
    "with open(\"sales_data.csv\", \"w\") as f:\n",
    "    f.write(sales_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fd1b3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. 定义专家智能体 ---\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 分析师智能体（直接返回预设结果）\n",
    "def analyst_agent(data, question):\n",
    "    \"\"\"模拟分析师智能体的响应\"\"\"\n",
    "    print(\"🧠 分析师智能体被调用\")\n",
    "    print(f\"问题: {question}\")\n",
    "    # 模拟分析结果（实际应从CSV计算得出）\n",
    "    return \"机械键盘,84800\"\n",
    "\n",
    "# 文案智能体\n",
    "writer_prompt = ChatPromptTemplate.from_template(\n",
    "    \"你是一个专业营销文案。请基于以下产品信息撰写文案:\\n\"\n",
    "    \"产品名称: {product}\\n\"\n",
    "    \"关键卖点: {key_points}\\n\"\n",
    "    \"要求:\\n\"\n",
    "    \"- 突出产品优势\\n\"\n",
    "    \"- 包含行动召唤\\n\"\n",
    "    \"- 不超过200字\\n\"\n",
    "    \"文案:\"\n",
    ")\n",
    "writer_agent = writer_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5334c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 定义工具 ---\n",
    "@tool\n",
    "def analyze_sales_data(question: str) -> str:\n",
    "    \"\"\"模拟分析销售数据（无需沙盒）\"\"\"\n",
    "    print(\"📊 使用预设分析结果\")\n",
    "    return \"机械键盘,84800\"\n",
    "\n",
    "@tool\n",
    "def write_marketing_copy(product: str, key_points: str) -> str:\n",
    "    \"\"\"为指定产品撰写营销文案\"\"\"\n",
    "    print(f\"📝 撰写文案: {product} - {key_points[:50]}...\")\n",
    "    return writer_agent.invoke({\"product\": product, \"key_points\": key_points})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ea160988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. 定义多智能体状态 ---\n",
    "class ManagerState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    task: str\n",
    "    analysis_result: str\n",
    "    final_output: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3badd596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. 构建多智能体图 ---\n",
    "# 创建工具节点\n",
    "tools = [analyze_sales_data, write_marketing_copy]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# 绑定工具的模型\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "def manager_node(state: ManagerState):\n",
    "    \"\"\"管理智能体：分解任务并调用专家\"\"\"\n",
    "    print(\"\\n--- MANAGER AGENT ---\")\n",
    "    # 首次调用\n",
    "    if not state.get(\"analysis_result\"):\n",
    "        print(f\"📋 任务分解: 分析销售数据 → 撰写文案\")\n",
    "        # 创建指令\n",
    "        instruction = (\n",
    "            f\"用户任务: {state['task']}\\n\"\n",
    "            \"请先分析销售数据找出销售额最高的产品，然后为该产品撰写营销文案。\"\n",
    "            \"使用工具完成分析步骤。\"\n",
    "        )\n",
    "        # 调用模型\n",
    "        response = model_with_tools.invoke([HumanMessage(content=instruction)])\n",
    "        return {\"messages\": [response]}\n",
    "    # 已有分析结果，进行下一步\n",
    "    else:\n",
    "        print(f\"📋 任务分解: 基于分析结果撰写文案\")\n",
    "        instruction = (\n",
    "            f\"分析结果: {state['analysis_result']}\\n\"\n",
    "            \"请为这个产品撰写营销文案。\"\n",
    "        )\n",
    "        response = model_with_tools.invoke([HumanMessage(content=instruction)])\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "def tool_node_simple(state: ManagerState):\n",
    "    \"\"\"简化版工具执行节点\"\"\"\n",
    "    print(\"\\n--- TOOL EXECUTION ---\")\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # 执行工具\n",
    "    tool_messages = tool_node.invoke([last_message])\n",
    "    \n",
    "    # 处理结果\n",
    "    if \"analyze_sales_data\" in last_message.content:\n",
    "        result = tool_messages[0].content\n",
    "        print(f\"🔍 分析结果: {result}\")\n",
    "        return {\"analysis_result\": result}\n",
    "    elif \"write_marketing_copy\" in last_message.content:\n",
    "        copy = tool_messages[0].content\n",
    "        print(f\"📄 文案结果: {copy[:100]}...\")\n",
    "        return {\"final_output\": copy}\n",
    "    \n",
    "    return {\"messages\": tool_messages}\n",
    "\n",
    "def should_continue(state: ManagerState):\n",
    "    \"\"\"条件路由：判断下一步\"\"\"\n",
    "    if state.get(\"final_output\"):\n",
    "        return END\n",
    "    if state.get(\"analysis_result\") and not state.get(\"final_output\"):\n",
    "        return \"manager\"  # 返回管理智能体进行下一步\n",
    "    return \"action\"  # 继续执行工具\n",
    "\n",
    "# 构建图\n",
    "isolate_graph = StateGraph(ManagerState)\n",
    "isolate_graph.add_node(\"manager\", manager_node)\n",
    "isolate_graph.add_node(\"action\", tool_node_simple)\n",
    "isolate_graph.set_entry_point(\"manager\")\n",
    "isolate_graph.add_conditional_edges(\n",
    "    \"manager\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"action\": \"action\",\n",
    "        \"manager\": \"manager\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "isolate_graph.add_edge(\"action\", \"manager\")\n",
    "isolate_workflow = isolate_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d4cc47a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### 演示多智能体协作 ###\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "📋 任务分解: 分析销售数据 → 撰写文案\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [manager] 步骤完成 ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "📊 使用预设分析结果\n",
      "--- [action] 步骤完成 ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "📋 任务分解: 分析销售数据 → 撰写文案\n",
      "--- [manager] 步骤完成 ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "📊 使用预设分析结果\n",
      "--- [action] 步骤完成 ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "📋 任务分解: 分析销售数据 → 撰写文案\n",
      "--- [manager] 步骤完成 ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "📊 使用预设分析结果\n",
      "--- [action] 步骤完成 ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "📋 任务分解: 分析销售数据 → 撰写文案\n",
      "--- [manager] 步骤完成 ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "📊 使用预设分析结果\n",
      "--- [action] 步骤完成 ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "📋 任务分解: 分析销售数据 → 撰写文案\n",
      "--- [manager] 步骤完成 ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "📊 使用预设分析结果\n",
      "--- [action] 步骤完成 ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "📋 任务分解: 分析销售数据 → 撰写文案\n",
      "--- [manager] 步骤完成 ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "📊 使用预设分析结果\n",
      "--- [action] 步骤完成 ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "📋 任务分解: 分析销售数据 → 撰写文案\n",
      "--- [manager] 步骤完成 ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "📊 使用预设分析结果\n",
      "--- [action] 步骤完成 ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "📋 任务分解: 分析销售数据 → 撰写文案\n",
      "--- [manager] 步骤完成 ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "📊 使用预设分析结果\n",
      "--- [action] 步骤完成 ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "📋 任务分解: 分析销售数据 → 撰写文案\n",
      "--- [manager] 步骤完成 ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "📊 使用预设分析结果\n",
      "--- [action] 步骤完成 ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "📋 任务分解: 分析销售数据 → 撰写文案\n",
      "--- [manager] 步骤完成 ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "📊 使用预设分析结果\n",
      "--- [action] 步骤完成 ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "📋 任务分解: 分析销售数据 → 撰写文案\n",
      "--- [manager] 步骤完成 ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "📊 使用预设分析结果\n",
      "--- [action] 步骤完成 ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "📋 任务分解: 分析销售数据 → 撰写文案\n",
      "--- [manager] 步骤完成 ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "📊 使用预设分析结果\n",
      "--- [action] 步骤完成 ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "📋 任务分解: 分析销售数据 → 撰写文案\n",
      "--- [manager] 步骤完成 ---\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 15\u001b[0m\n\u001b[1;32m      7\u001b[0m initial_state \u001b[38;5;241m=\u001b[39m ManagerState(\n\u001b[1;32m      8\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m      9\u001b[0m     task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[1;32m     10\u001b[0m     analysis_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     final_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 执行工作流\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m isolate_workflow\u001b[38;5;241m.\u001b[39mstream(initial_state):\n\u001b[1;32m     16\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(step\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m     state \u001b[38;5;241m=\u001b[39m step[node]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/__init__.py:2559\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_of_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2551\u001b[0m     msg \u001b[38;5;241m=\u001b[39m create_error_message(\n\u001b[1;32m   2552\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   2553\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2557\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mGRAPH_RECURSION_LIMIT,\n\u001b[1;32m   2558\u001b[0m     )\n\u001b[0;32m-> 2559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[1;32m   2560\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[1;32m   2561\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(loop\u001b[38;5;241m.\u001b[39moutput)\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
     ]
    }
   ],
   "source": [
    "# --- 6. 执行多智能体协作 ---\n",
    "print(\"\\n### 演示多智能体协作 ###\")\n",
    "task = (\n",
    "    \"分析销售数据找出销售额最高的产品，\"\n",
    "    \"然后为该产品撰写一篇吸引人的营销文案。\"\n",
    ")\n",
    "initial_state = ManagerState(\n",
    "    messages=[],\n",
    "    task=task,\n",
    "    analysis_result=\"\",\n",
    "    final_output=\"\"\n",
    ")\n",
    "\n",
    "# 执行工作流\n",
    "for step in isolate_workflow.stream(initial_state):\n",
    "    node = list(step.keys())[0]\n",
    "    state = step[node]\n",
    "    print(f\"--- [{node}] 步骤完成 ---\")\n",
    "    if \"final_output\" in state and state[\"final_output\"]:\n",
    "        print(f\"\\n🎉 最终文案:\\n{state['final_output']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
