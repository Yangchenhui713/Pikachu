{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e2281b",
   "metadata": {},
   "source": [
    "# **ä½¿ç”¨ LangGraph å’Œ Qwen æ¨¡å‹å®ç°ä¸Šä¸‹æ–‡å·¥ç¨‹å››å¤§ç­–ç•¥**\n",
    "\n",
    "### **ç›®æ ‡**\n",
    "æœ¬ Notebook å°†ä½œä¸ºä¸€ä»½è¯¦ç»†çš„æŠ€æœ¯æŒ‡å—ï¼Œæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ LangGraph æ¡†æ¶å’Œé€šä¹‰åƒé—®ï¼ˆQwenï¼‰æ¨¡å‹ï¼Œä¸€æ­¥æ­¥å®ç°â€œä¸Šä¸‹æ–‡å·¥ç¨‹â€çš„å››å¤§æ ¸å¿ƒç­–ç•¥ã€‚\n",
    "\n",
    "å››å¤§ç­–ç•¥åŒ…æ‹¬ï¼š\n",
    "1.  **å†™å…¥ (Write):** ä¸ºæ™ºèƒ½ä½“æ„å»ºä¸€ä¸ªâ€œå¤–éƒ¨å¤§è„‘â€ï¼ˆæš‚å­˜åŒºï¼‰ï¼Œä»¥åœ¨é•¿ä»»åŠ¡ä¸­ä¿æŒçŠ¶æ€ã€‚\n",
    "2.  **é€‰æ‹© (Select):** ä½¿ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ä»çŸ¥è¯†åº“ä¸­ç²¾å‡†è°ƒå–ä¿¡æ¯ã€‚\n",
    "3.  **å‹ç¼© (Compress):** æ™ºèƒ½åœ°æ€»ç»“å¯¹è¯å†å²ï¼Œä»¥èŠ‚çœæˆæœ¬å’ŒTokenã€‚\n",
    "4.  **éš”ç¦» (Isolate):** ä½¿ç”¨å¤šæ™ºèƒ½ä½“ï¼ˆMulti-agentï¼‰æ¶æ„ï¼Œå°†å¤æ‚ä»»åŠ¡åˆ†è§£ç»™ä¸“å®¶å¤„ç†ã€‚\n",
    "\n",
    "---\n",
    "### **ç¬¬ä¸€æ­¥ï¼šç¯å¢ƒè®¾ç½®ä¸æ¨¡å‹åˆå§‹åŒ–**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6ddefae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.cloud.aliyuncs.com/pypi/simple/\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-qwq in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.5.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
      "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.27)\n",
      "Requirement already satisfied: dashscope in /usr/local/lib/python3.10/dist-packages (1.23.8)\n",
      "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.11.0.post1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.69)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.4.6)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.70.0 in /usr/local/lib/python3.10/dist-packages (from langchain-qwq) (1.97.0)\n",
      "Requirement already satisfied: json-repair<0.41.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from langchain-qwq) (0.40.0)\n",
      "Requirement already satisfied: langchain-openai<0.4.0,>=0.3.11 in /usr/local/lib/python3.10/dist-packages (from langchain-qwq) (0.3.28)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph) (2.1.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.5.2)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.1.73)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.12.14)\n",
      "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from dashscope) (1.8.0)\n",
      "Requirement already satisfied: cryptography in /usr/lib/python3/dist-packages (from dashscope) (3.4.8)\n",
      "Requirement already satisfied: packaging in /root/.local/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (21.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /root/.local/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai<0.4.0,>=0.3.11->langchain-qwq) (0.9.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.70.0->langchain-qwq) (4.67.1)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.70.0->langchain-qwq) (1.3.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.70.0->langchain-qwq) (0.10.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.70.0->langchain-qwq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.70.0->langchain-qwq) (1.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (1.26.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.70.0->langchain-qwq) (1.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/lib/python3/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (2.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai<0.4.0,>=0.3.11->langchain-qwq) (2024.11.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install langchain langchain-qwq langgraph pandas python-dotenv langchain_community dashscope faiss-cpu pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0417ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import json\n",
    "import operator\n",
    "from typing import List, TypedDict, Annotated\n",
    "\n",
    "import tiktoken\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, ToolMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_qwq import ChatQwen\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1547b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. è®¾ç½®APIå¯†é’¥ ---\n",
    "# è¯·æ³¨æ„ï¼šè¿™é‡Œéœ€è¦çš„æ˜¯ DashScope çš„ API Key\n",
    "if \"DASHSCOPE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"DASHSCOPE_API_KEY\"] = getpass.getpass(\"è¯·è¾“å…¥æ‚¨çš„DashScope API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ef5d7428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼\n"
     ]
    }
   ],
   "source": [
    "# --- 2. åˆå§‹åŒ–Qwenæ¨¡å‹ ---\n",
    "# æˆ‘ä»¬å°†ä½¿ç”¨ qwen3-32b æ¨¡å‹ä½œä¸ºæˆ‘ä»¬æ™ºèƒ½ä½“çš„â€œå¤§è„‘â€\n",
    "try:\n",
    "    model = ChatQwen(model=\"qwen3-32b\", base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",  enable_thinking=False)\n",
    "    print(\"Qwen æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼\")\n",
    "except Exception as e:\n",
    "    print(f\"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥API Keyæˆ–ç½‘ç»œè¿æ¥: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bc73c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. åˆå§‹åŒ–Tokenè®¡ç®—å™¨ ---\n",
    "# è¿™å°†å¸®åŠ©æˆ‘ä»¬é‡åŒ–â€œå‹ç¼©â€ç­–ç•¥å¸¦æ¥çš„æ•ˆæœ\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a80f1e5",
   "metadata": {},
   "source": [
    "## **ç­–ç•¥ä¸€ï¼šå†™å…¥ (Write) - æ„å»ºæ™ºèƒ½ä½“çš„â€œè‰ç¨¿çº¸â€**\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³:** ä¸æŠŠæ‰€æœ‰ä¸­é—´æ­¥éª¤å’Œæ€è€ƒéƒ½å¡è¿›ä¸»å¯¹è¯å†å²ï¼ˆ`messages`ï¼‰ï¼Œè€Œæ˜¯å°†å®ƒä»¬â€œå†™å…¥â€åˆ°ä¸€ä¸ªç‹¬ç«‹çš„â€œæš‚å­˜åŒºâ€ï¼ˆ`scratchpad`ï¼‰ã€‚è¿™å¯ä»¥ä¿æŒä¸»å¯¹è¯çš„æ¸…æ™°ï¼Œå¹¶ä¸ºæ™ºèƒ½ä½“æä¾›ä¸€ä¸ªå¯é çš„çŸ­æœŸè®°å¿†ï¼Œé˜²æ­¢åœ¨é•¿ä»»åŠ¡ä¸­â€œå¤±å¿†â€ã€‚\n",
    "\n",
    "**å®ç°:** æˆ‘ä»¬å°†åœ¨`AgentState`ä¸­å¢åŠ ä¸€ä¸ª`scratchpad`å­—æ®µï¼Œå¹¶é€šè¿‡æ·»åŠ `SystemMessage`æ¥æŒ‡å¯¼æ¨¡å‹çš„è¡Œä¸ºï¼Œé˜²æ­¢æ— é™å¾ªç¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "63a46ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. å®šä¹‰çŠ¶æ€ ---\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List, Annotated\n",
    "import operator\n",
    "\n",
    "class ToolCallRecord(TypedDict):\n",
    "    step: int\n",
    "    tool_name: str\n",
    "    args: dict\n",
    "    result: str\n",
    "\n",
    "class WriteStrategyState(TypedDict):\n",
    "    messages: Annotated[list, operator.add]\n",
    "    # ç»“æ„åŒ– scratchpadï¼Œä¿ç•™å®Œæ•´å†å²\n",
    "    scratchpad: dict  # {\"history\": List[ToolCallRecord], \"final_answer\": str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "436e02ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. å®šä¹‰å·¥å…· ---\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def simple_calculator(operation: str, a: int, b: int) -> int:\n",
    "    \"\"\"ä¸€ä¸ªç®€å•çš„è®¡ç®—å™¨å·¥å…·ï¼Œæ‰§è¡ŒåŠ å‡ä¹˜é™¤ã€‚\"\"\"\n",
    "    if operation == \"add\":\n",
    "        return a + b\n",
    "    if operation == \"subtract\":\n",
    "        return a - b\n",
    "    if operation == \"multiply\":\n",
    "        return a * b\n",
    "    if operation == \"divide\" and b != 0:\n",
    "        return a // b\n",
    "    return \"æ— æ•ˆæ“ä½œ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a7d01195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. å®šä¹‰å›¾çš„èŠ‚ç‚¹ ---\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import END\n",
    "\n",
    "tools = [simple_calculator]\n",
    "tool_node = ToolNode(tools)\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "def agent_with_scratchpad(state: WriteStrategyState):\n",
    "    \"\"\"\n",
    "    Agent èŠ‚ç‚¹ï¼šå†³å®šä¸‹ä¸€æ­¥åŠ¨ä½œï¼Œå¹¶æ›´æ–°æš‚å­˜åŒºã€‚\n",
    "    \"\"\"\n",
    "    print(\"---AGENT NODE---\")\n",
    "    response = model_with_tools.invoke(state['messages'])\n",
    "\n",
    "    if response.tool_calls:\n",
    "        # æš‚å­˜å½“å‰å¾…æ‰§è¡Œçš„å·¥å…·\n",
    "        state['scratchpad']['pending_tool'] = response.tool_calls[0]\n",
    "        print(f\"ğŸ§  Agent Action: Call tool `{response.tool_calls[0]['name']}` \"\n",
    "              f\"with arguments `{response.tool_calls[0]['args']}`\")\n",
    "    else:\n",
    "        # å…¨éƒ¨å®Œæˆï¼Œä¿å­˜æœ€ç»ˆç­”æ¡ˆ\n",
    "        state['scratchpad']['final_answer'] = response.content\n",
    "        print(f\"âœ… Final Answer: {response.content}\")\n",
    "\n",
    "    return {\"messages\": [response], \"scratchpad\": state['scratchpad']}\n",
    "\n",
    "def tool_node_with_scratchpad(state: WriteStrategyState):\n",
    "    \"\"\"\n",
    "    Tool èŠ‚ç‚¹ï¼šæ‰§è¡Œå·¥å…·ï¼Œå¹¶æŠŠç»“æœè®°å½•åˆ° historyã€‚\n",
    "    \"\"\"\n",
    "    print(\"---TOOL NODE---\")\n",
    "    last_message = state['messages'][-1]\n",
    "    tool_messages = tool_node.invoke([last_message])\n",
    "\n",
    "    # å–å‡ºå¾…å¤„ç†çš„å·¥å…·è°ƒç”¨\n",
    "    pending = state['scratchpad']['pending_tool']\n",
    "    record = ToolCallRecord(\n",
    "        step=len(state['scratchpad'].get(\"history\", [])) + 1,\n",
    "        tool_name=pending['name'],\n",
    "        args=pending['args'],\n",
    "        result=str(tool_messages[0].content)\n",
    "    )\n",
    "    # è¿½åŠ åˆ°å†å²\n",
    "    state['scratchpad'].setdefault(\"history\", []).append(record)\n",
    "    print(f\"ğŸ“ Recorded Tool Call: {record}\")\n",
    "    state['scratchpad'].pop(\"pending_tool\", None)  # æ¸…ç†\n",
    "\n",
    "    #print(f\"ğŸ› ï¸ Tool Result: `{record['result']}`\")\n",
    "    return {\"messages\": tool_messages, \"scratchpad\": state['scratchpad']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4be3a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. æ„å»ºå›¾ ---\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "write_graph_builder = StateGraph(WriteStrategyState)\n",
    "write_graph_builder.add_node(\"agent\", agent_with_scratchpad)\n",
    "write_graph_builder.add_node(\"action\", tool_node_with_scratchpad)\n",
    "write_graph_builder.set_entry_point(\"agent\")\n",
    "\n",
    "# æ¡ä»¶è¾¹ï¼šæ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªå®Œæˆçš„å·¥å…·\n",
    "def should_continue(state: WriteStrategyState) -> str:\n",
    "    # è‹¥æœ€ç»ˆç­”æ¡ˆå·²å­˜åœ¨ï¼Œç›´æ¥ç»“æŸ\n",
    "    if state['scratchpad'].get(\"final_answer\"):\n",
    "        return END\n",
    "    return \"action\"\n",
    "\n",
    "write_graph_builder.add_conditional_edges(\"agent\", should_continue, {\"action\": \"action\", END: END})\n",
    "write_graph_builder.add_edge(\"action\", \"agent\")\n",
    "write_graph = write_graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3aa372ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### æ¼”ç¤ºâ€œå†™å…¥â€ç­–ç•¥ ###\n",
      "---AGENT NODE---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Agent Action: Call tool `simple_calculator` with arguments `{'a': 128, 'b': 72, 'operation': 'add'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "ğŸ“ Recorded Tool Call: {'step': 1, 'tool_name': 'simple_calculator', 'args': {'a': 128, 'b': 72, 'operation': 'add'}, 'result': '200'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "ğŸ§  Agent Action: Call tool `simple_calculator` with arguments `{'a': 200, 'b': 3, 'operation': 'multiply'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "ğŸ“ Recorded Tool Call: {'step': 2, 'tool_name': 'simple_calculator', 'args': {'a': 200, 'b': 3, 'operation': 'multiply'}, 'result': '600'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "ğŸ§  Agent Action: Call tool `simple_calculator` with arguments `{'a': 600, 'b': 100, 'operation': 'divide'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "ğŸ“ Recorded Tool Call: {'step': 3, 'tool_name': 'simple_calculator', 'args': {'a': 600, 'b': 100, 'operation': 'divide'}, 'result': '6'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "ğŸ§  Agent Action: Call tool `simple_calculator` with arguments `{'a': 6, 'b': 20, 'operation': 'multiply'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "ğŸ“ Recorded Tool Call: {'step': 4, 'tool_name': 'simple_calculator', 'args': {'a': 6, 'b': 20, 'operation': 'multiply'}, 'result': '120'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "ğŸ§  Agent Action: Call tool `simple_calculator` with arguments `{'a': 120, 'b': 222, 'operation': 'subtract'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "ğŸ“ Recorded Tool Call: {'step': 5, 'tool_name': 'simple_calculator', 'args': {'a': 120, 'b': 222, 'operation': 'subtract'}, 'result': '-102'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "âœ… Final Answer: 5) æœ€ç»ˆä»é£é™©æ•å£ä¸­ä¸€æ¬¡æ€§æ‰£é™¤ 222 å…ƒå›ºå®šå‡†å¤‡é‡‘åçš„ç»“æœæ˜¯ -102 å…ƒã€‚\n",
      "\n",
      "æœ€ç»ˆç»“æœï¼š-102\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# --- 5. æ¼”ç¤º ---\n",
    "print(\"### æ¼”ç¤ºâ€œå†™å…¥â€ç­–ç•¥ ###\")\n",
    "task = (\n",
    "    \"1) åˆå§‹ç°é‡‘æµ 128 å…ƒä¸é¢„ç®—è¿½åŠ  72 å…ƒå…ˆè¿›è¡Œåˆå¹¶ï¼›\\n\"\n",
    "    \"2) åˆå¹¶åçš„èµ„é‡‘æŒ‰å­£åº¦å¤åˆ© 3 å€æ æ†æ”¾å¤§ï¼›\\n\"\n",
    "    \"3) æ”¾å¤§åçš„èµ„é‡‘å› æ±‡ç‡æŠ˜ç®—éœ€é™¤ä»¥ 100 å¾—åˆ°åŸºå‡†å•ä½å€¼ï¼›\\n\"\n",
    "    \"4) åŸºå‡†å•ä½å€¼å†æŒ‰ 20 å€é£é™©ç³»æ•°æ”¾å¤§ï¼Œå½¢æˆé£é™©æ•å£ï¼›\\n\"\n",
    "    \"5) æœ€ç»ˆä»é£é™©æ•å£ä¸­ä¸€æ¬¡æ€§æ‰£é™¤ 222 å…ƒçš„å›ºå®šå‡†å¤‡é‡‘ã€‚\\n\"\n",
    "    \"è¯·åˆ—å‡ºæ¯ä¸€æ­¥çš„æ•°å€¼ç»“æœï¼Œå¹¶ä»¥ã€æœ€ç»ˆç»“æœï¼š{æ•°å€¼}ã€çš„æ ¼å¼ç»™å‡ºç­”æ¡ˆã€‚\"\n",
    ")\n",
    "\n",
    "system_prompt = (\n",
    "    \"ä½ æ˜¯ä¸€ä¸ªè®¡ç®—åŠ©æ‰‹ã€‚è¯·æŒ‰æ­¥éª¤ä½¿ç”¨ `simple_calculator` å·¥å…·æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚ \"\n",
    ")\n",
    "initial_messages = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(content=task)\n",
    "]\n",
    "initial_state = {\"messages\": initial_messages, \"scratchpad\": {\"history\": [], \"final_answer\": None}}\n",
    "\n",
    "# ä½¿ç”¨ .stream() è§‚å¯Ÿæ¯ä¸€æ­¥\n",
    "for step in write_graph.stream(initial_state, {\"recursion_limit\": 20}):\n",
    "    #print(step)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e126c53",
   "metadata": {},
   "source": [
    "## **ç­–ç•¥äºŒï¼šé€‰æ‹© (Select) - ç²¾å‡†çš„\"ä¿¡æ¯è°ƒå–\"**\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³ï¼š** ä½¿ç”¨RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æŠ€æœ¯ï¼Œä»å¤–éƒ¨çŸ¥è¯†åº“ä¸­ç²¾å‡†æ£€ç´¢æœ€ç›¸å…³çš„ä¿¡æ¯ç‰‡æ®µï¼Œåªå°†å¿…è¦ä¿¡æ¯æ³¨å…¥ä¸Šä¸‹æ–‡ã€‚\n",
    "\n",
    "**å®ç°æ­¥éª¤ï¼š**\n",
    "1. åˆ›å»ºäº§å“çŸ¥è¯†åº“ï¼ˆæ¨¡æ‹Ÿå‘é‡æ•°æ®åº“ï¼‰\n",
    "2. æ„å»ºRAGæ£€ç´¢å™¨\n",
    "3. è®¾è®¡æ™ºèƒ½ä½“æµç¨‹ï¼šé—®é¢˜ â†’ æ£€ç´¢ â†’ ç”Ÿæˆç­”æ¡ˆ\n",
    "4. å¯è§†åŒ–TokenèŠ‚çœæ•ˆæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8d67324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. åˆ›å»ºæ¨¡æ‹Ÿäº§å“çŸ¥è¯†åº“ ---\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "\n",
    "# åˆ›å»ºåµŒå…¥æ¨¡å‹\n",
    "embeddings = DashScopeEmbeddings(model=\"text-embedding-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "29f0b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# äº§å“çŸ¥è¯†æ–‡æ¡£ï¼ˆå®é™…åº”ç”¨ä¸­ä¼šä»æ•°æ®åº“åŠ è½½ï¼‰\n",
    "product_docs = [\n",
    "    Document(page_content=\"\"\"æœºæ¢°é”®ç›˜ X1 Pro æŠ€æœ¯è§„æ ¼ï¼š\n",
    "- è½´ä½“ï¼šå®šåˆ¶é’è½´ï¼Œ60gè§¦å‘å‹åŠ›\n",
    "- è¿æ¥ï¼šä¸‰æ¨¡ï¼ˆè“ç‰™5.1/2.4G/USB-Cï¼‰\n",
    "- ç”µæ± ï¼š4000mAhï¼Œç»­èˆª200å°æ—¶\n",
    "- ç‰¹ç‚¹ï¼šçƒ­æ’æ‹”è½´ä½“ï¼ŒPBTåŒè‰²é”®å¸½ï¼Œå…¨é”®æ— å†²\n",
    "- ä»·æ ¼ï¼š699å…ƒï¼ˆé™æ—¶ä¼˜æƒ 599å…ƒï¼‰\"\"\", \n",
    "             metadata={\"product\": \"æœºæ¢°é”®ç›˜ X1 Pro\", \"category\": \"é”®ç›˜\"}),\n",
    "    \n",
    "    Document(page_content=\"\"\"æ¸¸æˆé¼ æ ‡ M800 æ——èˆ°ç‰ˆï¼š\n",
    "- ä¼ æ„Ÿå™¨ï¼šåŸç›¸PAW3395ï¼Œ26000DPI\n",
    "- å¾®åŠ¨ï¼šæ¬§å§†é¾™å…‰å­¦å¾®åŠ¨ï¼Œ1äº¿æ¬¡å¯¿å‘½\n",
    "- é‡é‡ï¼š58gï¼ˆè¶…è½»é‡åŒ–è®¾è®¡ï¼‰\n",
    "- RGBï¼š1680ä¸‡è‰²ï¼Œ10åŒºåŸŸç‹¬ç«‹æ§å…‰\n",
    "- ä»·æ ¼ï¼š399å…ƒï¼ˆå¥—è£…ä¼˜æƒ ä»·ï¼‰\"\"\", \n",
    "             metadata={\"product\": \"æ¸¸æˆé¼ æ ‡ M800\", \"category\": \"é¼ æ ‡\"}),\n",
    "    \n",
    "    Document(page_content=\"\"\"ä¿ƒé”€é‚®ä»¶å†™ä½œæŒ‡å—ï¼š\n",
    "1. æ ‡é¢˜è¦å¸å¼•çœ¼çƒï¼ŒåŒ…å«ä¼˜æƒ ä¿¡æ¯\n",
    "2. å¼€å¤´ç”¨ç—›ç‚¹åœºæ™¯å¼•å‘å…±é¸£\n",
    "3. çªå‡ºäº§å“æ ¸å¿ƒä¼˜åŠ¿ï¼ˆæ€§èƒ½>å‚æ•°ï¼‰\n",
    "4. é™æ—¶ä¼˜æƒ åˆ¶é€ ç´§è¿«æ„Ÿ\n",
    "5. æ¸…æ™°çš„è¡ŒåŠ¨å¬å”¤æŒ‰é’®\"\"\", \n",
    "             metadata={\"doc_type\": \"writing_guide\"}),\n",
    "    \n",
    "    Document(page_content=\"\"\"ç”¨æˆ·åå¥½åˆ†æï¼š\n",
    "ç§‘æŠ€äº§å“æ¶ˆè´¹è€…æœ€å…³æ³¨ï¼š\n",
    "- æ€§èƒ½å‚æ•°ï¼ˆ75%ç”¨æˆ·ï¼‰\n",
    "- æ€§ä»·æ¯”ï¼ˆ68%ç”¨æˆ·ï¼‰\n",
    "- è€ç”¨æ€§ï¼ˆ52%ç”¨æˆ·ï¼‰\n",
    "- å¤–è§‚è®¾è®¡ï¼ˆ48%ç”¨æˆ·ï¼‰\"\"\", \n",
    "             metadata={\"doc_type\": \"user_insight\"}),\n",
    "]\n",
    "\n",
    "# åˆ›å»ºå‘é‡æ•°æ®åº“\n",
    "vector_db = FAISS.from_documents(product_docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "259408e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. æ„å»ºRAGæ£€ç´¢å™¨ ---\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# åˆ›å»ºæ£€ç´¢å™¨\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"æ ¼å¼åŒ–æ£€ç´¢åˆ°çš„æ–‡æ¡£\"\"\"\n",
    "    return \"\\n\\n\".join(f\"## æ¥æº {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(docs))\n",
    "\n",
    "# åˆ›å»ºRAGæç¤ºæ¨¡æ¿\n",
    "rag_template = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„äº§å“æ–‡æ¡ˆåŠ©æ‰‹ã€‚è¯·æ ¹æ®æä¾›çš„èƒŒæ™¯ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n",
    "\n",
    "<èƒŒæ™¯ä¿¡æ¯>\n",
    "{context}\n",
    "</èƒŒæ™¯ä¿¡æ¯>\n",
    "\n",
    "ç”¨æˆ·é—®é¢˜ï¼š{question}\n",
    "\n",
    "è¯·ç”¨ä¸“ä¸šã€ç®€æ´çš„è¯­è¨€å›ç­”ï¼Œçªå‡ºäº§å“æ ¸å¿ƒä¼˜åŠ¿ï¼š\n",
    "\"\"\"\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_template)\n",
    "\n",
    "# åˆ›å»ºRAGé“¾\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | RunnableLambda(format_docs), \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b04e7dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. è®¾è®¡æ™ºèƒ½ä½“æµç¨‹ ---\n",
    "class SelectStrategyState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    context: str  # å­˜å‚¨æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡\n",
    "\n",
    "def retrieve_context(state: SelectStrategyState):\n",
    "    \"\"\"æ£€ç´¢èŠ‚ç‚¹ï¼šä»çŸ¥è¯†åº“è·å–ç›¸å…³ä¿¡æ¯\"\"\"\n",
    "    print(\"\\n--- RETRIEVE CONTEXT ---\")\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    \n",
    "    # æ‰§è¡Œæ£€ç´¢\n",
    "    docs = retriever.invoke(last_message)\n",
    "    context = format_docs(docs)\n",
    "    \n",
    "    # è®¡ç®—TokenèŠ‚çœ\n",
    "    orig_token_count = sum(len(encoding.encode(doc.page_content)) for doc in docs)\n",
    "    context_token_count = len(encoding.encode(context))\n",
    "    savings = orig_token_count - context_token_count\n",
    "    \n",
    "    print(f\"ğŸ” æ£€ç´¢åˆ° {len(docs)} æ¡ç›¸å…³æ–‡æ¡£\")\n",
    "    print(f\"ğŸ“‰ TokenèŠ‚çœ: {savings} (åŸå§‹: {orig_token_count} -> å‹ç¼©: {context_token_count})\")\n",
    "    print(f\"ğŸ“ æ³¨å…¥ä¸Šä¸‹æ–‡:\\n{context[:300]}...\")\n",
    "    \n",
    "    return {\"context\": context}\n",
    "\n",
    "def generate_with_context(state: SelectStrategyState):\n",
    "    \"\"\"ç”ŸæˆèŠ‚ç‚¹ï¼šä½¿ç”¨æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ç”Ÿæˆå›ç­”\"\"\"\n",
    "    print(\"\\n--- GENERATE WITH CONTEXT ---\")\n",
    "    question = state[\"messages\"][-1].content\n",
    "    \n",
    "    # ä½¿ç”¨RAGé“¾ç”Ÿæˆå›ç­”\n",
    "    response = rag_chain.invoke(question)\n",
    "    \n",
    "    # åˆ›å»ºæ¶ˆæ¯å¯¹è±¡\n",
    "    response_message = HumanMessage(content=response)\n",
    "    \n",
    "    # è¾“å‡ºç»“æœ\n",
    "    print(f\"ğŸ’¡ ç”Ÿæˆçš„å›ç­”: {response}\")\n",
    "    return {\"messages\": [response_message]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c58e344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. æ„å»ºé€‰æ‹©ç­–ç•¥å›¾ ---\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# å®šä¹‰çŠ¶æ€\n",
    "class SelectState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    context: str\n",
    "\n",
    "# åˆ›å»ºå›¾\n",
    "select_graph = StateGraph(SelectState)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "select_graph.add_node(\"retrieve\", retrieve_context)\n",
    "select_graph.add_node(\"generate\", generate_with_context)\n",
    "\n",
    "# è®¾ç½®å…¥å£ç‚¹\n",
    "select_graph.set_entry_point(\"retrieve\")\n",
    "\n",
    "# æ·»åŠ è¾¹\n",
    "select_graph.add_edge(\"retrieve\", \"generate\")\n",
    "select_graph.add_edge(\"generate\", END)\n",
    "\n",
    "# ç¼–è¯‘å›¾\n",
    "select_workflow = select_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6bd425e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### æ¼”ç¤º'é€‰æ‹©'ç­–ç•¥ ###\n",
      "\n",
      "--- RETRIEVE CONTEXT ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æ£€ç´¢åˆ° 2 æ¡ç›¸å…³æ–‡æ¡£\n",
      "ğŸ“‰ TokenèŠ‚çœ: -14 (åŸå§‹: 223 -> å‹ç¼©: 237)\n",
      "ğŸ“ æ³¨å…¥ä¸Šä¸‹æ–‡:\n",
      "## æ¥æº 1:\n",
      "æœºæ¢°é”®ç›˜ X1 Pro æŠ€æœ¯è§„æ ¼ï¼š\n",
      "- è½´ä½“ï¼šå®šåˆ¶é’è½´ï¼Œ60gè§¦å‘å‹åŠ›\n",
      "- è¿æ¥ï¼šä¸‰æ¨¡ï¼ˆè“ç‰™5.1/2.4G/USB-Cï¼‰\n",
      "- ç”µæ± ï¼š4000mAhï¼Œç»­èˆª200å°æ—¶\n",
      "- ç‰¹ç‚¹ï¼šçƒ­æ’æ‹”è½´ä½“ï¼ŒPBTåŒè‰²é”®å¸½ï¼Œå…¨é”®æ— å†²\n",
      "- ä»·æ ¼ï¼š699å…ƒï¼ˆé™æ—¶ä¼˜æƒ 599å…ƒï¼‰\n",
      "\n",
      "## æ¥æº 2:\n",
      "ä¿ƒé”€é‚®ä»¶å†™ä½œæŒ‡å—ï¼š\n",
      "1. æ ‡é¢˜è¦å¸å¼•çœ¼çƒï¼ŒåŒ…å«ä¼˜æƒ ä¿¡æ¯\n",
      "2. å¼€å¤´ç”¨ç—›ç‚¹åœºæ™¯å¼•å‘å…±é¸£\n",
      "3. çªå‡ºäº§å“æ ¸å¿ƒä¼˜åŠ¿ï¼ˆæ€§èƒ½>å‚æ•°ï¼‰\n",
      "4. é™æ—¶ä¼˜æƒ åˆ¶é€ ç´§è¿«æ„Ÿ\n",
      "5. æ¸…æ™°çš„è¡ŒåŠ¨å¬å”¤æŒ‰é’®...\n",
      "{'retrieve': {'context': '## æ¥æº 1:\\næœºæ¢°é”®ç›˜ X1 Pro æŠ€æœ¯è§„æ ¼ï¼š\\n- è½´ä½“ï¼šå®šåˆ¶é’è½´ï¼Œ60gè§¦å‘å‹åŠ›\\n- è¿æ¥ï¼šä¸‰æ¨¡ï¼ˆè“ç‰™5.1/2.4G/USB-Cï¼‰\\n- ç”µæ± ï¼š4000mAhï¼Œç»­èˆª200å°æ—¶\\n- ç‰¹ç‚¹ï¼šçƒ­æ’æ‹”è½´ä½“ï¼ŒPBTåŒè‰²é”®å¸½ï¼Œå…¨é”®æ— å†²\\n- ä»·æ ¼ï¼š699å…ƒï¼ˆé™æ—¶ä¼˜æƒ 599å…ƒï¼‰\\n\\n## æ¥æº 2:\\nä¿ƒé”€é‚®ä»¶å†™ä½œæŒ‡å—ï¼š\\n1. æ ‡é¢˜è¦å¸å¼•çœ¼çƒï¼ŒåŒ…å«ä¼˜æƒ ä¿¡æ¯\\n2. å¼€å¤´ç”¨ç—›ç‚¹åœºæ™¯å¼•å‘å…±é¸£\\n3. çªå‡ºäº§å“æ ¸å¿ƒä¼˜åŠ¿ï¼ˆæ€§èƒ½>å‚æ•°ï¼‰\\n4. é™æ—¶ä¼˜æƒ åˆ¶é€ ç´§è¿«æ„Ÿ\\n5. æ¸…æ™°çš„è¡ŒåŠ¨å¬å”¤æŒ‰é’®'}}\n",
      "---\n",
      "\n",
      "--- GENERATE WITH CONTEXT ---\n",
      "ğŸ’¡ ç”Ÿæˆçš„å›ç­”: **ä¸»é¢˜ï¼šé™æ—¶ç‰¹æƒ ï¼æ——èˆ°æœºæ¢°é”®ç›˜ X1 Pro ä»…éœ€599å…ƒï¼Œæ‰“å·¥äººå¿…å¤‡ç¥å™¨ï¼**\n",
      "\n",
      "äº²çˆ±çš„ç”¨æˆ·ï¼š\n",
      "\n",
      "ä½ æ˜¯å¦è¿˜åœ¨ä¸ºæ•²å­—å¡é¡¿ã€æ‰‹æ„Ÿç”Ÿç¡¬ã€ç»­èˆªçŸ­è€Œçƒ¦æ¼ï¼Ÿ  \n",
      "X1 Pro æœºæ¢°é”®ç›˜ï¼Œä¸“ä¸ºè¿½æ±‚æè‡´ä½“éªŒçš„ä½ è€Œæ¥ï¼\n",
      "\n",
      "**å®šåˆ¶é’è½´ | çƒ­æ’æ‹”è®¾è®¡ | 200å°æ—¶è¶…é•¿ç»­èˆª**  \n",
      "X1 Pro é…å¤‡60gè§¦å‘å‹åŠ›çš„å®šåˆ¶é’è½´ï¼Œæ¸…è„†é¡ºæ»‘ï¼Œå›é¦ˆæ„Ÿåè¶³ï¼›æ”¯æŒçƒ­æ’æ‹”ï¼Œè½»æ¾æ›´æ¢è½´ä½“ã€‚æ­é…PBTåŒè‰²é”®å¸½ï¼Œè€ç£¨ä¸æ‰“æ²¹ï¼Œæ‰‹æ„Ÿæ›´å‡ºè‰²ã€‚å…¨é”®æ— å†²è®¾è®¡ï¼Œæ¸¸æˆåŠå…¬ä¸¤ä¸è¯¯ã€‚\n",
      "\n",
      "ä¸‰æ¨¡è¿æ¥ï¼ˆè“ç‰™5.1 / 2.4G / USB-Cï¼‰ï¼Œç¨³å®šå¿«é€Ÿå“åº”ï¼Œå…¼å®¹å¤šè®¾å¤‡ä½¿ç”¨ã€‚å†…ç½®4000mAhå¤§ç”µæ± ï¼Œç»­èˆªé•¿è¾¾200å°æ—¶ï¼Œå‘Šåˆ«é¢‘ç¹å……ç”µçƒ¦æ¼ã€‚\n",
      "\n",
      "**ç°åœ¨ä¸‹å•ç«‹äº«é™æ—¶ä¼˜æƒ ä»·ï¼š599å…ƒï¼**  \n",
      "åŸä»·699å…ƒï¼Œä»…é™å‰100åä¸‹å•ç”¨æˆ·ï¼Œé”™è¿‡ä¸å†ï¼\n",
      "\n",
      "ğŸ‘‰ **ç«‹å³æŠ¢è´­ï¼Œäº«å—é«˜æ•ˆæ‰“å­—æ–°ä½“éªŒï¼**\n",
      "\n",
      "ç¥æ‚¨å·¥ä½œæ„‰å¿«ï¼Œ  \n",
      "[æ‚¨çš„å“ç‰Œå›¢é˜Ÿ]\n",
      "{'generate': {'messages': [HumanMessage(content='**ä¸»é¢˜ï¼šé™æ—¶ç‰¹æƒ ï¼æ——èˆ°æœºæ¢°é”®ç›˜ X1 Pro ä»…éœ€599å…ƒï¼Œæ‰“å·¥äººå¿…å¤‡ç¥å™¨ï¼**\\n\\näº²çˆ±çš„ç”¨æˆ·ï¼š\\n\\nä½ æ˜¯å¦è¿˜åœ¨ä¸ºæ•²å­—å¡é¡¿ã€æ‰‹æ„Ÿç”Ÿç¡¬ã€ç»­èˆªçŸ­è€Œçƒ¦æ¼ï¼Ÿ  \\nX1 Pro æœºæ¢°é”®ç›˜ï¼Œä¸“ä¸ºè¿½æ±‚æè‡´ä½“éªŒçš„ä½ è€Œæ¥ï¼\\n\\n**å®šåˆ¶é’è½´ | çƒ­æ’æ‹”è®¾è®¡ | 200å°æ—¶è¶…é•¿ç»­èˆª**  \\nX1 Pro é…å¤‡60gè§¦å‘å‹åŠ›çš„å®šåˆ¶é’è½´ï¼Œæ¸…è„†é¡ºæ»‘ï¼Œå›é¦ˆæ„Ÿåè¶³ï¼›æ”¯æŒçƒ­æ’æ‹”ï¼Œè½»æ¾æ›´æ¢è½´ä½“ã€‚æ­é…PBTåŒè‰²é”®å¸½ï¼Œè€ç£¨ä¸æ‰“æ²¹ï¼Œæ‰‹æ„Ÿæ›´å‡ºè‰²ã€‚å…¨é”®æ— å†²è®¾è®¡ï¼Œæ¸¸æˆåŠå…¬ä¸¤ä¸è¯¯ã€‚\\n\\nä¸‰æ¨¡è¿æ¥ï¼ˆè“ç‰™5.1 / 2.4G / USB-Cï¼‰ï¼Œç¨³å®šå¿«é€Ÿå“åº”ï¼Œå…¼å®¹å¤šè®¾å¤‡ä½¿ç”¨ã€‚å†…ç½®4000mAhå¤§ç”µæ± ï¼Œç»­èˆªé•¿è¾¾200å°æ—¶ï¼Œå‘Šåˆ«é¢‘ç¹å……ç”µçƒ¦æ¼ã€‚\\n\\n**ç°åœ¨ä¸‹å•ç«‹äº«é™æ—¶ä¼˜æƒ ä»·ï¼š599å…ƒï¼**  \\nåŸä»·699å…ƒï¼Œä»…é™å‰100åä¸‹å•ç”¨æˆ·ï¼Œé”™è¿‡ä¸å†ï¼\\n\\nğŸ‘‰ **ç«‹å³æŠ¢è´­ï¼Œäº«å—é«˜æ•ˆæ‰“å­—æ–°ä½“éªŒï¼**\\n\\nç¥æ‚¨å·¥ä½œæ„‰å¿«ï¼Œ  \\n[æ‚¨çš„å“ç‰Œå›¢é˜Ÿ]', additional_kwargs={}, response_metadata={})]}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# --- 5. æ¼”ç¤ºé€‰æ‹©ç­–ç•¥ ---\n",
    "print(\"\\n### æ¼”ç¤º'é€‰æ‹©'ç­–ç•¥ ###\")\n",
    "question = \"è¯·ä¸ºæˆ‘ä»¬çš„æ——èˆ°æœºæ¢°é”®ç›˜X1 Proå†™ä¸€å°ä¿ƒé”€é‚®ä»¶ï¼Œçªå‡ºå…¶æ ¸å¿ƒä¼˜åŠ¿\"\n",
    "\n",
    "# åˆå§‹çŠ¶æ€\n",
    "initial_state = SelectState(\n",
    "    messages=[HumanMessage(content=question)],\n",
    "    context=\"\"\n",
    ")\n",
    "\n",
    "# æ‰§è¡Œå·¥ä½œæµ\n",
    "for step in select_workflow.stream(initial_state):\n",
    "    if \"__end__\" not in step:\n",
    "        print(step)\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b78e84",
   "metadata": {},
   "source": [
    "## **ç­–ç•¥ä¸‰ï¼šå‹ç¼© (Compress) - ä¸ºä¸Šä¸‹æ–‡\"ç˜¦èº«å‡è´Ÿ\"**\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³ï¼š** ä½¿ç”¨æ€»ç»“(summarization)å’Œè£å‰ª(trimming)æŠ€æœ¯å‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦ï¼ŒèŠ‚çœTokenå¹¶æé«˜æ•ˆç‡ã€‚\n",
    "\n",
    "**å®ç°ä¸¤ç§å‹ç¼©æŠ€æœ¯ï¼š**\n",
    "1. **æ€»ç»“å‹ç¼©**ï¼šå°†é•¿æ–‡æœ¬æç‚¼ä¸ºç®€æ´æ‘˜è¦\n",
    "2. **è£å‰ªå‹ç¼©**ï¼šæ™ºèƒ½ä¿ç•™å¯¹è¯ä¸­æœ€ç›¸å…³çš„éƒ¨åˆ†\n",
    "\n",
    "**åœºæ™¯æ¼”ç¤ºï¼š** æ™ºèƒ½ä½“éœ€è¦é˜…è¯»ä¸€ç¯‡é•¿æ–‡ç« å¹¶å›ç­”é—®é¢˜ï¼Œæˆ‘ä»¬é€šè¿‡æ€»ç»“å‹ç¼©æ–‡ç« å†…å®¹ï¼›åŒæ—¶å±•ç¤ºå¯¹è¯å†å²è£å‰ªæŠ€æœ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a1022bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. å‡†å¤‡é•¿æ–‡æœ¬ç¤ºä¾‹ ---\n",
    "long_article = \"\"\"\n",
    "åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‘å±•æ­£ä»¥å‰æ‰€æœªæœ‰çš„é€Ÿåº¦æ¨è¿›ã€‚2023å¹´ï¼ŒOpenAIå‘å¸ƒäº†GPT-4æ¨¡å‹ï¼Œå…¶ä¸Šä¸‹æ–‡çª—å£æ‰©å±•åˆ°32K tokensï¼Œå¤§å¤§å¢å¼ºäº†å¤„ç†é•¿æ–‡æ¡£çš„èƒ½åŠ›ã€‚éšåï¼ŒAnthropicæ¨å‡ºäº†Claude 2.1æ¨¡å‹ï¼Œæ”¯æŒ200K tokensçš„ä¸Šä¸‹æ–‡çª—å£ï¼Œåˆ›ä¸‹äº†å½“æ—¶çš„æ–°çºªå½•ã€‚\n",
    "\n",
    "ç„¶è€Œï¼Œ2024å¹´ï¼Œè¿™ä¸€çºªå½•è¢«ä¸­å›½ç§‘æŠ€å…¬å¸æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰æ‰“ç ´ã€‚ä»–ä»¬å‘å¸ƒäº†DeepSeek-R1æ¨¡å‹ï¼Œä¸ä»…æ”¯æŒ128K tokensçš„ä¸Šä¸‹æ–‡çª—å£ï¼Œè¿˜åˆ›æ–°æ€§åœ°å¼•å…¥äº†\"ä¸Šä¸‹æ–‡å‹ç¼©\"æŠ€æœ¯ã€‚è¯¥æŠ€æœ¯é€šè¿‡æ™ºèƒ½æ€»ç»“å’Œå…³é”®ä¿¡æ¯æå–ï¼Œå¯ä»¥å°†é•¿æ–‡æ¡£å‹ç¼©åˆ°åŸé•¿åº¦çš„20%-30%ï¼ŒåŒæ—¶ä¿ç•™95%ä»¥ä¸Šçš„æ ¸å¿ƒä¿¡æ¯ã€‚\n",
    "\n",
    "DeepSeek-R1çš„æŠ€æœ¯åˆ›æ–°ä¸»è¦ä½“ç°åœ¨ä¸‰ä¸ªæ–¹é¢ï¼š\n",
    "1. åˆ†å±‚æ€»ç»“æ¶æ„ï¼šæ¨¡å‹é¦–å…ˆå¯¹æ–‡æ¡£è¿›è¡Œåˆ†æ®µæ€»ç»“ï¼Œç„¶åå¯¹åˆ†æ®µæ‘˜è¦è¿›è¡ŒäºŒæ¬¡æ€»ç»“ï¼Œå½¢æˆå±‚æ¬¡åŒ–çš„å‹ç¼©ç»“æ„ã€‚\n",
    "2. è¯­ä¹‰å¯†åº¦ä¼˜åŒ–ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œæ¨¡å‹å­¦ä¼šè¯†åˆ«å¹¶ä¿ç•™ä¿¡æ¯å¯†åº¦æœ€é«˜çš„å†…å®¹ã€‚\n",
    "3. è‡ªé€‚åº”å‹ç¼©ç‡ï¼šæ ¹æ®ç”¨æˆ·ä»»åŠ¡ç±»å‹åŠ¨æ€è°ƒæ•´å‹ç¼©å¼ºåº¦ï¼Œå¹³è¡¡ä¿¡æ¯ä¿ç•™ä¸æ•ˆç‡ã€‚\n",
    "\n",
    "åœ¨å®é™…æµ‹è¯•ä¸­ï¼ŒDeepSeek-R1å¤„ç†ä¸€ç¯‡10,000å­—çš„ç§‘æŠ€è®ºæ–‡æ—¶ï¼Œå°†å…¶å‹ç¼©åˆ°1,500å­—çš„å…³é”®æ‘˜è¦ï¼ŒåŒæ—¶å‡†ç¡®å›ç­”äº†è®ºæ–‡ä¸­çš„æ ¸å¿ƒé—®é¢˜ã€‚æ›´ä»¤äººå°è±¡æ·±åˆ»çš„æ˜¯ï¼Œå‹ç¼©åçš„Tokenä½¿ç”¨é‡ä»…ä¸ºåŸå§‹çš„18%ï¼Œè€Œä»»åŠ¡å®Œæˆè´¨é‡ä»…ä¸‹é™2%ã€‚\n",
    "\n",
    "è¿™é¡¹æŠ€æœ¯çš„å•†ä¸šåº”ç”¨å‰æ™¯å¹¿é˜”ï¼š\n",
    "- æ³•å¾‹è¡Œä¸šï¼šå¿«é€Ÿåˆ†æå†—é•¿çš„æ³•å¾‹æ–‡ä»¶\n",
    "- é‡‘èé¢†åŸŸï¼šé«˜æ•ˆå¤„ç†å¹´åº¦è´¢æŠ¥å’Œæ‹›è‚¡ä¹¦\n",
    "- å­¦æœ¯ç ”ç©¶ï¼šåŠ é€Ÿæ–‡çŒ®ç»¼è¿°è¿‡ç¨‹\n",
    "- å®¢æˆ·æœåŠ¡ï¼šå¿«é€Ÿç†è§£é•¿ç¯‡å®¢æˆ·åé¦ˆ\n",
    "\n",
    "DeepSeekå›¢é˜Ÿè¡¨ç¤ºï¼Œä»–ä»¬ä¸‹ä¸€æ­¥å°†æ¢ç´¢\"åŠ¨æ€ä¸Šä¸‹æ–‡å‹ç¼©\"ï¼Œå³åœ¨å¯¹è¯è¿‡ç¨‹ä¸­å®æ—¶è°ƒæ•´å‹ç¼©ç‡ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–æ™ºèƒ½ä½“çš„é•¿æœŸè®°å¿†ç®¡ç†ã€‚\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6e07de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. å®šä¹‰å‹ç¼©å·¥å…· ---\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# æ€»ç»“å‹ç¼©å·¥å…·\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"è¯·å°†ä»¥ä¸‹æ–‡æœ¬æ€»ç»“ä¸ºä¸è¶…è¿‡{max_words}å­—çš„å…³é”®è¦ç‚¹ï¼Œä¿ç•™æ‰€æœ‰æ ¸å¿ƒæŠ€æœ¯å’Œæ•°æ®ï¼š\\n\\n{text}\"\n",
    ")\n",
    "\n",
    "summarizer_chain = (\n",
    "    summary_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# è£å‰ªå‹ç¼©å‡½æ•°\n",
    "def trim_messages(messages: List[BaseMessage], max_messages=5) -> List[BaseMessage]:\n",
    "    \"\"\"è£å‰ªå¯¹è¯å†å²ï¼Œä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€æ–°çš„å‡ æ¡æ¶ˆæ¯\"\"\"\n",
    "    # å§‹ç»ˆä¿ç•™ç¬¬ä¸€æ¡ç³»ç»Ÿæ¶ˆæ¯\n",
    "    system_message = messages[0] if messages and isinstance(messages[0], SystemMessage) else None\n",
    "    \n",
    "    # ä¿ç•™æœ€è¿‘çš„max_messagesæ¡æ¶ˆæ¯ï¼ˆæ’é™¤ç³»ç»Ÿæ¶ˆæ¯ï¼‰\n",
    "    recent_messages = messages[-max_messages:] if len(messages) > 1 else messages\n",
    "    \n",
    "    # é‡æ–°ç»„åˆ\n",
    "    trimmed = []\n",
    "    if system_message:\n",
    "        trimmed.append(system_message)\n",
    "    trimmed.extend(recent_messages)\n",
    "    \n",
    "    return trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "59937644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. å®šä¹‰çŠ¶æ€å’ŒèŠ‚ç‚¹ ---\n",
    "class CompressState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    original_text: str  # åŸå§‹é•¿æ–‡æœ¬\n",
    "    compressed_text: str  # å‹ç¼©åçš„æ–‡æœ¬\n",
    "    token_savings: int  # èŠ‚çœçš„Tokenæ•°é‡\n",
    "\n",
    "def compress_long_text(state: CompressState):\n",
    "    \"\"\"æ€»ç»“å‹ç¼©èŠ‚ç‚¹ï¼šå°†é•¿æ–‡æœ¬å‹ç¼©ä¸ºæ‘˜è¦\"\"\"\n",
    "    print(\"\\n--- COMPRESSING LONG TEXT ---\")\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # ä»ç”¨æˆ·æ¶ˆæ¯ä¸­æå–é—®é¢˜\n",
    "    question = last_message.content\n",
    "    \n",
    "    # å‹ç¼©é•¿æ–‡æœ¬\n",
    "    summary = summarizer_chain.invoke({\"text\": state[\"original_text\"], \"max_words\": 300})\n",
    "    \n",
    "    # è®¡ç®—TokenèŠ‚çœ\n",
    "    orig_tokens = len(encoding.encode(state[\"original_text\"]))\n",
    "    comp_tokens = len(encoding.encode(summary))\n",
    "    savings = orig_tokens - comp_tokens\n",
    "    \n",
    "    print(f\"ğŸ“‰ æ–‡æœ¬å‹ç¼©: {orig_tokens} tokens â†’ {comp_tokens} tokens (èŠ‚çœ {savings} tokens)\")\n",
    "    print(f\"ğŸ“ å‹ç¼©æ‘˜è¦:\\n{summary[:200]}...\")\n",
    "    \n",
    "    # æ›´æ–°çŠ¶æ€\n",
    "    return {\n",
    "        \"compressed_text\": summary,\n",
    "        \"token_savings\": savings,\n",
    "        \"messages\": [HumanMessage(content=f\"åŸºäºä»¥ä¸‹æ‘˜è¦å›ç­”é—®é¢˜:\\n{summary}\\n\\né—®é¢˜: {question}\")]\n",
    "    }\n",
    "\n",
    "def answer_with_compressed_text(state: CompressState):\n",
    "    \"\"\"å›ç­”èŠ‚ç‚¹ï¼šåŸºäºå‹ç¼©æ–‡æœ¬å›ç­”é—®é¢˜\"\"\"\n",
    "    print(\"\\n--- ANSWERING WITH COMPRESSED TEXT ---\")\n",
    "    \n",
    "    # è°ƒç”¨æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    answer = response.content\n",
    "    \n",
    "    print(f\"ğŸ’¡ ç”Ÿæˆçš„å›ç­”: {answer[:200]}...\")\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def trim_context(state: CompressState):\n",
    "    \"\"\"è£å‰ªèŠ‚ç‚¹ï¼šå‹ç¼©å¯¹è¯å†å²\"\"\"\n",
    "    print(\"\\n--- TRIMMING CONTEXT ---\")\n",
    "    \n",
    "    # è®¡ç®—è£å‰ªå‰çš„Token\n",
    "    all_messages = \"\".join(m.content for m in state[\"messages\"])\n",
    "    before_tokens = len(encoding.encode(all_messages))\n",
    "    \n",
    "    # æ‰§è¡Œè£å‰ª\n",
    "    trimmed_messages = trim_messages(state[\"messages\"], max_messages=3)\n",
    "    \n",
    "    # è®¡ç®—è£å‰ªåçš„Token\n",
    "    trimmed_content = \"\".join(m.content for m in trimmed_messages)\n",
    "    after_tokens = len(encoding.encode(trimmed_content))\n",
    "    savings = before_tokens - after_tokens\n",
    "    \n",
    "    print(f\"âœ‚ï¸ è£å‰ªå†å²: {len(state['messages'])}æ¡ â†’ {len(trimmed_messages)}æ¡æ¶ˆæ¯\")\n",
    "    print(f\"ğŸ“‰ TokenèŠ‚çœ: {savings} (åŸå§‹: {before_tokens} -> è£å‰ªå: {after_tokens})\")\n",
    "    \n",
    "    return {\"messages\": trimmed_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "047924db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. æ„å»ºå‹ç¼©ç­–ç•¥å›¾ ---\n",
    "compress_graph = StateGraph(CompressState)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "compress_graph.add_node(\"compress\", compress_long_text)\n",
    "compress_graph.add_node(\"answer\", answer_with_compressed_text)\n",
    "compress_graph.add_node(\"trim\", trim_context)\n",
    "\n",
    "# è®¾ç½®å…¥å£ç‚¹\n",
    "compress_graph.set_entry_point(\"compress\")\n",
    "\n",
    "# æ·»åŠ è¾¹\n",
    "compress_graph.add_edge(\"compress\", \"answer\")\n",
    "compress_graph.add_edge(\"answer\", END)\n",
    "\n",
    "# æ·»åŠ æ¡ä»¶è¾¹ç”¨äºè£å‰ª\n",
    "def should_trim(state: CompressState):\n",
    "    \"\"\"å½“æ¶ˆæ¯è¶…è¿‡5æ¡æ—¶è§¦å‘è£å‰ª\"\"\"\n",
    "    if len(state[\"messages\"]) > 5:\n",
    "        return \"trim\"\n",
    "    return END\n",
    "\n",
    "compress_graph.add_conditional_edges(\"answer\", should_trim, {\"trim\": \"trim\", END: END})\n",
    "compress_graph.add_edge(\"trim\", END)\n",
    "\n",
    "# ç¼–è¯‘å›¾\n",
    "compress_workflow = compress_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bd584237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### æ¼”ç¤º'æ€»ç»“å‹ç¼©'æŠ€æœ¯ ###\n",
      "\n",
      "--- COMPRESSING LONG TEXT ---\n",
      "ğŸ“‰ æ–‡æœ¬å‹ç¼©: 682 tokens â†’ 275 tokens (èŠ‚çœ 407 tokens)\n",
      "ğŸ“ å‹ç¼©æ‘˜è¦:\n",
      "2023å¹´ï¼ŒGPT-4æ”¯æŒ32K tokensä¸Šä¸‹æ–‡çª—å£ï¼›2024å¹´ï¼ŒClaude 2.1æ‰©å±•è‡³200K tokensã€‚åŒå¹´ï¼Œä¸­å›½å…¬å¸æ·±åº¦æ±‚ç´¢å‘å¸ƒDeepSeek-R1æ¨¡å‹ï¼Œæ”¯æŒ128K tokensï¼Œå¹¶å¼•å…¥â€œä¸Šä¸‹æ–‡å‹ç¼©â€æŠ€æœ¯ï¼Œå¯å°†é•¿æ–‡æ¡£å‹ç¼©è‡³åŸé•¿åº¦çš„20%-30%ï¼Œä¿ç•™95%ä»¥ä¸Šæ ¸å¿ƒä¿¡æ¯ã€‚\n",
      "\n",
      "å…¶æŠ€æœ¯åˆ›æ–°åŒ…æ‹¬ï¼šåˆ†å±‚æ€»ç»“æ¶æ„ã€è¯­ä¹‰å¯†åº¦ä¼˜åŒ–å’Œè‡ªé€‚åº”å‹ç¼©ç‡ã€‚æµ‹è¯•æ˜¾ç¤ºï¼Œå¤„ç†ä¸€ç¯‡10,000å­—è®ºæ–‡æ—¶ï¼Œæ¨¡å‹å‹...\n",
      "{'compress': {'compressed_text': '2023å¹´ï¼ŒGPT-4æ”¯æŒ32K tokensä¸Šä¸‹æ–‡çª—å£ï¼›2024å¹´ï¼ŒClaude 2.1æ‰©å±•è‡³200K tokensã€‚åŒå¹´ï¼Œä¸­å›½å…¬å¸æ·±åº¦æ±‚ç´¢å‘å¸ƒDeepSeek-R1æ¨¡å‹ï¼Œæ”¯æŒ128K tokensï¼Œå¹¶å¼•å…¥â€œä¸Šä¸‹æ–‡å‹ç¼©â€æŠ€æœ¯ï¼Œå¯å°†é•¿æ–‡æ¡£å‹ç¼©è‡³åŸé•¿åº¦çš„20%-30%ï¼Œä¿ç•™95%ä»¥ä¸Šæ ¸å¿ƒä¿¡æ¯ã€‚\\n\\nå…¶æŠ€æœ¯åˆ›æ–°åŒ…æ‹¬ï¼šåˆ†å±‚æ€»ç»“æ¶æ„ã€è¯­ä¹‰å¯†åº¦ä¼˜åŒ–å’Œè‡ªé€‚åº”å‹ç¼©ç‡ã€‚æµ‹è¯•æ˜¾ç¤ºï¼Œå¤„ç†ä¸€ç¯‡10,000å­—è®ºæ–‡æ—¶ï¼Œæ¨¡å‹å‹ç¼©è‡³1,500å­—ï¼Œä»…ä½¿ç”¨18%çš„åŸå§‹Tokenï¼Œä»»åŠ¡è´¨é‡ä¸‹é™ä»…2%ã€‚\\n\\nè¯¥æŠ€æœ¯é€‚ç”¨äºæ³•å¾‹ã€é‡‘èã€å­¦æœ¯åŠå®¢æˆ·æœåŠ¡ç­‰é¢†åŸŸã€‚å›¢é˜Ÿæœªæ¥è®¡åˆ’æ¢ç´¢â€œåŠ¨æ€ä¸Šä¸‹æ–‡å‹ç¼©â€ï¼Œå®ç°å¯¹è¯ä¸­çš„å®æ—¶å‹ç¼©ç‡è°ƒæ•´ï¼Œæå‡æ™ºèƒ½ä½“é•¿æœŸè®°å¿†ç®¡ç†èƒ½åŠ›ã€‚', 'token_savings': 407, 'messages': [HumanMessage(content='åŸºäºä»¥ä¸‹æ‘˜è¦å›ç­”é—®é¢˜:\\n2023å¹´ï¼ŒGPT-4æ”¯æŒ32K tokensä¸Šä¸‹æ–‡çª—å£ï¼›2024å¹´ï¼ŒClaude 2.1æ‰©å±•è‡³200K tokensã€‚åŒå¹´ï¼Œä¸­å›½å…¬å¸æ·±åº¦æ±‚ç´¢å‘å¸ƒDeepSeek-R1æ¨¡å‹ï¼Œæ”¯æŒ128K tokensï¼Œå¹¶å¼•å…¥â€œä¸Šä¸‹æ–‡å‹ç¼©â€æŠ€æœ¯ï¼Œå¯å°†é•¿æ–‡æ¡£å‹ç¼©è‡³åŸé•¿åº¦çš„20%-30%ï¼Œä¿ç•™95%ä»¥ä¸Šæ ¸å¿ƒä¿¡æ¯ã€‚\\n\\nå…¶æŠ€æœ¯åˆ›æ–°åŒ…æ‹¬ï¼šåˆ†å±‚æ€»ç»“æ¶æ„ã€è¯­ä¹‰å¯†åº¦ä¼˜åŒ–å’Œè‡ªé€‚åº”å‹ç¼©ç‡ã€‚æµ‹è¯•æ˜¾ç¤ºï¼Œå¤„ç†ä¸€ç¯‡10,000å­—è®ºæ–‡æ—¶ï¼Œæ¨¡å‹å‹ç¼©è‡³1,500å­—ï¼Œä»…ä½¿ç”¨18%çš„åŸå§‹Tokenï¼Œä»»åŠ¡è´¨é‡ä¸‹é™ä»…2%ã€‚\\n\\nè¯¥æŠ€æœ¯é€‚ç”¨äºæ³•å¾‹ã€é‡‘èã€å­¦æœ¯åŠå®¢æˆ·æœåŠ¡ç­‰é¢†åŸŸã€‚å›¢é˜Ÿæœªæ¥è®¡åˆ’æ¢ç´¢â€œåŠ¨æ€ä¸Šä¸‹æ–‡å‹ç¼©â€ï¼Œå®ç°å¯¹è¯ä¸­çš„å®æ—¶å‹ç¼©ç‡è°ƒæ•´ï¼Œæå‡æ™ºèƒ½ä½“é•¿æœŸè®°å¿†ç®¡ç†èƒ½åŠ›ã€‚\\n\\né—®é¢˜: DeepSeek-R1åœ¨æ–‡æœ¬å‹ç¼©æ–¹é¢æœ‰å“ªäº›æŠ€æœ¯åˆ›æ–°ï¼Ÿå‹ç¼©æ•ˆæœå¦‚ä½•ï¼Ÿ', additional_kwargs={}, response_metadata={})]}}\n",
      "---\n",
      "\n",
      "--- ANSWERING WITH COMPRESSED TEXT ---\n",
      "ğŸ’¡ ç”Ÿæˆçš„å›ç­”: DeepSeek-R1åœ¨æ–‡æœ¬å‹ç¼©æ–¹é¢å¼•å…¥äº†ä»¥ä¸‹ä¸‰å¤§æŠ€æœ¯åˆ›æ–°ï¼š\n",
      "\n",
      "1. **åˆ†å±‚æ€»ç»“æ¶æ„**ï¼šè¯¥æŠ€æœ¯é€šè¿‡å¤šå±‚æ¬¡çš„ä¿¡æ¯æå–å’Œæ•´åˆï¼Œé€æ­¥æç‚¼å‡ºæ–‡æœ¬çš„æ ¸å¿ƒå†…å®¹ã€‚è¿™ç§æ–¹å¼å¯ä»¥æœ‰æ•ˆä¿ç•™å…³é”®ä¿¡æ¯ï¼ŒåŒæ—¶å»é™¤å†—ä½™éƒ¨åˆ†ã€‚\n",
      "\n",
      "2. **è¯­ä¹‰å¯†åº¦ä¼˜åŒ–**ï¼šæ¨¡å‹é€šè¿‡å¯¹è¯­ä¹‰çš„æ·±å…¥ç†è§£ï¼Œä¼˜å…ˆä¿ç•™é«˜ä»·å€¼çš„è¯­ä¹‰å•å…ƒï¼Œä»è€Œæå‡å‹ç¼©åæ–‡æœ¬çš„ä¿¡æ¯å¯†åº¦ï¼Œç¡®ä¿æ ¸å¿ƒæ„ä¹‰ä¸ä¸¢å¤±ã€‚\n",
      "\n",
      "3. **è‡ªé€‚åº”å‹ç¼©ç‡**ï¼šæ ¹æ®è¾“å…¥æ–‡æœ¬çš„ç‰¹ç‚¹å’Œç”¨æˆ·éœ€æ±‚ï¼Œè‡ªåŠ¨...\n",
      "{'answer': {'messages': [AIMessage(content='DeepSeek-R1åœ¨æ–‡æœ¬å‹ç¼©æ–¹é¢å¼•å…¥äº†ä»¥ä¸‹ä¸‰å¤§æŠ€æœ¯åˆ›æ–°ï¼š\\n\\n1. **åˆ†å±‚æ€»ç»“æ¶æ„**ï¼šè¯¥æŠ€æœ¯é€šè¿‡å¤šå±‚æ¬¡çš„ä¿¡æ¯æå–å’Œæ•´åˆï¼Œé€æ­¥æç‚¼å‡ºæ–‡æœ¬çš„æ ¸å¿ƒå†…å®¹ã€‚è¿™ç§æ–¹å¼å¯ä»¥æœ‰æ•ˆä¿ç•™å…³é”®ä¿¡æ¯ï¼ŒåŒæ—¶å»é™¤å†—ä½™éƒ¨åˆ†ã€‚\\n\\n2. **è¯­ä¹‰å¯†åº¦ä¼˜åŒ–**ï¼šæ¨¡å‹é€šè¿‡å¯¹è¯­ä¹‰çš„æ·±å…¥ç†è§£ï¼Œä¼˜å…ˆä¿ç•™é«˜ä»·å€¼çš„è¯­ä¹‰å•å…ƒï¼Œä»è€Œæå‡å‹ç¼©åæ–‡æœ¬çš„ä¿¡æ¯å¯†åº¦ï¼Œç¡®ä¿æ ¸å¿ƒæ„ä¹‰ä¸ä¸¢å¤±ã€‚\\n\\n3. **è‡ªé€‚åº”å‹ç¼©ç‡**ï¼šæ ¹æ®è¾“å…¥æ–‡æœ¬çš„ç‰¹ç‚¹å’Œç”¨æˆ·éœ€æ±‚ï¼Œè‡ªåŠ¨è°ƒæ•´å‹ç¼©æ¯”ä¾‹ï¼Œåœ¨ä¿è¯ä¿¡æ¯å®Œæ•´æ€§çš„å‰æä¸‹ï¼Œå®ç°çµæ´»é«˜æ•ˆçš„å‹ç¼©æ•ˆæœã€‚\\n\\n---\\n\\n**å‹ç¼©æ•ˆæœæ–¹é¢**ï¼Œæµ‹è¯•æ•°æ®æ˜¾ç¤ºï¼š\\n\\n- DeepSeek-R1èƒ½å¤Ÿå°†é•¿æ–‡æ¡£å‹ç¼©è‡³åŸé•¿åº¦çš„**20%-30%**ã€‚\\n- åœ¨å¤„ç†ä¸€ç¯‡10,000å­—è®ºæ–‡æ—¶ï¼Œå‹ç¼©åçš„ç»“æœä¸º1,500å­—ï¼Œä»…ä½¿ç”¨åŸå§‹Tokençš„**18%**ã€‚\\n- å‹ç¼©åä»èƒ½ä¿ç•™**95%ä»¥ä¸Šçš„æ ¸å¿ƒä¿¡æ¯**ã€‚\\n- ä»»åŠ¡è´¨é‡ï¼ˆå¦‚æ‘˜è¦å‡†ç¡®æ€§ã€å…³é”®ä¿¡æ¯å®Œæ•´æ€§ï¼‰ä»…ä¸‹é™**2%**ï¼Œè¯´æ˜å…¶å‹ç¼©èƒ½åŠ›å¯¹ä»»åŠ¡æ€§èƒ½å½±å“æå°ã€‚\\n\\nç»¼ä¸Šæ‰€è¿°ï¼ŒDeepSeek-R1åœ¨æ–‡æœ¬å‹ç¼©æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå…·å¤‡é«˜æ•ˆã€ç²¾å‡†ã€ä½æŸç­‰ä¼˜åŠ¿ï¼Œé€‚ç”¨äºæ³•å¾‹ã€é‡‘èã€å­¦æœ¯åŠå®¢æˆ·æœåŠ¡ç­‰å¤šä¸ªé¢†åŸŸã€‚', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-32b'}, id='run--97c14254-311e-400c-98e4-a51bddb36adc-0', usage_metadata={'input_tokens': 249, 'output_tokens': 281, 'total_tokens': 530, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# --- 5. æ¼”ç¤ºæ€»ç»“å‹ç¼© ---\n",
    "print(\"\\n### æ¼”ç¤º'æ€»ç»“å‹ç¼©'æŠ€æœ¯ ###\")\n",
    "question = \"DeepSeek-R1åœ¨æ–‡æœ¬å‹ç¼©æ–¹é¢æœ‰å“ªäº›æŠ€æœ¯åˆ›æ–°ï¼Ÿå‹ç¼©æ•ˆæœå¦‚ä½•ï¼Ÿ\"\n",
    "\n",
    "# åˆå§‹çŠ¶æ€\n",
    "initial_state = CompressState(\n",
    "    messages=[SystemMessage(content=\"ä½ æ˜¯ä¸€ä¸ªAIæŠ€æœ¯åˆ†æå¸ˆ\"), HumanMessage(content=question)],\n",
    "    original_text=long_article,\n",
    "    compressed_text=\"\",\n",
    "    token_savings=0\n",
    ")\n",
    "\n",
    "# æ‰§è¡Œå·¥ä½œæµ\n",
    "for step in compress_workflow.stream(initial_state):\n",
    "    if \"__end__\" not in step:\n",
    "        print(step)\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "77dc2c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### æ¼”ç¤º'è£å‰ªå‹ç¼©'æŠ€æœ¯ ###\n",
      "\n",
      "--- TRIMMING CONTEXT ---\n",
      "âœ‚ï¸ è£å‰ªå†å²: 10æ¡ â†’ 4æ¡æ¶ˆæ¯\n",
      "ğŸ“‰ TokenèŠ‚çœ: 92 (åŸå§‹: 150 -> è£å‰ªå: 58)\n",
      "\n",
      "è£å‰ªå‰æ¶ˆæ¯:\n",
      "ğŸ¤– ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—…è¡ŒåŠ©æ‰‹\n",
      "ğŸ‘¤ æˆ‘æƒ³è®¡åˆ’ä¸€æ¬¡å»æ—¥æœ¬çš„æ—…è¡Œ\n",
      "ğŸ‘¤ æ—¶é—´å¤§æ¦‚æ˜¯æ˜å¹´3æœˆä¸‹æ—¬ï¼Œ10å¤©å·¦å³\n",
      "ğŸ‘¤ æˆ‘å¯¹äº¬éƒ½çš„æ–‡åŒ–æ™¯ç‚¹ç‰¹åˆ«æ„Ÿå…´è¶£\n",
      "ğŸ‘¤ å¦å¤–ä¹Ÿæƒ³ä½“éªŒä¸€ä¸‹ä¸œäº¬çš„ç°ä»£åŒ–éƒ½å¸‚\n",
      "ğŸ‘¤ é¢„ç®—æ–¹é¢å¸Œæœ›æ§åˆ¶åœ¨2ä¸‡å…ƒä»¥å†…\n",
      "ğŸ‘¤ è¯·å¸®æˆ‘è§„åˆ’ä¸€ä¸ªè¡Œç¨‹\n",
      "ğŸ‘¤ å¯¹äº†ï¼Œæˆ‘è¿˜æƒ³ä½“éªŒä¸€æ¬¡æ¸©æ³‰æ—…é¦†\n",
      "ğŸ‘¤ æœ€å¥½æ˜¯é‚£ç§ä¼ ç»Ÿçš„æ—¥å¼æ—…é¦†\n",
      "ğŸ‘¤ ç°åœ¨è¯·ç»™æˆ‘å…·ä½“çš„è¡Œç¨‹å»ºè®®\n",
      "\n",
      "è£å‰ªåæ¶ˆæ¯:\n",
      "ğŸ¤– ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—…è¡ŒåŠ©æ‰‹\n",
      "ğŸ‘¤ å¯¹äº†ï¼Œæˆ‘è¿˜æƒ³ä½“éªŒä¸€æ¬¡æ¸©æ³‰æ—…é¦†\n",
      "ğŸ‘¤ æœ€å¥½æ˜¯é‚£ç§ä¼ ç»Ÿçš„æ—¥å¼æ—…é¦†\n",
      "ğŸ‘¤ ç°åœ¨è¯·ç»™æˆ‘å…·ä½“çš„è¡Œç¨‹å»ºè®®\n"
     ]
    }
   ],
   "source": [
    "# --- 6. æ¼”ç¤ºå¯¹è¯å†å²è£å‰ª ---\n",
    "print(\"\\n### æ¼”ç¤º'è£å‰ªå‹ç¼©'æŠ€æœ¯ ###\")\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªé•¿å¯¹è¯å†å²\n",
    "long_chat_history = [\n",
    "    SystemMessage(content=\"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—…è¡ŒåŠ©æ‰‹\"),\n",
    "    HumanMessage(content=\"æˆ‘æƒ³è®¡åˆ’ä¸€æ¬¡å»æ—¥æœ¬çš„æ—…è¡Œ\"),\n",
    "    HumanMessage(content=\"æ—¶é—´å¤§æ¦‚æ˜¯æ˜å¹´3æœˆä¸‹æ—¬ï¼Œ10å¤©å·¦å³\"),\n",
    "    HumanMessage(content=\"æˆ‘å¯¹äº¬éƒ½çš„æ–‡åŒ–æ™¯ç‚¹ç‰¹åˆ«æ„Ÿå…´è¶£\"),\n",
    "    HumanMessage(content=\"å¦å¤–ä¹Ÿæƒ³ä½“éªŒä¸€ä¸‹ä¸œäº¬çš„ç°ä»£åŒ–éƒ½å¸‚\"),\n",
    "    HumanMessage(content=\"é¢„ç®—æ–¹é¢å¸Œæœ›æ§åˆ¶åœ¨2ä¸‡å…ƒä»¥å†…\"),\n",
    "    HumanMessage(content=\"è¯·å¸®æˆ‘è§„åˆ’ä¸€ä¸ªè¡Œç¨‹\"),\n",
    "    HumanMessage(content=\"å¯¹äº†ï¼Œæˆ‘è¿˜æƒ³ä½“éªŒä¸€æ¬¡æ¸©æ³‰æ—…é¦†\"),\n",
    "    HumanMessage(content=\"æœ€å¥½æ˜¯é‚£ç§ä¼ ç»Ÿçš„æ—¥å¼æ—…é¦†\"),\n",
    "    HumanMessage(content=\"ç°åœ¨è¯·ç»™æˆ‘å…·ä½“çš„è¡Œç¨‹å»ºè®®\")\n",
    "]\n",
    "\n",
    "# åˆå§‹çŠ¶æ€ï¼ˆæ— æ–‡æœ¬å‹ç¼©ï¼‰\n",
    "trim_demo_state = CompressState(\n",
    "    messages=long_chat_history,\n",
    "    original_text=\"\",\n",
    "    compressed_text=\"\",\n",
    "    token_savings=0\n",
    ")\n",
    "\n",
    "# æ‰§è¡Œè£å‰ª\n",
    "trimmed_state = trim_context(trim_demo_state)\n",
    "\n",
    "# æ˜¾ç¤ºè£å‰ªæ•ˆæœ\n",
    "print(\"\\nè£å‰ªå‰æ¶ˆæ¯:\")\n",
    "for i, msg in enumerate(long_chat_history):\n",
    "    prefix = \"ğŸ¤–\" if isinstance(msg, SystemMessage) else \"ğŸ‘¤\"\n",
    "    print(f\"{prefix} {msg.content[:50]}{'...' if len(msg.content) > 50 else ''}\")\n",
    "\n",
    "print(\"\\nè£å‰ªåæ¶ˆæ¯:\")\n",
    "for i, msg in enumerate(trimmed_state['messages']):\n",
    "    prefix = \"ğŸ¤–\" if isinstance(msg, SystemMessage) else \"ğŸ‘¤\"\n",
    "    print(f\"{prefix} {msg.content[:50]}{'...' if len(msg.content) > 50 else ''}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa94b02",
   "metadata": {},
   "source": [
    "## **ç­–ç•¥å››ï¼šéš”ç¦» (Isolate) - \"åˆ†è€Œæ²»ä¹‹\"çš„æ¶æ„æ™ºæ…§**\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³ï¼š** å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼Œç”±ä¸“é—¨çš„æ™ºèƒ½ä½“åœ¨éš”ç¦»ç¯å¢ƒä¸­å¤„ç†ï¼Œé¿å…ä¸Šä¸‹æ–‡æ±¡æŸ“ã€‚\n",
    "\n",
    "**å®ç°å¤šæ™ºèƒ½ä½“æ¶æ„ï¼š** åˆ›å»ºä¸“å®¶æ™ºèƒ½ä½“å›¢é˜Ÿï¼ˆåˆ†æå¸ˆ+æ–‡æ¡ˆï¼‰\n",
    "\n",
    "**åœºæ™¯æ¼”ç¤ºï¼š** ç”¨æˆ·ä¸Šä¼ é”€å”®æ•°æ®CSVï¼Œè¦æ±‚åˆ†æé”€å”®å† å†›å¹¶æ’°å†™è¥é”€æ–‡æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ca6ab70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. å‡†å¤‡æ•°æ® ---\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# åˆ›å»ºç¤ºä¾‹é”€å”®æ•°æ®CSV\n",
    "sales_data = \"\"\"\n",
    "æ—¥æœŸ,äº§å“,é”€å”®é¢,é”€å”®é‡\n",
    "2024-01-01,æœºæ¢°é”®ç›˜,12800,32\n",
    "2024-01-01,æ¸¸æˆé¼ æ ‡,9800,49\n",
    "2024-01-02,æœºæ¢°é”®ç›˜,14500,36\n",
    "2024-01-02,æ¸¸æˆé¼ æ ‡,10200,51\n",
    "2024-01-03,æœºæ¢°é”®ç›˜,16200,40\n",
    "2024-01-03,æ¸¸æˆé¼ æ ‡,10800,54\n",
    "2024-01-04,æœºæ¢°é”®ç›˜,13800,34\n",
    "2024-01-04,æ¸¸æˆé¼ æ ‡,11200,56\n",
    "2024-01-05,æœºæ¢°é”®ç›˜,17500,42\n",
    "2024-01-05,æ¸¸æˆé¼ æ ‡,11800,59\n",
    "\"\"\"\n",
    "\n",
    "# ä¿å­˜ä¸ºCSVæ–‡ä»¶\n",
    "with open(\"sales_data.csv\", \"w\") as f:\n",
    "    f.write(sales_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fd1b3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. å®šä¹‰ä¸“å®¶æ™ºèƒ½ä½“ ---\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# åˆ†æå¸ˆæ™ºèƒ½ä½“ï¼ˆç›´æ¥è¿”å›é¢„è®¾ç»“æœï¼‰\n",
    "def analyst_agent(data, question):\n",
    "    \"\"\"æ¨¡æ‹Ÿåˆ†æå¸ˆæ™ºèƒ½ä½“çš„å“åº”\"\"\"\n",
    "    print(\"ğŸ§  åˆ†æå¸ˆæ™ºèƒ½ä½“è¢«è°ƒç”¨\")\n",
    "    print(f\"é—®é¢˜: {question}\")\n",
    "    # æ¨¡æ‹Ÿåˆ†æç»“æœï¼ˆå®é™…åº”ä»CSVè®¡ç®—å¾—å‡ºï¼‰\n",
    "    return \"æœºæ¢°é”®ç›˜,84800\"\n",
    "\n",
    "# æ–‡æ¡ˆæ™ºèƒ½ä½“\n",
    "writer_prompt = ChatPromptTemplate.from_template(\n",
    "    \"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šè¥é”€æ–‡æ¡ˆã€‚è¯·åŸºäºä»¥ä¸‹äº§å“ä¿¡æ¯æ’°å†™æ–‡æ¡ˆ:\\n\"\n",
    "    \"äº§å“åç§°: {product}\\n\"\n",
    "    \"å…³é”®å–ç‚¹: {key_points}\\n\"\n",
    "    \"è¦æ±‚:\\n\"\n",
    "    \"- çªå‡ºäº§å“ä¼˜åŠ¿\\n\"\n",
    "    \"- åŒ…å«è¡ŒåŠ¨å¬å”¤\\n\"\n",
    "    \"- ä¸è¶…è¿‡200å­—\\n\"\n",
    "    \"æ–‡æ¡ˆ:\"\n",
    ")\n",
    "writer_agent = writer_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5334c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. å®šä¹‰å·¥å…· ---\n",
    "@tool\n",
    "def analyze_sales_data(question: str) -> str:\n",
    "    \"\"\"æ¨¡æ‹Ÿåˆ†æé”€å”®æ•°æ®ï¼ˆæ— éœ€æ²™ç›’ï¼‰\"\"\"\n",
    "    print(\"ğŸ“Š ä½¿ç”¨é¢„è®¾åˆ†æç»“æœ\")\n",
    "    return \"æœºæ¢°é”®ç›˜,84800\"\n",
    "\n",
    "@tool\n",
    "def write_marketing_copy(product: str, key_points: str) -> str:\n",
    "    \"\"\"ä¸ºæŒ‡å®šäº§å“æ’°å†™è¥é”€æ–‡æ¡ˆ\"\"\"\n",
    "    print(f\"ğŸ“ æ’°å†™æ–‡æ¡ˆ: {product} - {key_points[:50]}...\")\n",
    "    return writer_agent.invoke({\"product\": product, \"key_points\": key_points})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ea160988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. å®šä¹‰å¤šæ™ºèƒ½ä½“çŠ¶æ€ ---\n",
    "class ManagerState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    task: str\n",
    "    analysis_result: str\n",
    "    final_output: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3badd596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. æ„å»ºå¤šæ™ºèƒ½ä½“å›¾ ---\n",
    "# åˆ›å»ºå·¥å…·èŠ‚ç‚¹\n",
    "tools = [analyze_sales_data, write_marketing_copy]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# ç»‘å®šå·¥å…·çš„æ¨¡å‹\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "def manager_node(state: ManagerState):\n",
    "    \"\"\"ç®¡ç†æ™ºèƒ½ä½“ï¼šåˆ†è§£ä»»åŠ¡å¹¶è°ƒç”¨ä¸“å®¶\"\"\"\n",
    "    print(\"\\n--- MANAGER AGENT ---\")\n",
    "    # é¦–æ¬¡è°ƒç”¨\n",
    "    if not state.get(\"analysis_result\"):\n",
    "        print(f\"ğŸ“‹ ä»»åŠ¡åˆ†è§£: åˆ†æé”€å”®æ•°æ® â†’ æ’°å†™æ–‡æ¡ˆ\")\n",
    "        # åˆ›å»ºæŒ‡ä»¤\n",
    "        instruction = (\n",
    "            f\"ç”¨æˆ·ä»»åŠ¡: {state['task']}\\n\"\n",
    "            \"è¯·å…ˆåˆ†æé”€å”®æ•°æ®æ‰¾å‡ºé”€å”®é¢æœ€é«˜çš„äº§å“ï¼Œç„¶åä¸ºè¯¥äº§å“æ’°å†™è¥é”€æ–‡æ¡ˆã€‚\"\n",
    "            \"ä½¿ç”¨å·¥å…·å®Œæˆåˆ†ææ­¥éª¤ã€‚\"\n",
    "        )\n",
    "        # è°ƒç”¨æ¨¡å‹\n",
    "        response = model_with_tools.invoke([HumanMessage(content=instruction)])\n",
    "        return {\"messages\": [response]}\n",
    "    # å·²æœ‰åˆ†æç»“æœï¼Œè¿›è¡Œä¸‹ä¸€æ­¥\n",
    "    else:\n",
    "        print(f\"ğŸ“‹ ä»»åŠ¡åˆ†è§£: åŸºäºåˆ†æç»“æœæ’°å†™æ–‡æ¡ˆ\")\n",
    "        instruction = (\n",
    "            f\"åˆ†æç»“æœ: {state['analysis_result']}\\n\"\n",
    "            \"è¯·ä¸ºè¿™ä¸ªäº§å“æ’°å†™è¥é”€æ–‡æ¡ˆã€‚\"\n",
    "        )\n",
    "        response = model_with_tools.invoke([HumanMessage(content=instruction)])\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "def tool_node_simple(state: ManagerState):\n",
    "    \"\"\"ç®€åŒ–ç‰ˆå·¥å…·æ‰§è¡ŒèŠ‚ç‚¹\"\"\"\n",
    "    print(\"\\n--- TOOL EXECUTION ---\")\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # æ‰§è¡Œå·¥å…·\n",
    "    tool_messages = tool_node.invoke([last_message])\n",
    "    \n",
    "    # å¤„ç†ç»“æœ\n",
    "    if \"analyze_sales_data\" in last_message.content:\n",
    "        result = tool_messages[0].content\n",
    "        print(f\"ğŸ” åˆ†æç»“æœ: {result}\")\n",
    "        return {\"analysis_result\": result}\n",
    "    elif \"write_marketing_copy\" in last_message.content:\n",
    "        copy = tool_messages[0].content\n",
    "        print(f\"ğŸ“„ æ–‡æ¡ˆç»“æœ: {copy[:100]}...\")\n",
    "        return {\"final_output\": copy}\n",
    "    \n",
    "    return {\"messages\": tool_messages}\n",
    "\n",
    "def should_continue(state: ManagerState):\n",
    "    \"\"\"æ¡ä»¶è·¯ç”±ï¼šåˆ¤æ–­ä¸‹ä¸€æ­¥\"\"\"\n",
    "    if state.get(\"final_output\"):\n",
    "        return END\n",
    "    if state.get(\"analysis_result\") and not state.get(\"final_output\"):\n",
    "        return \"manager\"  # è¿”å›ç®¡ç†æ™ºèƒ½ä½“è¿›è¡Œä¸‹ä¸€æ­¥\n",
    "    return \"action\"  # ç»§ç»­æ‰§è¡Œå·¥å…·\n",
    "\n",
    "# æ„å»ºå›¾\n",
    "isolate_graph = StateGraph(ManagerState)\n",
    "isolate_graph.add_node(\"manager\", manager_node)\n",
    "isolate_graph.add_node(\"action\", tool_node_simple)\n",
    "isolate_graph.set_entry_point(\"manager\")\n",
    "isolate_graph.add_conditional_edges(\n",
    "    \"manager\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"action\": \"action\",\n",
    "        \"manager\": \"manager\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "isolate_graph.add_edge(\"action\", \"manager\")\n",
    "isolate_workflow = isolate_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d4cc47a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### æ¼”ç¤ºå¤šæ™ºèƒ½ä½“åä½œ ###\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "ğŸ“‹ ä»»åŠ¡åˆ†è§£: åˆ†æé”€å”®æ•°æ® â†’ æ’°å†™æ–‡æ¡ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [manager] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "ğŸ“Š ä½¿ç”¨é¢„è®¾åˆ†æç»“æœ\n",
      "--- [action] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "ğŸ“‹ ä»»åŠ¡åˆ†è§£: åˆ†æé”€å”®æ•°æ® â†’ æ’°å†™æ–‡æ¡ˆ\n",
      "--- [manager] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "ğŸ“Š ä½¿ç”¨é¢„è®¾åˆ†æç»“æœ\n",
      "--- [action] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "ğŸ“‹ ä»»åŠ¡åˆ†è§£: åˆ†æé”€å”®æ•°æ® â†’ æ’°å†™æ–‡æ¡ˆ\n",
      "--- [manager] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "ğŸ“Š ä½¿ç”¨é¢„è®¾åˆ†æç»“æœ\n",
      "--- [action] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "ğŸ“‹ ä»»åŠ¡åˆ†è§£: åˆ†æé”€å”®æ•°æ® â†’ æ’°å†™æ–‡æ¡ˆ\n",
      "--- [manager] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "ğŸ“Š ä½¿ç”¨é¢„è®¾åˆ†æç»“æœ\n",
      "--- [action] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "ğŸ“‹ ä»»åŠ¡åˆ†è§£: åˆ†æé”€å”®æ•°æ® â†’ æ’°å†™æ–‡æ¡ˆ\n",
      "--- [manager] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "ğŸ“Š ä½¿ç”¨é¢„è®¾åˆ†æç»“æœ\n",
      "--- [action] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "ğŸ“‹ ä»»åŠ¡åˆ†è§£: åˆ†æé”€å”®æ•°æ® â†’ æ’°å†™æ–‡æ¡ˆ\n",
      "--- [manager] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "ğŸ“Š ä½¿ç”¨é¢„è®¾åˆ†æç»“æœ\n",
      "--- [action] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "ğŸ“‹ ä»»åŠ¡åˆ†è§£: åˆ†æé”€å”®æ•°æ® â†’ æ’°å†™æ–‡æ¡ˆ\n",
      "--- [manager] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "ğŸ“Š ä½¿ç”¨é¢„è®¾åˆ†æç»“æœ\n",
      "--- [action] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "ğŸ“‹ ä»»åŠ¡åˆ†è§£: åˆ†æé”€å”®æ•°æ® â†’ æ’°å†™æ–‡æ¡ˆ\n",
      "--- [manager] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "ğŸ“Š ä½¿ç”¨é¢„è®¾åˆ†æç»“æœ\n",
      "--- [action] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "ğŸ“‹ ä»»åŠ¡åˆ†è§£: åˆ†æé”€å”®æ•°æ® â†’ æ’°å†™æ–‡æ¡ˆ\n",
      "--- [manager] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "ğŸ“Š ä½¿ç”¨é¢„è®¾åˆ†æç»“æœ\n",
      "--- [action] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "ğŸ“‹ ä»»åŠ¡åˆ†è§£: åˆ†æé”€å”®æ•°æ® â†’ æ’°å†™æ–‡æ¡ˆ\n",
      "--- [manager] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "ğŸ“Š ä½¿ç”¨é¢„è®¾åˆ†æç»“æœ\n",
      "--- [action] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "ğŸ“‹ ä»»åŠ¡åˆ†è§£: åˆ†æé”€å”®æ•°æ® â†’ æ’°å†™æ–‡æ¡ˆ\n",
      "--- [manager] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "ğŸ“Š ä½¿ç”¨é¢„è®¾åˆ†æç»“æœ\n",
      "--- [action] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "ğŸ“‹ ä»»åŠ¡åˆ†è§£: åˆ†æé”€å”®æ•°æ® â†’ æ’°å†™æ–‡æ¡ˆ\n",
      "--- [manager] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- TOOL EXECUTION ---\n",
      "ğŸ“Š ä½¿ç”¨é¢„è®¾åˆ†æç»“æœ\n",
      "--- [action] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- MANAGER AGENT ---\n",
      "ğŸ“‹ ä»»åŠ¡åˆ†è§£: åˆ†æé”€å”®æ•°æ® â†’ æ’°å†™æ–‡æ¡ˆ\n",
      "--- [manager] æ­¥éª¤å®Œæˆ ---\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 15\u001b[0m\n\u001b[1;32m      7\u001b[0m initial_state \u001b[38;5;241m=\u001b[39m ManagerState(\n\u001b[1;32m      8\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m      9\u001b[0m     task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[1;32m     10\u001b[0m     analysis_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     final_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# æ‰§è¡Œå·¥ä½œæµ\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m isolate_workflow\u001b[38;5;241m.\u001b[39mstream(initial_state):\n\u001b[1;32m     16\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(step\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m     state \u001b[38;5;241m=\u001b[39m step[node]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/__init__.py:2559\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_of_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2551\u001b[0m     msg \u001b[38;5;241m=\u001b[39m create_error_message(\n\u001b[1;32m   2552\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   2553\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2557\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mGRAPH_RECURSION_LIMIT,\n\u001b[1;32m   2558\u001b[0m     )\n\u001b[0;32m-> 2559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[1;32m   2560\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[1;32m   2561\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(loop\u001b[38;5;241m.\u001b[39moutput)\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
     ]
    }
   ],
   "source": [
    "# --- 6. æ‰§è¡Œå¤šæ™ºèƒ½ä½“åä½œ ---\n",
    "print(\"\\n### æ¼”ç¤ºå¤šæ™ºèƒ½ä½“åä½œ ###\")\n",
    "task = (\n",
    "    \"åˆ†æé”€å”®æ•°æ®æ‰¾å‡ºé”€å”®é¢æœ€é«˜çš„äº§å“ï¼Œ\"\n",
    "    \"ç„¶åä¸ºè¯¥äº§å“æ’°å†™ä¸€ç¯‡å¸å¼•äººçš„è¥é”€æ–‡æ¡ˆã€‚\"\n",
    ")\n",
    "initial_state = ManagerState(\n",
    "    messages=[],\n",
    "    task=task,\n",
    "    analysis_result=\"\",\n",
    "    final_output=\"\"\n",
    ")\n",
    "\n",
    "# æ‰§è¡Œå·¥ä½œæµ\n",
    "for step in isolate_workflow.stream(initial_state):\n",
    "    node = list(step.keys())[0]\n",
    "    state = step[node]\n",
    "    print(f\"--- [{node}] æ­¥éª¤å®Œæˆ ---\")\n",
    "    if \"final_output\" in state and state[\"final_output\"]:\n",
    "        print(f\"\\nğŸ‰ æœ€ç»ˆæ–‡æ¡ˆ:\\n{state['final_output']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
