### **培训主题：上下文工程 (Context Engineering) 新手入门指南**

**目标受众：** 对AI或LLM有基本了解，但对“上下文工程”概念不熟悉的团队同事。

**培训目标：**
*   理解什么是上下文工程及其重要性。
*   了解为什么上下文工程对于构建AI智能体(Agent)至关重要。
*   掌握上下文工程的四种核心策略及其具体技术。

---

### **第一部分：开篇 - 什么是上下文工程？**

**1. 核心定义**

上下文工程 (Context Engineering) 是一门“艺术”与“科学”，其核心目标是在AI智能体执行任务的每一步中，都为其上下文窗口（Context Window）填充恰到好处的信息。

**2. 一个生动的比喻**

您可以将大语言模型（LLM）想象成计算机的 **CPU（中央处理器）**，而它的“上下文窗口”则像是计算机的 **RAM（内存）**。 RAM的容量是有限的，操作系统需要智能地管理哪些数据在特定时刻被调入RAM供CPU使用。同样，上下文工程所做的，就是像一个高效的操作系统一样，精心管理和编排进入LLM有限“内存”中的信息，以确保它能高效、准确地完成任务。

**3. 上下文工程的重要性**

随着任务变长、交互变多，如果不进行有效管理，上下文窗口很快会被填满。这会导致多种问题，包括：
*   **超出窗口限制：** 直接导致程序中断或信息丢失。
*   **成本和延迟飙升：** 上下文越长，处理它所需的计算资源和时间就越多。
*   **性能下降：** 过长或混乱的上下文会严重影响AI的判断力。

---

### **第二部分：AI智能体面临的“上下文”挑战**

AI智能体通过一系列“思考 -> 调用工具 -> 观察结果”的循环来完成复杂任务。 这个过程会不断产生新的信息（工具的返回结果、中间思考等），这些信息都会被加入到上下文中。

如果不对上下文进行工程化管理，智能体可能会遇到以下四种典型问题：
1.  **上下文中毒 (Context Poisoning):** 当一个错误或幻觉（Hallucination）信息进入上下文，并误导了后续的判断。
2.  **上下文干扰 (Context Distraction):** 当上下文中无关信息过多，淹没了核心指令或关键信息，导致模型“分心”。
3.  **上下文混淆 (Context Confusion):** 当不必要的上下文信息影响了模型的最终输出。
4.  **上下文冲突 (Context Clash):** 当上下文中包含相互矛盾的信息时。

因此，正如Cognition和Anthropic等顶尖AI公司所强调的，“上下文工程”是构建高效AI智能体的工程师的首要工作之一。

---

### **第三部分：上下文工程的四大核心策略**

我们可以将上下文工程的方法归纳为四大策略：**写入 (Write)、选择 (Select)、压缩 (Compress) 和隔离 (Isolate)**。

**策略一：写入 (Write) - 将信息保存到“外部”**

这个策略的核心思想是，不把所有东西都塞进即时的上下文窗口，而是先存起来。
*   **暂存区 (Scratchpads):** 就像我们解决复杂问题时在旁边打草稿一样。智能体可以将任务执行过程中的中间计划、思考步骤或临时数据“写”到一个外部的暂存区（比如一个文件或一个状态对象）。这能确保即使上下文窗口因为过长而被截断，关键的计划和信息也不会丢失。
*   **记忆 (Memories):** 用于跨会话、长期地保存信息。比如，AI可以从与用户的交互中学习并形成长期记忆，或者通过“反思”来总结经验教训。这些记忆可以在未来的任务中被唤醒和使用。

**策略二：选择 (Select) - 只把“对”的信息拉进来**

当信息被“写入”外部后，我们需要一个机制在恰当的时机，只“选择”最相关的信息放回上下文窗口。
*   **从暂存区/记忆中选择:**
    *   **简单读取:** 如果暂存区是个文件，可以直接读取。
    *   **智能检索:** 当记忆库变得庞大时，需要更智能的方法。常用技术是**嵌入(Embedding)检索**或**知识图谱**，根据当前任务的需要，在海量记忆中找到最相关的片段（比如相似的案例、可遵循的指令或相关的事实）。
*   **工具选择 (Tool Selection):** 当智能体有非常多的工具（API）可用时，它可能会混淆该用哪个。我们可以运用RAG（检索增强生成）技术，不把所有工具的描述都给模型，而是先根据任务检索出最可能用到的几个工具，再让模型选择。

**策略三：压缩 (Compress) - 为上下文“瘦身”**

此策略旨在减少Token的消耗，只保留最精华的信息。
*   **上下文总结 (Context Summarization):** 当对话历史变得非常长，或者某个工具返回了大量文本时，可以调用一个LLM来对这些信息进行总结，用一段精简的摘要来替代原文。
*   **上下文裁剪 (Context Trimming):** 这是一种更直接的过滤方法。例如，通过设定规则（如“只保留最近的10轮对话”）或使用一个训练好的模型来“修剪”掉不那么重要的上下文。

**策略四：隔离 (Isolate) - “分而治之”**

隔离策略通过拆分上下文来帮助智能体更好地执行任务。
*   **多智能体架构 (Multi-agent):** 这是最流行的隔离方法。将一个复杂的大任务，拆解成多个子任务，分配给一个“智能体团队”。每个子智能体都有自己独立的、更小的上下文窗口，只专注于自己的特定任务（如一个负责搜集资料，一个负责编码，一个负责审查）。
*   **沙盒环境 (Environments):** 让智能体生成的代码在一个隔离的“沙盒”中执行。这样做的好处是，代码执行过程中产生的复杂对象或大量数据可以保留在沙盒这个“外部状态”中，只有最终的关键结果才会被挑选出来，返回给LLM的上下文。
*   **状态对象 (State Objects):** 在程序设计中，可以创建一个结构化的“状态对象”，用来存储不同类型的信息。在与LLM交互时，只将对象中标记为“需暴露给LLM”的字段传入上下文，其他信息则被隔离在该对象内部，供程序逻辑后续使用。

---

### **第四部分：总结与展望**

**核心要点回顾：**
上下文工程是构建强大AI智能体的关键。我们今天学习了它的四大核心策略：
1.  **写入 (Write):** 用暂存区和记忆将信息存到外部。
2.  **选择 (Select):** 用检索等方式只将相关信息拉入上下文。
3.  **压缩 (Compress):** 用总结和裁剪为上下文瘦身。
4.  **隔离 (Isolate):** 用多智能体和沙盒等方式分而治之。

通过灵活组合运用这些策略，我们可以构建出更强大、更高效、更可靠的AI应用。