{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e2281b",
   "metadata": {},
   "source": [
    "# **使用 LangGraph 和 Qwen 模型实现上下文工程四大策略**\n",
    "\n",
    "### **目标**\n",
    "本 Notebook 将作为一份详细的技术指南，演示如何使用 LangGraph 框架和通义千问（Qwen）模型，一步步实现“上下文工程”的四大核心策略。\n",
    "\n",
    "四大策略包括：\n",
    "1.  **写入 (Write):** 为智能体构建一个“外部大脑”（暂存区），以在长任务中保持状态。\n",
    "2.  **选择 (Select):** 使用检索增强生成（RAG）从知识库中精准调取信息。\n",
    "3.  **压缩 (Compress):** 智能地总结对话历史，以节省成本和Token。\n",
    "4.  **隔离 (Isolate):** 使用多智能体（Multi-agent）架构，将复杂任务分解给专家处理。\n",
    "\n",
    "---\n",
    "### **第一步：环境设置与模型初始化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ddefae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: langchain in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-qwq in c:\\users\\ych25\\appdata\\roaming\\python\\python311\\site-packages (0.2.0)\n",
      "Requirement already satisfied: langgraph in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: langchain_community in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (0.3.26)\n",
      "Requirement already satisfied: dashscope in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (1.23.6)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\ych25\\appdata\\roaming\\python\\python311\\site-packages (1.11.0.post1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain) (0.3.67)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain) (0.4.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: json-repair<0.41.0,>=0.40.0 in c:\\users\\ych25\\appdata\\roaming\\python\\python311\\site-packages (from langchain-qwq) (0.40.0)\n",
      "Requirement already satisfied: langchain-openai<0.4.0,>=0.3.11 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain-qwq) (0.3.27)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.70.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain-qwq) (1.91.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain-openai<0.4.0,>=0.3.11->langchain-qwq) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from openai<2.0.0,>=1.70.0->langchain-qwq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from openai<2.0.0,>=1.70.0->langchain-qwq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from openai<2.0.0,>=1.70.0->langchain-qwq) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from openai<2.0.0,>=1.70.0->langchain-qwq) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from openai<2.0.0,>=1.70.0->langchain-qwq) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from openai<2.0.0,>=1.70.0->langchain-qwq) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.70.0->langchain-qwq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.70.0->langchain-qwq) (0.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai<0.4.0,>=0.3.11->langchain-qwq) (2024.11.6)\n",
      "Requirement already satisfied: langgraph-checkpoint>=2.1.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langgraph) (2.1.0)\n",
      "Requirement already satisfied: langgraph-prebuilt>=0.5.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langgraph) (0.5.2)\n",
      "Requirement already satisfied: langgraph-sdk>=0.1.42 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langgraph) (0.1.72)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain_community) (3.12.13)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: websocket-client in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from dashscope) (1.8.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langgraph-checkpoint>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\miniconda3\\envs\\docproject\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.70.0->langchain-qwq) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain langchain-qwq langgraph pandas python-dotenv langchain_community dashscope faiss-cpu pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0417ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import json\n",
    "import operator\n",
    "from typing import List, TypedDict, Annotated\n",
    "\n",
    "import tiktoken\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, ToolMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_qwq import ChatQwen\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1547b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 设置API密钥 ---\n",
    "# 请注意：这里需要的是 DashScope 的 API Key\n",
    "if \"DASHSCOPE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"DASHSCOPE_API_KEY\"] = getpass.getpass(\"请输入您的DashScope API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef5d7428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen 模型初始化成功！\n"
     ]
    }
   ],
   "source": [
    "# --- 2. 初始化Qwen模型 ---\n",
    "# 我们将使用 qwen3-32b 模型作为我们智能体的“大脑”\n",
    "try:\n",
    "    model = ChatQwen(model=\"qwen3-30b-a3b\", base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",  enable_thinking=False)\n",
    "    print(\"Qwen 模型初始化成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"模型初始化失败，请检查API Key或网络连接: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc73c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 初始化Token计算器 ---\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a80f1e5",
   "metadata": {},
   "source": [
    "## **策略一：写入 (Write) - 构建智能体的“草稿纸”**\n",
    "\n",
    "**核心思想:** 不把所有中间步骤和思考都塞进主对话历史（`messages`），而是将它们“写入”到一个独立的“暂存区”（`scratchpad`）。这可以保持主对话的清晰，并为智能体提供一个可靠的短期记忆，防止在长任务中“失忆”。\n",
    "\n",
    "**实现:** 我们将在`AgentState`中增加一个`scratchpad`字段，并通过添加`SystemMessage`来指导模型的行为，防止无限循环。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63a46ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 定义状态 ---\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List, Annotated\n",
    "import operator\n",
    "\n",
    "class ToolCallRecord(TypedDict):\n",
    "    step: int\n",
    "    tool_name: str\n",
    "    args: dict\n",
    "    result: str\n",
    "\n",
    "class WriteStrategyState(TypedDict):\n",
    "    messages: Annotated[list, operator.add]\n",
    "    # 结构化 scratchpad，保留完整历史\n",
    "    scratchpad: dict  # {\"history\": List[ToolCallRecord], \"final_answer\": str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "436e02ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. 定义工具 ---\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def simple_calculator(operation: str, a: int, b: int) -> int:\n",
    "    \"\"\"一个简单的计算器工具，执行加减乘除。\"\"\"\n",
    "    if operation == \"add\":\n",
    "        return a + b\n",
    "    if operation == \"subtract\":\n",
    "        return a - b\n",
    "    if operation == \"multiply\":\n",
    "        return a * b\n",
    "    if operation == \"divide\" and b != 0:\n",
    "        return a // b\n",
    "    return \"无效操作\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7d01195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 定义图的节点 ---\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import END\n",
    "\n",
    "tools = [simple_calculator]\n",
    "tool_node = ToolNode(tools)\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "def agent_with_scratchpad(state: WriteStrategyState):\n",
    "    \"\"\"\n",
    "    Agent 节点：决定下一步动作，并更新暂存区。\n",
    "    \"\"\"\n",
    "    print(\"---AGENT NODE---\")\n",
    "    response = model_with_tools.invoke(state['messages'])\n",
    "\n",
    "    if response.tool_calls:\n",
    "        # 暂存当前待执行的工具\n",
    "        state['scratchpad']['pending_tool'] = response.tool_calls[0]\n",
    "        print(f\"🧠 Agent Action: Call tool `{response.tool_calls[0]['name']}` \"\n",
    "              f\"with arguments `{response.tool_calls[0]['args']}`\")\n",
    "    else:\n",
    "        # 全部完成，保存最终答案\n",
    "        state['scratchpad']['final_answer'] = response.content\n",
    "        print(f\"✅ Final Answer: {response.content}\")\n",
    "\n",
    "    return {\"messages\": [response], \"scratchpad\": state['scratchpad']}\n",
    "\n",
    "def tool_node_with_scratchpad(state: WriteStrategyState):\n",
    "    \"\"\"\n",
    "    Tool 节点：执行工具，并把结果记录到 history。\n",
    "    \"\"\"\n",
    "    print(\"---TOOL NODE---\")\n",
    "    last_message = state['messages'][-1]\n",
    "    tool_messages = tool_node.invoke([last_message])\n",
    "\n",
    "    # 取出待处理的工具调用\n",
    "    pending = state['scratchpad']['pending_tool']\n",
    "    record = ToolCallRecord(\n",
    "        step=len(state['scratchpad'].get(\"history\", [])) + 1,\n",
    "        tool_name=pending['name'],\n",
    "        args=pending['args'],\n",
    "        result=str(tool_messages[0].content)\n",
    "    )\n",
    "    # 追加到历史\n",
    "    state['scratchpad'].setdefault(\"history\", []).append(record)\n",
    "    print(f\"📝 Recorded Tool Call: {record}\")\n",
    "    state['scratchpad'].pop(\"pending_tool\", None)  # 清理\n",
    "\n",
    "    #print(f\"🛠️ Tool Result: `{record['result']}`\")\n",
    "    return {\"messages\": tool_messages, \"scratchpad\": state['scratchpad']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4be3a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. 构建图 ---\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "write_graph_builder = StateGraph(WriteStrategyState)\n",
    "write_graph_builder.add_node(\"agent\", agent_with_scratchpad)\n",
    "write_graph_builder.add_node(\"action\", tool_node_with_scratchpad)\n",
    "write_graph_builder.set_entry_point(\"agent\")\n",
    "\n",
    "# 条件边：检查是否还有未完成的工具\n",
    "def should_continue(state: WriteStrategyState) -> str:\n",
    "    # 若最终答案已存在，直接结束\n",
    "    if state['scratchpad'].get(\"final_answer\"):\n",
    "        return END\n",
    "    return \"action\"\n",
    "\n",
    "write_graph_builder.add_conditional_edges(\"agent\", should_continue, {\"action\": \"action\", END: END})\n",
    "write_graph_builder.add_edge(\"action\", \"agent\")\n",
    "write_graph = write_graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aa372ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 工程造价预算调整计算 ###\n",
      "---AGENT NODE---\n",
      "🧠 Agent Action: Call tool `simple_calculator` with arguments `{'a': 128, 'b': 72, 'operation': 'add'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "📝 Recorded Tool Call: {'step': 1, 'tool_name': 'simple_calculator', 'args': {'a': 128, 'b': 72, 'operation': 'add'}, 'result': '200'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "🧠 Agent Action: Call tool `simple_calculator` with arguments `{'a': 200, 'b': 3, 'operation': 'multiply'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "📝 Recorded Tool Call: {'step': 2, 'tool_name': 'simple_calculator', 'args': {'a': 200, 'b': 3, 'operation': 'multiply'}, 'result': '600'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "🧠 Agent Action: Call tool `simple_calculator` with arguments `{'a': 600, 'b': 100, 'operation': 'divide'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "📝 Recorded Tool Call: {'step': 3, 'tool_name': 'simple_calculator', 'args': {'a': 600, 'b': 100, 'operation': 'divide'}, 'result': '6'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "🧠 Agent Action: Call tool `simple_calculator` with arguments `{'a': 6, 'b': 20, 'operation': 'multiply'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "📝 Recorded Tool Call: {'step': 4, 'tool_name': 'simple_calculator', 'args': {'a': 6, 'b': 20, 'operation': 'multiply'}, 'result': '120'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "🧠 Agent Action: Call tool `simple_calculator` with arguments `{'a': 120, 'b': 22, 'operation': 'subtract'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "📝 Recorded Tool Call: {'step': 5, 'tool_name': 'simple_calculator', 'args': {'a': 120, 'b': 22, 'operation': 'subtract'}, 'result': '98'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "✅ Final Answer: 工程最终预算：98万元\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# --- 5. 演示 ---\n",
    "print(\"### 工程造价预算调整计算 ###\")\n",
    "task = (\n",
    "    \"1) 初始工程预算 128 万元与设计变更追加 72 万元进行合并；\\n\"\n",
    "    \"2) 合并后的预算按季度材料价格波动系数进行 3 倍调整；\\n\"\n",
    "    \"3) 调整后的预算因国际标准转换需除以 100 得到标准工料单位；\\n\"\n",
    "    \"4) 标准工料单位值按 20 倍风险系数扩大，形成最终风险预算；\\n\"\n",
    "    \"5) 从风险预算中扣除 22 万元的质量保证金。\\n\"\n",
    "    \"请列出每一步的数值结果，并以『工程最终预算：{数值}万元』的格式给出答案。\"\n",
    ")\n",
    "\n",
    "system_prompt = (\n",
    "    \"你是一个工程造价计算助手。请按步骤使用 `simple_calculator` 工具进行工程预算计算。\"\n",
    ")\n",
    "initial_messages = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(content=task)\n",
    "]\n",
    "initial_state = {\"messages\": initial_messages, \"scratchpad\": {\"history\": [], \"final_answer\": None}}\n",
    "\n",
    "# 使用 .stream() 观察每一步\n",
    "for step in write_graph.stream(initial_state, {\"recursion_limit\": 20}):\n",
    "    #print(step)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e126c53",
   "metadata": {},
   "source": [
    "## **策略二：选择 (Select) - 精准的\"信息调取\"**\n",
    "\n",
    "**核心思想：** 使用RAG（检索增强生成）技术，从外部知识库中精准检索最相关的信息片段，只将必要信息注入上下文。\n",
    "\n",
    "**实现步骤：**\n",
    "1. 创建产品知识库（模拟向量数据库）\n",
    "2. 构建RAG检索器\n",
    "3. 设计智能体流程：问题 → 检索 → 生成答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d67324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 创建模拟产品知识库 ---\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "\n",
    "# 创建嵌入模型\n",
    "embeddings = DashScopeEmbeddings(model=\"text-embedding-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29f0b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_docs = [\n",
    "    Document(page_content=\"\"\"电力造价管理系统：\n",
    "- 理念：电力工程全生命周期造价管理\n",
    "- 覆盖专业：发电/变电/输电/农配网/运维检修五大领域\n",
    "- 核心功能：支持可研估算、初步设计概算、施工图预算、招投标报价、竣工结算全流程\n",
    "- 技术特点：内置行业计价依据与业务场景库\n",
    "- 优势：智能高效完成造价编制，确保合规性与准确性\n",
    "- 适用对象：电力工程造价咨询机构、建设单位\"\"\", \n",
    "             metadata={\"product\": \"电力造价管理系统\", \"category\": \"造价软件\"}),\n",
    "    \n",
    "    Document(page_content=\"\"\"电力设计协同平台：\n",
    "- 专业覆盖：输电/变电/配电三大核心专业\n",
    "- 核心功能：预置设计规程规范、典型设计方案、标准物料库、成果模板\n",
    "- 技术特点：可视化图形设计界面，支持数字化成果输出\n",
    "- 优势：提升设计效率30%+，规范设计质量\n",
    "- 适用场景：电力设计院、工程总承包项目\"\"\", \n",
    "             metadata={\"product\": \"电力设计协同平台\", \"category\": \"设计软件\"}),\n",
    "    \n",
    "    Document(page_content=\"\"\"易数大数据分析平台：\n",
    "- 核心能力：构建大数据可视化分析生态圈\n",
    "- 功能模块：数据资产治理、多维度可视化分析、智能决策支持\n",
    "- 适用领域：政府能源监管、电力企业运营分析、新能源项目管理\n",
    "- 技术优势：低代码操作界面，支持TB级数据实时分析\n",
    "- 部署方式：私有云/公有云双模式\"\"\", \n",
    "             metadata={\"product\": \"易数大数据平台\", \"category\": \"数据分析\"}),\n",
    "    \n",
    "    Document(page_content=\"\"\"电力业务管理工具集：\n",
    "- 核心产品：清标工具（招标文件智能审查）\n",
    "           智慧招投标系统（全流程电子化）\n",
    "- 功能亮点：自动识别风险项、智能生成审查报告\n",
    "- 适用对象：业主单位/施工单位/招标代理机构\n",
    "- 效率提升：人工成本降低50%，错误率下降80%\"\"\", \n",
    "             metadata={\"product\": \"电力管理工具集\", \"category\": \"管理工具\"}),\n",
    "    \n",
    "    # 行业知识补充文档\n",
    "    Document(page_content=\"\"\"电力工程采购指南：\n",
    "1. 突出全生命周期成本优势\n",
    "2. 强调合规性与行业标准适配\n",
    "3. 技术参数需匹配国网/南网规范\n",
    "4. 提供典型项目成功案例\n",
    "5. 采用分阶段报价策略\"\"\", \n",
    "             metadata={\"doc_type\": \"采购指南\"}),\n",
    "    \n",
    "    Document(page_content=\"\"\"电力行业用户需求：\n",
    "- 采购决策关键因素：\n",
    "  1. 系统合规性（82%）\n",
    "  2. 数据安全性（76%） \n",
    "  3. 与现有系统兼容性（68%）\n",
    "  4. 本地化服务能力（63%）\n",
    "  5. ROI周期（55%）\"\"\", \n",
    "             metadata={\"doc_type\": \"行业洞察\"}),\n",
    "]\n",
    "\n",
    "# 创建向量数据库\n",
    "vector_db = FAISS.from_documents(product_docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "259408e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. 构建RAG检索器 ---\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 创建检索器\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"格式化检索到的文档\"\"\"\n",
    "    return \"\\n\\n\".join(f\"## 来源 {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(docs))\n",
    "\n",
    "# 创建RAG提示模板\n",
    "rag_template = \"\"\"\n",
    "你是一位专业的产品文案助手。请根据提供的背景信息回答用户问题。\n",
    "\n",
    "<背景信息>\n",
    "{context}\n",
    "</背景信息>\n",
    "\n",
    "用户问题：{question}\n",
    "\n",
    "请用专业、简洁的语言回答，突出产品核心优势：\n",
    "\"\"\"\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_template)\n",
    "\n",
    "# 创建RAG链\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | RunnableLambda(format_docs), \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b04e7dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 设计智能体流程 ---\n",
    "class SelectStrategyState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    context: str  # 存储检索到的上下文\n",
    "\n",
    "def retrieve_context(state: SelectStrategyState):\n",
    "    \"\"\"检索节点：从知识库获取相关信息\"\"\"\n",
    "    print(\"\\n--- RETRIEVE CONTEXT ---\")\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    \n",
    "    # 执行检索\n",
    "    docs = retriever.invoke(last_message)\n",
    "    context = format_docs(docs)\n",
    "    \n",
    "    # 计算Token节省\n",
    "    orig_token_count = sum(len(encoding.encode(doc.page_content)) for doc in docs)\n",
    "    context_token_count = len(encoding.encode(context))\n",
    "    savings = orig_token_count - context_token_count\n",
    "    \n",
    "    print(f\"🔍 检索到 {len(docs)} 条相关文档\")\n",
    "    # print(f\"📉 Token节省: {savings} (原始: {orig_token_count} -> 压缩: {context_token_count})\")\n",
    "    print(f\"📝 注入上下文:\\n{context[:300]}...\")\n",
    "    \n",
    "    return {\"context\": context}\n",
    "\n",
    "def generate_with_context(state: SelectStrategyState):\n",
    "    \"\"\"生成节点：使用检索到的上下文生成回答\"\"\"\n",
    "    print(\"\\n--- GENERATE WITH CONTEXT ---\")\n",
    "    question = state[\"messages\"][-1].content\n",
    "    \n",
    "    # 使用RAG链生成回答\n",
    "    response = rag_chain.invoke(question)\n",
    "    \n",
    "    # 创建消息对象\n",
    "    response_message = HumanMessage(content=response)\n",
    "    \n",
    "    # 输出结果\n",
    "    print(f\"💡 生成的回答: {response}\")\n",
    "    return {\"messages\": [response_message]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c58e344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. 构建选择策略图 ---\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# 定义状态\n",
    "class SelectState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    context: str\n",
    "\n",
    "# 创建图\n",
    "select_graph = StateGraph(SelectState)\n",
    "\n",
    "# 添加节点\n",
    "select_graph.add_node(\"retrieve\", retrieve_context)\n",
    "select_graph.add_node(\"generate\", generate_with_context)\n",
    "\n",
    "# 设置入口点\n",
    "select_graph.set_entry_point(\"retrieve\")\n",
    "\n",
    "# 添加边\n",
    "select_graph.add_edge(\"retrieve\", \"generate\")\n",
    "select_graph.add_edge(\"generate\", END)\n",
    "\n",
    "# 编译图\n",
    "select_workflow = select_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bd425e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### 演示'选择'策略 ###\n",
      "\n",
      "--- RETRIEVE CONTEXT ---\n",
      "🔍 检索到 2 条相关文档\n",
      "📝 注入上下文:\n",
      "## 来源 1:\n",
      "电力造价管理系统：\n",
      "- 理念：电力工程全生命周期造价管理\n",
      "- 覆盖专业：发电/变电/输电/农配网/运维检修五大领域\n",
      "- 核心功能：支持可研估算、初步设计概算、施工图预算、招投标报价、竣工结算全流程\n",
      "- 技术特点：内置行业计价依据与业务场景库\n",
      "- 优势：智能高效完成造价编制，确保合规性与准确性\n",
      "- 适用对象：电力工程造价咨询机构、建设单位\n",
      "\n",
      "## 来源 2:\n",
      "电力业务管理工具集：\n",
      "- 核心产品：清标工具（招标文件智能审查）\n",
      "           智慧招投标系统（全流程电子化）\n",
      "- 功能亮点：自动识别风险项、智能生成审查报告\n",
      "- 适用对象：业主单位/施工单位/招标代理机构\n",
      "- 效...\n",
      "{'retrieve': {'context': '## 来源 1:\\n电力造价管理系统：\\n- 理念：电力工程全生命周期造价管理\\n- 覆盖专业：发电/变电/输电/农配网/运维检修五大领域\\n- 核心功能：支持可研估算、初步设计概算、施工图预算、招投标报价、竣工结算全流程\\n- 技术特点：内置行业计价依据与业务场景库\\n- 优势：智能高效完成造价编制，确保合规性与准确性\\n- 适用对象：电力工程造价咨询机构、建设单位\\n\\n## 来源 2:\\n电力业务管理工具集：\\n- 核心产品：清标工具（招标文件智能审查）\\n           智慧招投标系统（全流程电子化）\\n- 功能亮点：自动识别风险项、智能生成审查报告\\n- 适用对象：业主单位/施工单位/招标代理机构\\n- 效率提升：人工成本降低50%，错误率下降80%'}}\n",
      "---\n",
      "\n",
      "--- GENERATE WITH CONTEXT ---\n",
      "💡 生成的回答: 【电力造价管理，精准高效，助力工程全程管控】  \n",
      "\n",
      "在电力工程中，造价管理是关键环节，直接影响项目质量与效益。我们的**电力造价管理系统**，以“全生命周期造价管理”为核心理念，全面覆盖发电、变电、输电、农配网及运维检修五大领域，支持可研估算、初步设计概算、施工图预算、招投标报价、竣工结算等全流程造价工作。  \n",
      "\n",
      "系统内置权威行业计价依据与丰富业务场景库，智能高效完成造价编制，确保合规性与准确性，大幅提升工作效率。  \n",
      "\n",
      "无论是电力工程造价咨询机构还是建设单位，本系统都是您不可或缺的得力助手。  \n",
      "\n",
      "**智能驱动，精准控本，选择我们，让造价管理更专业、更高效！**\n",
      "{'generate': {'messages': [HumanMessage(content='【电力造价管理，精准高效，助力工程全程管控】  \\n\\n在电力工程中，造价管理是关键环节，直接影响项目质量与效益。我们的**电力造价管理系统**，以“全生命周期造价管理”为核心理念，全面覆盖发电、变电、输电、农配网及运维检修五大领域，支持可研估算、初步设计概算、施工图预算、招投标报价、竣工结算等全流程造价工作。  \\n\\n系统内置权威行业计价依据与丰富业务场景库，智能高效完成造价编制，确保合规性与准确性，大幅提升工作效率。  \\n\\n无论是电力工程造价咨询机构还是建设单位，本系统都是您不可或缺的得力助手。  \\n\\n**智能驱动，精准控本，选择我们，让造价管理更专业、更高效！**', additional_kwargs={}, response_metadata={})]}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# --- 5. 演示选择策略 ---\n",
    "print(\"\\n### 演示'选择'策略 ###\")\n",
    "question = \"请为我们的电力造价管理系统写一封促销公众号短文，突出其核心优势\"\n",
    "\n",
    "# 初始状态\n",
    "initial_state = SelectState(\n",
    "    messages=[HumanMessage(content=question)],\n",
    "    context=\"\"\n",
    ")\n",
    "\n",
    "# 执行工作流\n",
    "for step in select_workflow.stream(initial_state):\n",
    "    if \"__end__\" not in step:\n",
    "        print(step)\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b78e84",
   "metadata": {},
   "source": [
    "## **策略三：压缩 (Compress) - 为上下文\"瘦身减负\"**\n",
    "\n",
    "**核心思想：** 使用总结(summarization)和裁剪(trimming)技术减少上下文长度，节省Token并提高效率。\n",
    "\n",
    "**实现两种压缩技术：**\n",
    "1. **总结压缩**：将长文本提炼为简洁摘要\n",
    "2. **裁剪压缩**：智能保留对话中最相关的部分\n",
    "\n",
    "**场景演示：** 智能体需要阅读一篇长文章并回答问题，我们通过总结压缩文章内容；同时展示对话历史裁剪技术。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1022bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 准备长文本示例 ---\n",
    "long_article = \"\"\"\n",
    "\n",
    "一. 总体工作概要\n",
    "从3月11日进入公司以来, 我的工作开展如下:\n",
    "\n",
    "AI技术研究为AI项目提供支持能力\n",
    "客户真实场景需求驱动技术研究迭代\n",
    "AI知识管理将经验转化为可复用的方法\n",
    "二. 相关工作情况\n",
    "2.1. 技术研究\n",
    "围绕两项技术: 多模态图纸识别 和 RAG(检索增强生成) 开展研究工作.\n",
    "\n",
    "2.1.1. 多模态图纸识别方面\n",
    "从少样本提示识别, 到搭建系统流程输出提资表, 再到通过YOLO(目标检测模型)+VL(视觉理解模型)+context(上下文信息)的信息输出, 在多个场景下验证了AI的能力.\n",
    "\n",
    "完成了少样本识别提示的应用界面Demo(见后附图1). 支持用户将工程图纸上传, 然后根据图纸信息进行定额匹配, 也可根据软件内的定额\\预规等, 帮助用户快速生成费用预估. 但是这项技术也存在不足, 主要是少样本提示不能无限扩充, 并且模型的指引跟随具有随机性.\n",
    "实现了整套图纸识别输出提资表的应用界面Demo(见后附图2). 这项技术可以从整套工程图纸中提取工程造价所需的参数(目前初步实现了架空线路杆塔工程的提取), 最终愿景是用户将设计资料导入后就能够自动生成造价成果. 当然我们距离这个最终愿景还有一定的距离, 需要解决的有识别准确率, 多文件信息的交叉验证等技术问题, 也有大量的业务问题.\n",
    "搭建了YOLO+VL+context的应用界面Demo(见后附图3). 这项技术研究在一定程度上可以解决上述第2项研究的部分问题, 但更大的价值还是构建了一个具有一定业务通用性的技术平台, 也就是说除了造价, 识图也可以用于如评审 施工等各个领域, 甚至也可以用户非工程领域. 而我们针对性要开展的工作也是更为明确的: 算法岗位负责YOLO训练, 大模型岗位负责VL模型应用系统搭建, 需求岗负责context构建.\n",
    "2.1.2. RAG(检索增强生成)方面\n",
    "RAG的研究经过两轮迭代,目前在Index(数据预处理和向量索引构建), Retrieval(检索方法), Generation(结果生成)方面都具备了较为体系化的解决方案.\n",
    "\n",
    "Index方面, 构建了文档嵌入系统Demo, 提供了灵活可选择的向量索引嵌入方法(见后附图4). 而在数据预处理方面. 并且为了解决原始数据质量不佳的问题, 研究了基于多模态大模型对原始文档进行处理的方法(见后附图5), 针对复杂的文档结构(多栏 图 文 表 公式兼具, 还有页眉页脚信息), 实现了极高的转化准确率, 输出的markdown文本后续chunk 进行RAG入库, 可以显著提升检索准确率, 并可实现按照图片URL的回答渲染(这套方法处于验证可行阶段, 搭建系统还需要一定过程).\n",
    "Retrieval方面, 实验了多种embedding模型和rerank模型, 并且实践了GLM-SDK Dashscope-SDK Langchain 等多种框架, 以及Faiss Chroma等多种向量数据库, 针对多种场景下的技术选型, 具有了比较成熟的经验.(Retrieval过程没有构建界面展示)\n",
    "Generation方面, 迭代了两版内容生成界面(见后附图6). 第二版相较于第一版做了思考模式 多轮对话 对话过程记录等方面的关键优化, 可显著提升运用效果.\n",
    "以上两项技术研究, 我认为是具有生长为两条产品线的潜力的.\n",
    "2.2. 项目支持\n",
    "AI项目支持面向的省份主要是 浙江 江苏 广东 这三个发达地区省份\n",
    "\n",
    "2.2.1. 对浙江支持的情况\n",
    "上半年以来, 浙江客户对AI项目的迫切度是最高, 3 4 5三个月频繁在浙江温州 嘉兴 绍兴 等地市出差, 针对各地市承担的省公司下方AI建设任务, 也都积极地给出了相关解决方案乃至演示Demo. 但到目前为止, 项目都没有落下来, 我认为没有牵头人是最关键的原因.\n",
    "客户方没有牵头人. 原本是省公司安排任务, 地市公司执行. 但是省公司只安排任务, 不安排费用, 这就导致地市纷纷观望, 等待省公司再给出明确的发文. 本质上这就是一个谁投入 谁负责 以及谁受益的问题.\n",
    "而我们本身也是一样.\n",
    "\n",
    "2.2.2. 对江苏支持的情况\n",
    "6月份以来, 根据江苏分公司的要求, 对江苏的AI项目进行了支持, 包括江苏省经研院和江苏省咨询公司. 江苏这边由分公司杨正健经理作为对接牵头人, 并且其也能够调用分公司资源开展部分工作. 所以江苏这边项目工作的安排我个人认为是更为有序和合理的.\n",
    "\n",
    "2.2.3. 对广东支持的情况\n",
    "广东的支持围绕是广州院的项目, 得益于万可团队对项目推动的主动性, 我在其中的角色是最清晰的(也就是承担技术咨询支持的工作), 而其他相关项目常规动作都由其团队自行完成. 而目前看来, 广东的项目推进进度也是相对较好的.\n",
    "以上三个省份的支持, 代表了三种模式, 而到底采取什么样的模式, 也是接下来各地AI项目开展要解决的关键问题.\n",
    "\n",
    "2.3. 客户对接\n",
    "在对各省AI项目支持, 与客户对接的过程中, 对客户在AI领域的认知和需求, 也形成一定的总结.\n",
    "\n",
    "2.3.1. 客户对AI的认知\n",
    "对于大模型的一些基本概念或者能做什么, 客户是有所了解的. 但是由于大多数人接触的都是短视频/推文类的快信息, 所以无法对大模型建立系统性的认识, 即大模型的原理, 提示词工程的内涵, RAG的流程以及模型微调作用机制等, 这些对于客户来说大多无概念。\n",
    "这就会形成沟通上的不一致, 典型的说法有:\"明明这个很简单，你们为什么做不了?\"、\"这个不可能做到，还需要等一等再说.\" 这些其实就是客户站在既有的认知框架内, 对大模型能力的个人主观推断所形成的下意识表达。\n",
    "而我们的销售/市场人员, 也难说有很深度的认知.\n",
    "所以针对客户要求, 实际验证很重要, 要以实际跑出来的效果对客户提出的要求进行更准确的判断.\n",
    "\n",
    "2.3.2. 客户对AI的需求\n",
    "就目前接触到的客户来说, 对AI的需求基本还就是在识图和内容生成方面.\n",
    "对于识图, 是需要从图中提取到准确的业务参数, 从而推动下一步业务工作的自动化开展. 而内容生成是包括了问答, 文档产出等工作, 以替代原本由人工去查询和编写的低效方式.\n",
    "对于有关造价软件的直接的AI需求, 目前还尚未明确获取到. 但是我认为这是不可忽视, 并且将是极为重要的一个点, 挖掘我们造价软件的潜藏AI使用需求, 推动软件价值的进一步升级, 是一定要开展的重点工作.\n",
    "\n",
    "2.4. 知识管理\n",
    "知识管理方面包括团队分享和个人学习, 在组织的各种形态中, 学习型组织的生命力是最强的.\n",
    "\n",
    "2.4.1. 团队分享\n",
    "入司以来的5次AI技术分享:\n",
    "\n",
    "入司首日分享的 DeepSeek概念及用法\n",
    "提示词工程入门\n",
    "RAG基本原理和优化策略\n",
    "Agent 设计模式\n",
    "模型训练(已准备好分享资料,暂未开展分享会)\n",
    "2.4.2. 个人学习\n",
    "包括对模型 开发框架 工具使用的学习:\n",
    "\n",
    "DeepSeek Qwen GLM InternVL等系列模型的能力实践\n",
    "Langchain/Langgraph streamlit 等大模型应用开发框架的学习实践\n",
    "MCP CherryStudiu Cline等各种AI辅助工具的使用\n",
    "2.5. 工作情况小结\n",
    "以上是我入司四个月以来的主要工作情况. 我认为这四个月以来我是践行了重回公司所想做的事情, 也 是在公司 部门 和领导的支持鼓励下, 可以说取得了一定的工作成效. 从只是说AI, 转变到可以做一些具体的事情, 有一些看得到的东西.\n",
    "但同时, 我也逐步认识到个人的局限性. 随着以上四项工作逐渐做深, 每项工作所需的时间和精力投入都是越来越大. 虽然说能够在AI的辅助下, 尽可能地提升效率, 但也明显感觉越来越力不从心.\n",
    "\n",
    "三. 计划和建议\n",
    "3.1. 下半年计划\n",
    "基于上半年的技术研究基础、项目支持经验以及对客户需求的深入理解, 下半年工作将围绕技术深化、项目落地、价值挖掘和知识赋能四个核心方向展开, 具体计划如下:\n",
    "\n",
    "3.1.1. 技术研究深化与平台化\n",
    "3.1.1.1. 多模态图纸识别：\n",
    "目标是提升工程参数提取的准确率与鲁棒性, 探索1-2个新需求场景的可行性验证. 包括以下工作开展:\n",
    "\n",
    "优化平台, 重点解决多文件信息交叉验证难题, 建立更完善的业务上下文构建规范与流程.\n",
    "跟进YOLO模型的小样本训练优化, 提升目标检测精度.\n",
    "深化VL模型在复杂图纸理解中的应用策略, 探索模型微调对特定任务的增益.\n",
    "3.1.1.2. RAG技术工程化\n",
    "目标是完成多模态文档智能处理与RAG集成系统的工程化落地, 显著提升知识库构建效率与问答质量.包括以下工作开展:\n",
    "\n",
    "将验证成功的多模态文档转Markdown方案工程化, 实现自动化或半自动化的复杂文档（含图/文/表/公式）高质量预处理。\n",
    "整合文档处理、Chunk策略、向量化方法，构建标准化、可配置的索引构建流水线。\n",
    "完善Retrieval & Generation, 基于前期框架选型经验, 固化最佳实践, 提升系统响应速度与结果可靠性.\n",
    "3.1.2. AI项目落地攻坚\n",
    "目标是推动至少 1个省份的AI项目 实现实质性落地(签订合同或进入明确实施阶段)并优化支持模式, 提升整体项目成功率。\n",
    "\n",
    "全力配合江苏等能够有较高层次的客户对接人的省份AI项目, 利用已验证的Demo和技术能力, 推动项目需求细化、方案确认与合同落地.\n",
    "总结江苏（分公司牵头+资源协调）、广东（主动团队+清晰分工）模式的关键要素, 形成内部项目推动指南, 指导后续其他省份AI项目推进.\n",
    "3.1.3. 挖掘软件AI潜能\n",
    "启动造价软件核心业务流程的AI需求挖掘与概念验证。\n",
    "\n",
    "与造价产品、研发团队紧密协作，系统梳理造价软件关键模块中潜在的AI应用点(如智能定额匹配、异常审核提示、报告自动生成).\n",
    "针对1-2个高价值场景,利用现有技术能力(如少样本提示、RAG)进行快速概念验证, 展示AI提升软件效率与价值的可能性.\n",
    "3.1.4. 知识管理升级与团队赋能\n",
    "将个人经验与学习成果有效转化为团队共享资产, 提升团队整体AI能力.\n",
    "\n",
    "系统整理前期技术研究文档、Demo代码、客户常见问题、最佳实践，构建可检索的团队内部AI知识库.\n",
    "专题分享与培训: 完成“模型训练”分享, 围绕下半年重点技术(如YOLO优化实践、多模态RAG系统详解、软件AI PoC经验)和项目经验, 组织定期专题分享会. 针对市场团队, 开展客户AI沟通与需求引导专项培训, 提升其应对“认知鸿沟”的能力.\n",
    "协作机制: 在技术研究项目中(如YOLO+VL平台、RAG系统), 明确跨岗位协作流程与接口(算法、大模型、需求), 促进知识在协作中流动.\n",
    "3.2. 工作建议\n",
    "为有效支撑上述计划的达成, 并促进团队在AI领域的长期健康发展, 谨提出以下建议:\n",
    "\n",
    "建立清晰的技术研究与项目落地协同机制:\n",
    "明确技术研究团队(或核心人员)与区域销售/项目经理在AI项目中的责任界面. 技术团队聚焦解决方案设计、关键技术攻关与核心Demo交付; 销售/项目经理负责客户关系维护、商务谈判、资源协调及整体项目落地推动. 建立定期项目同步会机制, 确保信息对齐, 技术支撑及时响应项目关键节点.\n",
    "系统化构建团队AI知识资产与能力:\n",
    "将知识管理升级为团队级任务. 设立专项资源（可兼职）, 负责持续收集、整理、更新技术文档、案例研究、客户Q&A、最佳实践, 维护易用的内部知识库. 制度化技术分享, 要求参与重点项目的成员进行经验复盘与分享. 为新加入或需提升的成员设计AI认知与沟通培训课程。\n",
    "探索设立AI创新孵化或预研小组：\n",
    "考虑组建一个小的、跨职能的虚拟小组(包含研发、产品、技术研究代表), 定期（如双周）聚焦研讨核心软件AI需求挖掘、前沿技术跟踪评估(如Agent、模型微调新进展)、以及高潜力新方向的快速概念验证. 给予小组一定的资源进行小范围探索.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e07de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. 定义压缩工具 ---\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 总结压缩工具\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"请将以下文本总结为不超过{max_words}字的关键要点，保留所有核心工作内容：\\n\\n{text}\"\n",
    ")\n",
    "\n",
    "summarizer_chain = (\n",
    "    summary_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 裁剪压缩函数\n",
    "def trim_messages(messages: List[BaseMessage], max_messages=5) -> List[BaseMessage]:\n",
    "    \"\"\"裁剪对话历史，保留系统消息和最新的几条消息\"\"\"\n",
    "    # 始终保留第一条系统消息\n",
    "    system_message = messages[0] if messages and isinstance(messages[0], SystemMessage) else None\n",
    "    \n",
    "    # 保留最近的max_messages条消息（排除系统消息）\n",
    "    recent_messages = messages[-max_messages:] if len(messages) > 1 else messages\n",
    "    \n",
    "    # 重新组合\n",
    "    trimmed = []\n",
    "    if system_message:\n",
    "        trimmed.append(system_message)\n",
    "    trimmed.extend(recent_messages)\n",
    "    \n",
    "    return trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59937644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 定义状态和节点 ---\n",
    "class CompressState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    original_text: str  # 原始长文本\n",
    "    compressed_text: str  # 压缩后的文本\n",
    "    token_savings: int  # 节省的Token数量\n",
    "\n",
    "def compress_long_text(state: CompressState):\n",
    "    \"\"\"总结压缩节点：将长文本压缩为摘要\"\"\"\n",
    "    print(\"\\n--- COMPRESSING LONG TEXT ---\")\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # 从用户消息中提取问题\n",
    "    question = last_message.content\n",
    "    \n",
    "    # 压缩长文本\n",
    "    summary = summarizer_chain.invoke({\"text\": state[\"original_text\"], \"max_words\": 300})\n",
    "    \n",
    "    # 计算Token节省\n",
    "    orig_tokens = len(encoding.encode(state[\"original_text\"]))\n",
    "    comp_tokens = len(encoding.encode(summary))\n",
    "    savings = orig_tokens - comp_tokens\n",
    "    \n",
    "    print(f\"📉 文本压缩: {orig_tokens} tokens → {comp_tokens} tokens (节省 {savings} tokens)\")\n",
    "    print(f\"📝 压缩摘要:\\n{summary[:200]}...\")\n",
    "    \n",
    "    # 更新状态\n",
    "    return {\n",
    "        \"compressed_text\": summary,\n",
    "        \"token_savings\": savings,\n",
    "        \"messages\": [HumanMessage(content=f\"基于以下摘要回答问题:\\n{summary}\\n\\n问题: {question}\")]\n",
    "    }\n",
    "\n",
    "def answer_with_compressed_text(state: CompressState):\n",
    "    \"\"\"回答节点：基于压缩文本回答问题\"\"\"\n",
    "    print(\"\\n--- ANSWERING WITH COMPRESSED TEXT ---\")\n",
    "    \n",
    "    # 调用模型生成答案\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    answer = response.content\n",
    "    \n",
    "    print(f\"💡 生成的回答: {answer}\")\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def trim_context(state: CompressState):\n",
    "    \"\"\"裁剪节点：压缩对话历史\"\"\"\n",
    "    print(\"\\n--- TRIMMING CONTEXT ---\")\n",
    "    \n",
    "    # 计算裁剪前的Token\n",
    "    all_messages = \"\".join(m.content for m in state[\"messages\"])\n",
    "    before_tokens = len(encoding.encode(all_messages))\n",
    "    \n",
    "    # 执行裁剪\n",
    "    trimmed_messages = trim_messages(state[\"messages\"], max_messages=3)\n",
    "    \n",
    "    # 计算裁剪后的Token\n",
    "    trimmed_content = \"\".join(m.content for m in trimmed_messages)\n",
    "    after_tokens = len(encoding.encode(trimmed_content))\n",
    "    savings = before_tokens - after_tokens\n",
    "    \n",
    "    print(f\"✂️ 裁剪历史: {len(state['messages'])}条 → {len(trimmed_messages)}条消息\")\n",
    "    print(f\"📉 Token节省: {savings} (原始: {before_tokens} -> 裁剪后: {after_tokens})\")\n",
    "    \n",
    "    return {\"messages\": trimmed_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "047924db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. 构建压缩策略图 ---\n",
    "compress_graph = StateGraph(CompressState)\n",
    "\n",
    "# 添加节点\n",
    "compress_graph.add_node(\"compress\", compress_long_text)\n",
    "compress_graph.add_node(\"answer\", answer_with_compressed_text)\n",
    "compress_graph.add_node(\"trim\", trim_context)\n",
    "\n",
    "# 设置入口点\n",
    "compress_graph.set_entry_point(\"compress\")\n",
    "\n",
    "# 添加边\n",
    "compress_graph.add_edge(\"compress\", \"answer\")\n",
    "compress_graph.add_edge(\"answer\", END)\n",
    "\n",
    "# 添加条件边用于裁剪\n",
    "def should_trim(state: CompressState):\n",
    "    \"\"\"当消息超过5条时触发裁剪\"\"\"\n",
    "    if len(state[\"messages\"]) > 5:\n",
    "        return \"trim\"\n",
    "    return END\n",
    "\n",
    "compress_graph.add_conditional_edges(\"answer\", should_trim, {\"trim\": \"trim\", END: END})\n",
    "compress_graph.add_edge(\"trim\", END)\n",
    "\n",
    "# 编译图\n",
    "compress_workflow = compress_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd584237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### 演示'总结压缩'技术 ###\n",
      "\n",
      "--- COMPRESSING LONG TEXT ---\n",
      "📉 文本压缩: 4861 tokens → 421 tokens (节省 4440 tokens)\n",
      "📝 压缩摘要:\n",
      "本总结涵盖入职四个月以来的核心工作内容，共分五大部分：\n",
      "\n",
      "1. **总体工作概要**：围绕AI技术研究、客户场景驱动、知识管理三方面展开，推动AI能力落地。\n",
      "\n",
      "2. **技术研究**：重点推进多模态图纸识别与RAG技术。前者完成少样本识别、整套图纸提资表及YOLO+VL+context系统Demo，后者实现数据预处理、检索优化与生成界面迭代，具备产品化潜力。\n",
      "\n",
      "3. **项目支持**：聚焦浙江、江...\n",
      "{'compress': {'compressed_text': '本总结涵盖入职四个月以来的核心工作内容，共分五大部分：\\n\\n1. **总体工作概要**：围绕AI技术研究、客户场景驱动、知识管理三方面展开，推动AI能力落地。\\n\\n2. **技术研究**：重点推进多模态图纸识别与RAG技术。前者完成少样本识别、整套图纸提资表及YOLO+VL+context系统Demo，后者实现数据预处理、检索优化与生成界面迭代，具备产品化潜力。\\n\\n3. **项目支持**：聚焦浙江、江苏、广东三省，分别体现“无牵头人”、“有协调人”、“主动团队”三种模式，项目落地仍需解决机制问题。\\n\\n4. **客户对接**：客户对AI认知有限，需求集中在识图与内容生成，未来应挖掘造价软件的AI应用潜力。\\n\\n5. **知识管理**：组织多次技术分享，个人学习模型开发、框架使用等技能，推动学习型组织建设。\\n\\n**下半年计划**包括技术深化、项目落地、软件AI潜能挖掘和知识赋能，建议建立协同机制、知识资产体系及创新孵化小组，以支撑长期发展。', 'token_savings': 4440, 'messages': [HumanMessage(content='基于以下摘要回答问题:\\n本总结涵盖入职四个月以来的核心工作内容，共分五大部分：\\n\\n1. **总体工作概要**：围绕AI技术研究、客户场景驱动、知识管理三方面展开，推动AI能力落地。\\n\\n2. **技术研究**：重点推进多模态图纸识别与RAG技术。前者完成少样本识别、整套图纸提资表及YOLO+VL+context系统Demo，后者实现数据预处理、检索优化与生成界面迭代，具备产品化潜力。\\n\\n3. **项目支持**：聚焦浙江、江苏、广东三省，分别体现“无牵头人”、“有协调人”、“主动团队”三种模式，项目落地仍需解决机制问题。\\n\\n4. **客户对接**：客户对AI认知有限，需求集中在识图与内容生成，未来应挖掘造价软件的AI应用潜力。\\n\\n5. **知识管理**：组织多次技术分享，个人学习模型开发、框架使用等技能，推动学习型组织建设。\\n\\n**下半年计划**包括技术深化、项目落地、软件AI潜能挖掘和知识赋能，建议建立协同机制、知识资产体系及创新孵化小组，以支撑长期发展。\\n\\n问题: 这段时间做了哪些工作?', additional_kwargs={}, response_metadata={})]}}\n",
      "---\n",
      "\n",
      "--- ANSWERING WITH COMPRESSED TEXT ---\n",
      "💡 生成的回答: 这段时间的工作主要围绕以下五个核心方面展开：\n",
      "\n",
      "1. **总体工作概要**：围绕AI技术研究、客户场景驱动和知识管理三个方面推进，致力于将AI能力落地应用。\n",
      "\n",
      "2. **技术研究**：\n",
      "   - 推进多模态图纸识别技术，完成少样本识别、整套图纸提资表以及YOLO+VL+context系统的Demo开发。\n",
      "   - 研究RAG（Retrieval-Augmented Generation）技术，实现数据预处理、检索优化与生成界面的迭代，具备产品化潜力。\n",
      "\n",
      "3. **项目支持**：\n",
      "   - 聚焦浙江、江苏、广东三省，分别采用“无牵头人”、“有协调人”、“主动团队”三种模式推进项目。\n",
      "   - 当前项目落地仍需解决机制问题。\n",
      "\n",
      "4. **客户对接**：\n",
      "   - 客户对AI的认知有限，需求集中在识图与内容生成。\n",
      "   - 未来应进一步挖掘AI在造价软件中的应用潜力。\n",
      "\n",
      "5. **知识管理**：\n",
      "   - 组织多次技术分享，推动团队学习氛围。\n",
      "   - 个人在模型开发、框架使用等方面持续学习，助力学习型组织建设。\n",
      "\n",
      "整体上，工作聚焦于技术探索、项目实践、客户沟通与知识沉淀，为后续AI能力的深化与落地打下基础。\n",
      "{'answer': {'messages': [AIMessage(content='这段时间的工作主要围绕以下五个核心方面展开：\\n\\n1. **总体工作概要**：围绕AI技术研究、客户场景驱动和知识管理三个方面推进，致力于将AI能力落地应用。\\n\\n2. **技术研究**：\\n   - 推进多模态图纸识别技术，完成少样本识别、整套图纸提资表以及YOLO+VL+context系统的Demo开发。\\n   - 研究RAG（Retrieval-Augmented Generation）技术，实现数据预处理、检索优化与生成界面的迭代，具备产品化潜力。\\n\\n3. **项目支持**：\\n   - 聚焦浙江、江苏、广东三省，分别采用“无牵头人”、“有协调人”、“主动团队”三种模式推进项目。\\n   - 当前项目落地仍需解决机制问题。\\n\\n4. **客户对接**：\\n   - 客户对AI的认知有限，需求集中在识图与内容生成。\\n   - 未来应进一步挖掘AI在造价软件中的应用潜力。\\n\\n5. **知识管理**：\\n   - 组织多次技术分享，推动团队学习氛围。\\n   - 个人在模型开发、框架使用等方面持续学习，助力学习型组织建设。\\n\\n整体上，工作聚焦于技术探索、项目实践、客户沟通与知识沉淀，为后续AI能力的深化与落地打下基础。', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-30b-a3b'}, id='run--d4910bbf-b07d-4b32-be9f-a86cdec0c46b-0', usage_metadata={'input_tokens': 283, 'output_tokens': 282, 'total_tokens': 565, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# --- 5. 演示总结压缩 ---\n",
    "print(\"\\n### 演示'总结压缩'技术 ###\")\n",
    "question = \"这段时间做了哪些工作?\"\n",
    "\n",
    "# 初始状态\n",
    "initial_state = CompressState(\n",
    "    messages=[SystemMessage(content=\"你是一个分析师\"), HumanMessage(content=question)],\n",
    "    original_text=long_article,\n",
    "    compressed_text=\"\",\n",
    "    token_savings=0\n",
    ")\n",
    "\n",
    "# 执行工作流\n",
    "for step in compress_workflow.stream(initial_state):\n",
    "    if \"__end__\" not in step:\n",
    "        print(step)\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77dc2c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### 演示'裁剪压缩'技术 ###\n",
      "\n",
      "--- TRIMMING CONTEXT ---\n",
      "✂️ 裁剪历史: 13条 → 4条消息\n",
      "📉 Token节省: 169 (原始: 250 -> 裁剪后: 81)\n",
      "\n",
      "裁剪前消息:\n",
      "🤖 您已接入电力工程设计软件客服助手\n",
      "👤 你好，我想了解电力设计协同平台支持哪些设计专业？\n",
      "👤 需要导入国网典型设计方案时，系统有预置模板吗？\n",
      "👤 标准物料库更新后，如何同步到现有项目？\n",
      "👤 可视化图形平台是否支持三维设计功能？\n",
      "👤 设计成果能否直接生成符合行业标准的PDF报告？\n",
      "👤 初次使用的话，有没有提供试用版本？\n",
      "👤 技术支持是7x24小时响应吗？服务等级怎么划分？\n",
      "👤 如果需要定制开发，费用是怎么计算的？\n",
      "👤 项目完成后，是否提供项目报告？\n",
      "👤 请问如何获取最新的产品手册和用户指南？\n",
      "👤 我对电力造价管理系统的核心功能很感兴趣，请给我详细介绍。\n",
      "👤 请给我详细介绍电力造价管理系统的核心功能。\n",
      "\n",
      "裁剪后消息:\n",
      "🤖 您已接入电力工程设计软件客服助手\n",
      "👤 请问如何获取最新的产品手册和用户指南？\n",
      "👤 我对电力造价管理系统的核心功能很感兴趣，请给我详细介绍。\n",
      "👤 请给我详细介绍电力造价管理系统的核心功能。\n"
     ]
    }
   ],
   "source": [
    "# --- 6. 演示对话历史裁剪 ---\n",
    "print(\"\\n### 演示'裁剪压缩'技术 ###\")\n",
    "\n",
    "# 创建一个长对话历史\n",
    "long_chat_history = [\n",
    "    SystemMessage(content=\"您已接入电力工程设计软件客服助手\"),\n",
    "    HumanMessage(content=\"你好，我想了解电力设计协同平台支持哪些设计专业？\"),\n",
    "    HumanMessage(content=\"需要导入国网典型设计方案时，系统有预置模板吗？\"),\n",
    "    HumanMessage(content=\"标准物料库更新后，如何同步到现有项目？\"),\n",
    "    HumanMessage(content=\"可视化图形平台是否支持三维设计功能？\"),\n",
    "    HumanMessage(content=\"设计成果能否直接生成符合行业标准的PDF报告？\"),\n",
    "    HumanMessage(content=\"初次使用的话，有没有提供试用版本？\"),\n",
    "    HumanMessage(content=\"技术支持是7x24小时响应吗？服务等级怎么划分？\"),\n",
    "    HumanMessage(content=\"如果需要定制开发，费用是怎么计算的？\"),\n",
    "    HumanMessage(content=\"项目完成后，是否提供项目报告？\"),\n",
    "    HumanMessage(content=\"请问如何获取最新的产品手册和用户指南？\"),\n",
    "    HumanMessage(content=\"我对电力造价管理系统的核心功能很感兴趣，请给我详细介绍。\"),\n",
    "    HumanMessage(content=\"请给我详细介绍电力造价管理系统的核心功能。\")\n",
    "]\n",
    "\n",
    "# 初始状态（无文本压缩）\n",
    "trim_demo_state = CompressState(\n",
    "    messages=long_chat_history,\n",
    "    original_text=\"\",\n",
    "    compressed_text=\"\",\n",
    "    token_savings=0\n",
    ")\n",
    "\n",
    "# 执行裁剪\n",
    "trimmed_state = trim_context(trim_demo_state)\n",
    "\n",
    "# 显示裁剪效果\n",
    "print(\"\\n裁剪前消息:\")\n",
    "for i, msg in enumerate(long_chat_history):\n",
    "    prefix = \"🤖\" if isinstance(msg, SystemMessage) else \"👤\"\n",
    "    print(f\"{prefix} {msg.content[:50]}{'...' if len(msg.content) > 50 else ''}\")\n",
    "\n",
    "print(\"\\n裁剪后消息:\")\n",
    "for i, msg in enumerate(trimmed_state['messages']):\n",
    "    prefix = \"🤖\" if isinstance(msg, SystemMessage) else \"👤\"\n",
    "    print(f\"{prefix} {msg.content[:50]}{'...' if len(msg.content) > 50 else ''}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa94b02",
   "metadata": {},
   "source": [
    "## **策略四：隔离 (Isolate) - \"分而治之\"的架构智慧**\n",
    "\n",
    "**核心思想：** 将复杂任务分解为多个子任务，由专门的智能体在隔离环境中处理，避免上下文污染。\n",
    "\n",
    "**实现多智能体架构：** 创建专家智能体团队（分析师+文案）\n",
    "\n",
    "**场景演示：** 用户上传销售数据CSV，要求分析销售冠军并撰写营销文案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca6ab70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 准备数据 ---\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# 创建示例销售数据CSV\n",
    "sales_data = \"\"\"\n",
    "日期,产品,销售额,销售量\n",
    "2024-01-01,电力造价管理系统V3.0,320000,4  \n",
    "2024-01-01,电力设计协同平台Pro,240000,3   \n",
    "2024-01-01,易数大数据分析平台,180000,2     \n",
    "2024-01-01,电力管理工具集标准版,95000,5  \n",
    "2024-01-02,电力造价管理系统V3.0,280000,3.5\n",
    "2024-01-02,电力设计协同平台Pro,220000,2.75\n",
    "2024-01-02,易数大数据分析平台,170000,1.89\n",
    "2024-01-02,电力管理工具集标准版,88000,4.7\n",
    "2024-01-03,电力造价管理系统V3.0,360000,4.5\n",
    "2024-01-03,电力设计协同平台Pro,260000,3.25\n",
    "2024-01-03,易数大数据分析平台,190000,2.11\n",
    "2024-01-03,电力管理工具集标准版,102000,5.3\n",
    "2024-01-04,电力造价管理系统V3.0,300000,3.75\n",
    "2024-01-04,电力设计协同平台Pro,230000,2.88\n",
    "2024-01-04,易数大数据分析平台,175000,1.94\n",
    "2024-01-04,电力管理工具集标准版,92000,4.85\n",
    "2024-01-05,电力造价管理系统V3.0,400000,5   \n",
    "2024-01-05,电力设计协同平台Pro,320000,4 \n",
    "2024-01-05,易数大数据分析平台,220000,2.44\n",
    "2024-01-05,电力管理工具集标准版,110000,5.5\n",
    "\"\"\"\n",
    "\n",
    "# 保存为CSV文件\n",
    "with open(\"sales_data.csv\", \"w\") as f:\n",
    "    f.write(sales_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bcf219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. 定义状态 ---\n",
    "# 定义多智能体协作的状态\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    task: str\n",
    "    analysis_result: str\n",
    "    final_output: str\n",
    "    next_agent: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22cb0128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 定义工具 ---\n",
    "@tool\n",
    "def analyze_sales_data(question: str) -> str:\n",
    "    \"\"\"\n",
    "    分析销售数据CSV文件，找出销售额最高的产品及其销售总额。\n",
    "    参数:\n",
    "        question (str): 用户的原始问题，用于记录分析背景。\n",
    "    返回:\n",
    "        str: 一个逗号分隔的字符串，包含产品名称和总销售额，例如 \"产品A,150000\"。\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- TOOL: ANALYZE SALES DATA ---\")\n",
    "    print(f\"📝 分析任务: {question}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(\"sales_data.csv\")\n",
    "        product_sales = df.groupby(\"产品\")[\"销售额\"].sum()\n",
    "        top_product = product_sales.idxmax()\n",
    "        top_sales = product_sales.max()\n",
    "        result = f\"{top_product},{top_sales}\"\n",
    "        print(f\"🏆 分析结果: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"分析失败: {e}\"\n",
    "\n",
    "@tool\n",
    "def write_marketing_copy(product: str, key_points: str) -> str:\n",
    "    \"\"\"\n",
    "    为指定产品撰写营销文案。\n",
    "    参数:\n",
    "        product (str): 需要撰写文案的产品名称。\n",
    "        key_points (str): 文案需要围绕的核心卖点。\n",
    "    返回:\n",
    "        str: 生成的营销文案。\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- TOOL: WRITE MARKETING COPY ---\")\n",
    "    print(f\"📝 撰写文案: {product} - {key_points[:50]}...\")\n",
    "    \n",
    "    writer_prompt = ChatPromptTemplate.from_template(\n",
    "        \"你是一个专业营销文案。请基于以下产品信息撰写一篇不超过150字的吸引人的营销文案:\\n\"\n",
    "        \"产品名称: {product}\\n\"\n",
    "        \"核心卖点: {key_points}\\n\"\n",
    "        \"文案:\"\n",
    "    )\n",
    "    writer_chain = writer_prompt | model | StrOutputParser()\n",
    "    \n",
    "    return writer_chain.invoke({\"product\": product, \"key_points\": key_points})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd1b3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. 创建智能体 ---\n",
    "\n",
    "# Helper function to create a specialist agent\n",
    "def create_agent(system_prompt: str, tools: list):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ])\n",
    "    agent = prompt | model.bind_tools(tools)\n",
    "    return agent\n",
    "\n",
    "# 分析师智能体\n",
    "analyst_agent = create_agent(\n",
    "    \"你是一名专业的数据分析师。你的任务是分析给定的数据并返回关键结果。请使用`analyze_sales_data`工具来完成任务。\",\n",
    "    [analyze_sales_data]\n",
    ")\n",
    "\n",
    "# 文案智能体\n",
    "writer_agent = create_agent(\n",
    "    \"你是一名专业的营销文案。你的任务是根据分析结果，为产品撰写引人注目的营销文案。请使用`write_marketing_copy`工具来完成任务。\",\n",
    "    [write_marketing_copy]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5334c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. 定义智能体节点 ---\n",
    "\n",
    "def analyst_node(state: AgentState):\n",
    "    print(\"\\n--- CALLING ANALYST AGENT ---\")\n",
    "    result = analyst_agent.invoke({\"messages\": [HumanMessage(content=state['task'])]})\n",
    "    return {\"messages\": [result]}\n",
    "\n",
    "def writer_node(state: AgentState):\n",
    "    print(\"\\n--- CALLING WRITER AGENT ---\")\n",
    "    # 从state中提取分析结果，并作为输入传递给文案智能体\n",
    "    product, sales = state['analysis_result'].split(',')\n",
    "    prompt = f\"分析结果：销售冠军是‘{product}’，总销售额为 {sales} 元。请为此产品撰写营销文案。\"\n",
    "    result = writer_agent.invoke({\"messages\": [HumanMessage(content=prompt)]})\n",
    "    return {\"messages\": [result]}\n",
    "\n",
    "# 定义工具执行节点\n",
    "tool_node = ToolNode([analyze_sales_data, write_marketing_copy])\n",
    "\n",
    "def execute_tools(state: AgentState):\n",
    "    print(\"\\n--- EXECUTING TOOLS ---\")\n",
    "    last_message = state['messages'][-1]\n",
    "    tool_call = last_message.tool_calls[0]\n",
    "    \n",
    "    # 执行工具\n",
    "    tool_result = tool_node.invoke([last_message])\n",
    "    \n",
    "    # 根据工具更新状态\n",
    "    if tool_call['name'] == 'analyze_sales_data':\n",
    "        return {\"messages\": tool_result, \"analysis_result\": tool_result[0].content}\n",
    "    elif tool_call['name'] == 'write_marketing_copy':\n",
    "        return {\"messages\": tool_result, \"final_output\": tool_result[0].content}\n",
    "    \n",
    "    return {\"messages\": tool_result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea160988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. 构建图 (Supervisor模式) ---\n",
    "\n",
    "def supervisor_router(state: AgentState):\n",
    "    \"\"\"路由：决定下一个应该由哪个智能体来处理\"\"\"\n",
    "    print(\"\\n--- SUPERVISOR ---\")\n",
    "\n",
    "    # 如果分析结果还未产生，则分配给分析师\n",
    "    if not state.get(\"analysis_result\"):\n",
    "        print(\"📋 任务分配: 分析师 (Analyst)\")\n",
    "        return \"analyst\"\n",
    "        \n",
    "    # 如果分析已完成但文案还未撰写，则分配给文案\n",
    "    if state.get(\"analysis_result\") and not state.get(\"final_output\"):\n",
    "        print(\"📋 任务分配: 文案撰写 (Writer)\")\n",
    "        return \"writer\"\n",
    "        \n",
    "    # 如果一切都完成了\n",
    "    print(\"✅ 所有任务完成\")\n",
    "    return END\n",
    "\n",
    "# 构建图\n",
    "isolate_graph = StateGraph(AgentState)\n",
    "\n",
    "isolate_graph.add_node(\"analyst\", analyst_node)\n",
    "isolate_graph.add_node(\"writer\", writer_node)\n",
    "isolate_graph.add_node(\"execute_tools\", execute_tools)\n",
    "\n",
    "# 设置入口点\n",
    "isolate_graph.set_entry_point(\"analyst\")\n",
    "\n",
    "# 定义图的边\n",
    "isolate_graph.add_edge(\"analyst\", \"execute_tools\")\n",
    "isolate_graph.add_edge(\"writer\", \"execute_tools\")\n",
    "isolate_graph.add_conditional_edges(\n",
    "    \"execute_tools\",\n",
    "    supervisor_router,\n",
    "    {\"analyst\": \"analyst\", \"writer\": \"writer\", END: END}\n",
    ")\n",
    "\n",
    "# 编译工作流\n",
    "isolate_workflow = isolate_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e0bce9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### 演示多智能体协作 (Supervisor模式) ###\n",
      "\n",
      "--- CALLING ANALYST AGENT ---\n",
      "--- [analyst] 步骤完成 ---\n",
      "\n",
      "--- EXECUTING TOOLS ---\n",
      "\n",
      "--- TOOL: ANALYZE SALES DATA ---\n",
      "📝 分析任务: 分析销售数据找出销售额最高的产品，然后为该产品撰写一篇吸引人的营销文案。\n",
      "🏆 分析结果: 电力造价管理系统V3.0,1660000\n",
      "\n",
      "--- SUPERVISOR ---\n",
      "📋 任务分配: 文案撰写 (Writer)\n",
      "--- [execute_tools] 步骤完成 ---\n",
      "\n",
      "--- CALLING WRITER AGENT ---\n",
      "--- [writer] 步骤完成 ---\n",
      "\n",
      "--- EXECUTING TOOLS ---\n",
      "\n",
      "--- TOOL: WRITE MARKETING COPY ---\n",
      "📝 撰写文案: 电力造价管理系统V3.0 - 销售冠军，总销售额为1660000元...\n",
      "\n",
      "--- SUPERVISOR ---\n",
      "✅ 所有任务完成\n",
      "--- [execute_tools] 步骤完成 ---\n",
      "\n",
      "🎉 最终文案:\n",
      "电力造价管理系统V3.0，销售冠军，总销售额突破166万元！精准计算、高效管理，助力企业降本增效。智能报价、数据可视化，让造价更轻松。选择V3.0，成就卓越工程！\n"
     ]
    }
   ],
   "source": [
    "# --- 7. 执行多智能体协作 ---\n",
    "print(\"\\n### 演示多智能体协作 (Supervisor模式) ###\")\n",
    "task = (\n",
    "    \"分析销售数据找出销售额最高的产品，\"\n",
    "    \"然后为该产品撰写一篇吸引人的营销文案。\"\n",
    ")\n",
    "initial_state = AgentState(\n",
    "    messages=[],\n",
    "    task=task,\n",
    "    analysis_result=\"\",\n",
    "    final_output=\"\",\n",
    "    next_agent=\"analyst\"\n",
    ")\n",
    "\n",
    "# 执行工作流\n",
    "for step in isolate_workflow.stream(initial_state, {\"recursion_limit\": 10}):\n",
    "    node = list(step.keys())[0]\n",
    "    state = step[node]\n",
    "    print(f\"--- [{node}] 步骤完成 ---\")\n",
    "    if \"final_output\" in state and state[\"final_output\"]:\n",
    "        print(f\"\\n🎉 最终文案:\\n{state['final_output']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
