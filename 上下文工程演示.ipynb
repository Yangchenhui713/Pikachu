{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e2281b",
   "metadata": {},
   "source": [
    "# **ä½¿ç”¨ LangGraph å’Œ Qwen æ¨¡å‹å®ç°ä¸Šä¸‹æ–‡å·¥ç¨‹å››å¤§ç­–ç•¥**\n",
    "\n",
    "### **ç›®æ ‡**\n",
    "æœ¬ Notebook å°†ä½œä¸ºä¸€ä»½è¯¦ç»†çš„æŠ€æœ¯æŒ‡å—ï¼Œæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ LangGraph æ¡†æ¶å’Œé€šä¹‰åƒé—®ï¼ˆQwenï¼‰æ¨¡å‹ï¼Œä¸€æ­¥æ­¥å®ç°â€œä¸Šä¸‹æ–‡å·¥ç¨‹â€çš„å››å¤§æ ¸å¿ƒç­–ç•¥ã€‚\n",
    "\n",
    "å››å¤§ç­–ç•¥åŒ…æ‹¬ï¼š\n",
    "1.  **å†™å…¥ (Write):** ä¸ºæ™ºèƒ½ä½“æ„å»ºä¸€ä¸ªâ€œå¤–éƒ¨å¤§è„‘â€ï¼ˆæš‚å­˜åŒºï¼‰ï¼Œä»¥åœ¨é•¿ä»»åŠ¡ä¸­ä¿æŒçŠ¶æ€ã€‚\n",
    "2.  **é€‰æ‹© (Select):** ä½¿ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ä»çŸ¥è¯†åº“ä¸­ç²¾å‡†è°ƒå–ä¿¡æ¯ã€‚\n",
    "3.  **å‹ç¼© (Compress):** æ™ºèƒ½åœ°æ€»ç»“å¯¹è¯å†å²ï¼Œä»¥èŠ‚çœæˆæœ¬å’ŒTokenã€‚\n",
    "4.  **éš”ç¦» (Isolate):** ä½¿ç”¨å¤šæ™ºèƒ½ä½“ï¼ˆMulti-agentï¼‰æ¶æ„ï¼Œå°†å¤æ‚ä»»åŠ¡åˆ†è§£ç»™ä¸“å®¶å¤„ç†ã€‚\n",
    "\n",
    "---\n",
    "### **ç¬¬ä¸€æ­¥ï¼šç¯å¢ƒè®¾ç½®ä¸æ¨¡å‹åˆå§‹åŒ–**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ddefae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.cloud.aliyuncs.com/pypi/simple/\n",
      "Collecting langchain\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/f1/f2/c09a2e383283e3af1db669ab037ac05a45814f4b9c472c48dc24c0cef039/langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-qwq\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/06/f8/3f0419be750e897a4c4ebf932096722216ac43512b25aedae05f916cbd47/langchain_qwq-0.2.0-py3-none-any.whl (16 kB)\n",
      "Collecting langgraph\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/d7/2f/11be9302d3a213debcfe44355453a1e8fd7ee5e3138edeb8bd82b56bc8f6/langgraph-0.5.3-py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m903.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/07/5f/63760ff107bcf5146eee41b38b3985f9055e710a72fdd637b791dea3495c/pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/5f/ed/539768cf28c661b5b068d66d96a2f155c4971a5d55684a514c1a0e0dec2f/python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Collecting langchain_community\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/c8/bc/f8c7dae8321d37ed39ac9d7896617c4203248240a4835b136e3724b3bb62/langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dashscope\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/61/3f/2d1e656e997ddfaf3a3fde74d9b5120689338e4435ecc26b5c95720a6dc9/dashscope-1.23.9-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting faiss-cpu\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/84/30/e06cfcedf4664907f39a93f21988149f05ae7fef62e988abb9e99940beeb/faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting langchain-core<1.0.0,>=0.3.66 (from langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/51/7b/bb7b088440ff9cc55e9e6eba94162cbdcd3b1693c194e1ad4764acba29b9/langchain_core-0.3.69-py3-none-any.whl (441 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m441.6/441.6 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/8b/a3/3696ff2444658053c01b6b7443e761f28bb71217d82bb89137a978c5f66f/langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/19/4f/481324462c44ce21443b833ad73ee51117031d41c16fec06cddbb7495b26/langsmith-0.4.8-py3-none-any.whl (367 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m368.0/368.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/6a/c0/ec2b1c8712ca690e5d61979dee872603e92b8a32f94cc1b72d53beab008a/pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/62/e4/b9a7a0e5c6f79d49bcd6efb6e90d7536dc604dab64582a9dec220dab54b6/sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests<3,>=2 (from langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/7c/e4/56027c4a6b4ae70ca9de302488c5ca95ad4a39e190093d6c1a8ace08341b/requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/75/e4/2c27590dfc9992f73aabbeb9241ae20220bd9452df27483b6e56d3975cc5/PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting json-repair<0.41.0,>=0.40.0 (from langchain-qwq)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/f4/e1/f0e63cc027669763ccc2c1e62ba69959ec02db5328c81df2508a52711ec9/json_repair-0.40.0-py3-none-any.whl (20 kB)\n",
      "Collecting langchain-openai<0.4.0,>=0.3.11 (from langchain-qwq)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/91/56/75f3d84b69b8bdae521a537697375e1241377627c32b78edcae337093502/langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m867.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting openai<2.0.0,>=1.70.0 (from langchain-qwq)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/8a/91/1f1cf577f745e956b276a8b1d3d76fa7a6ee0c2b05db3b001b900f2c71db/openai-1.97.0-py3-none-any.whl (764 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m765.0/765.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/4c/dd/64686797b0927fb18b290044be12ae9d4df01670dce6bb2498d5ab65cb24/langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langgraph-prebuilt<0.6.0,>=0.5.0 (from langgraph)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/c3/64/6bc45ab9e0e1112698ebff579fe21f5606ea65cd08266995a357e312a4d2/langgraph_prebuilt-0.5.2-py3-none-any.whl (23 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/77/86/56e01e715e5b0028cdaff1492a89e54fa12e18c21e03b805a10ea36ecd5a/langgraph_sdk-0.1.73-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m467.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting xxhash>=3.5.0 (from langgraph)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/d9/72/9256303f10e41ab004799a4aa74b80b3c5977d6383ae4550548b24bd1971/xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m661.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.23.2 (from pandas)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/75/c9/9bec03675192077467a9c7c2bdd1f2e922bd01d3a69b15c3a0fdcd8548f6/numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /root/.local/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/81/c4/34e93fe5f5429d7570ec1fa436f1986fb1f00c3e0f43a589fe2bbcd22c3f/pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/5c/23/c7abc0ca0a1526a0774eca151daeb8de62ec457e77262b66b359c3c7679e/tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/e0/30/aadcdf71b510a718e3d98a7bfeaea2396ac847f218b7e8edb241b09bd99a/aiohttp-3.12.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain_community)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/e5/30/643397144bfbfec6f6ef821f36f33e57d35946c44a2352d3c9f0ae847619/tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/c3/be/d0d44e092656fe7a06b55e6103cbce807cdbdee17884a5367c68c9860853/dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/58/f0/427018098906416f580e3cf1366d3b1abfb408a0652e9f31600c24a1903c/pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/25/0a/6269e3473b09aed2dab8aa1a600c70f31f00ae1349bee30658f7e358a159/httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Collecting websocket-client (from dashscope)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/5a/84/44687a29792a70e111c5c477230a72c4b957d88d16141199bf9acb7537a3/websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cryptography (from dashscope)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/c9/d8/0749f7d39f53f8258e5c18a93131919ac465ee1f9dccaf1b3f420235e0b5/cryptography-45.0.5-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /root/.local/lib/python3.11/site-packages (from faiss-cpu) (25.0)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/0f/15/5bf3b99495fb160b63f95972b81750f18f7f4e02ad051373b669d17d44f2/aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/fb/76/641ae371508676492379f16e2fa48f4e2c11741bd63c48be4b12a6b09cba/aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/77/06/bb80f5f86020c4551da315d78b3ab75e8228f89f0162f2c3a819e407941a/attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/4d/83/220a374bd7b2aeba9d0725130665afe11de347d95c3620b9b82cc2fcab97/frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m235.3/235.3 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/74/07/2c9246cda322dfe08be85f1b8739646f2c4c5113a1422d7a407763422ec4/multidict-6.6.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m246.6/246.6 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/5d/e6/116ba39448753b1330f48ab8ba927dcd6cf0baea8a0ccbc512dfb49ba670/propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m213.5/213.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/00/70/8f78a95d6935a70263d46caa3dd18e1f223cf2f2ff2037baa01a22bc5b22/yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m349.0/349.0 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/34/75/51952c7b2d3873b44a0028b1bd26a25078c18f92f256608e8d1dc61b39fd/marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /root/.local/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.1)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai<0.4.0,>=0.3.11->langchain-qwq)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/b1/73/41591c525680cd460a6becf56c9b17468d3711b1df242c53d2c7b2183d16/tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/4e/92/7c91e8115fc37e88d1a35e13200fda3054ff5d2e5adf017345e58cea4834/ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting httpx>=0.25.2 (from langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting orjson>=3.10.1 (from langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/67/4f/d22f79a3c56dde563c4fbc12eebf9224a1b87af5e4ec61beb11f9b3eb499/orjson-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (127 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 kB\u001b[0m \u001b[31m776.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/76/3f/dbafccf19cfeca25bbabf6f2dd81796b7218f768ec400f043edc767015a6/zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting anyio<5,>=3.5.0 (from openai<2.0.0,>=1.70.0->langchain-qwq)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/a1/ee/48ca1a7c89ffec8b6a0c5d02b89c305671d5ffd8d3c94acf8b8c408575bb/anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.70.0->langchain-qwq)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.70.0->langchain-qwq)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/81/5a/0e73541b6edd3f4aada586c24e50626c7815c561a7ba337d6a7eb0a915b4/jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m352.2/352.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sniffio (from openai<2.0.0,>=1.70.0->langchain-qwq)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.70.0->langchain-qwq)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/47/bc/cd720e078576bdb8255d5032c5d63ee5c0bf4b7173dd955185a1d658c456/pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/17/69/cd203477f944c353c31bade965f880aa1061fd6bf05ded0726ca845b6ff7/typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: six>=1.5 in /root/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/92/9b/ad67f03d74554bed3aefd56fe836e1623a50780f7c998d00ca128924a499/charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.3/147.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/76/c6/c88e154df9c4e1a2a66ccf0005a88dfb2650c1dffb6f5ce603dfbd452ce3/idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/a7/c2/fe1e52489ae3122415c51f387e221dd0773709bad6c6cdaa599e8a2c5185/urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/4f/52/34c6cf5bb9285074dc3531c437b3919e825d976fde097a7a73f79e726d03/certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m162.7/162.7 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/65/89/77acf9e3da38e9bcfca881e43b02ed467c1dedc387021fc4d9bd9928afb8/greenlet-3.2.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (585 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m585.5/585.5 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cffi>=1.14 (from cryptography->dashscope)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/ff/6b/d45873c5e0242196f042d555526f92aa9e0c32355a1be1ff8c27f077fd37/cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (467 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m467.2/467.2 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pycparser (from cffi>=1.14->cryptography->dashscope)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/13/a3/a812df4e2dd5696d1f351d58b8fe16a405b234ad2886a0dab9183fb78109/pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpcore==1.* (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/7e/f5/f66802a942d491edb555dd61e3a9961140fd64c90bce1eafd741609d334d/httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/04/4b/29cac41a4d98d144bf5f6d33995617b185d14b22401f75ca86f384e87ff1/h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/71/92/5e77f98553e9e75130c78900d000368476aed74276eb8ae8796f65f00918/jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai<0.4.0,>=0.3.11->langchain-qwq)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/bf/ce/0d0e61429f603bac433910d99ef1a02ce45a8967ffbe3cbee48599e62d88/regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/79/7b/2c79738432f5c924bef5071f933bcc9efd0473bac3b4aa584a6f7c1c8df8/mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: pytz, zstandard, xxhash, websocket-client, urllib3, tzdata, typing-inspection, tqdm, tenacity, sniffio, regex, PyYAML, python-dotenv, pydantic-core, pycparser, propcache, ormsgpack, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpointer, json-repair, jiter, idna, httpx-sse, h11, greenlet, frozenlist, distro, charset_normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests, pydantic, pandas, jsonpatch, httpcore, faiss-cpu, cffi, anyio, aiosignal, tiktoken, requests-toolbelt, pydantic-settings, httpx, dataclasses-json, cryptography, aiohttp, openai, langsmith, langgraph-sdk, dashscope, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langgraph-prebuilt, langchain-qwq, langchain, langgraph, langchain_community\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.41 aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.9.0 attrs-25.3.0 certifi-2025.7.14 cffi-1.17.1 charset_normalizer-3.4.2 cryptography-45.0.5 dashscope-1.23.9 dataclasses-json-0.6.7 distro-1.9.0 faiss-cpu-1.11.0.post1 frozenlist-1.7.0 greenlet-3.2.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.1 idna-3.10 jiter-0.10.0 json-repair-0.40.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.26 langchain-core-0.3.69 langchain-openai-0.3.28 langchain-qwq-0.2.0 langchain-text-splitters-0.3.8 langchain_community-0.3.27 langgraph-0.5.3 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.5.2 langgraph-sdk-0.1.73 langsmith-0.4.8 marshmallow-3.26.1 multidict-6.6.3 mypy-extensions-1.1.0 numpy-2.3.1 openai-1.97.0 orjson-3.11.0 ormsgpack-1.10.0 pandas-2.3.1 propcache-0.3.2 pycparser-2.22 pydantic-2.11.7 pydantic-core-2.33.2 pydantic-settings-2.10.1 python-dotenv-1.1.1 pytz-2025.2 regex-2024.11.6 requests-2.32.4 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 tiktoken-0.9.0 tqdm-4.67.1 typing-inspect-0.9.0 typing-inspection-0.4.1 tzdata-2025.2 urllib3-2.5.0 websocket-client-1.8.0 xxhash-3.5.0 yarl-1.20.1 zstandard-0.23.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/python3.11/bin/python3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain langchain-qwq langgraph pandas python-dotenv langchain_community dashscope faiss-cpu pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0417ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import json\n",
    "import operator\n",
    "from typing import List, TypedDict, Annotated\n",
    "\n",
    "import tiktoken\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, ToolMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_qwq import ChatQwen\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1547b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. è®¾ç½®APIå¯†é’¥ ---\n",
    "# è¯·æ³¨æ„ï¼šè¿™é‡Œéœ€è¦çš„æ˜¯ DashScope çš„ API Key\n",
    "if \"DASHSCOPE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"DASHSCOPE_API_KEY\"] = getpass.getpass(\"è¯·è¾“å…¥æ‚¨çš„DashScope API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef5d7428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼\n"
     ]
    }
   ],
   "source": [
    "# --- 2. åˆå§‹åŒ–Qwenæ¨¡å‹ ---\n",
    "# æˆ‘ä»¬å°†ä½¿ç”¨ qwen3-32b æ¨¡å‹ä½œä¸ºæˆ‘ä»¬æ™ºèƒ½ä½“çš„â€œå¤§è„‘â€\n",
    "try:\n",
    "    model = ChatQwen(model=\"qwen3-30b-a3b\", base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",  enable_thinking=False)\n",
    "    print(\"Qwen æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼\")\n",
    "except Exception as e:\n",
    "    print(f\"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥API Keyæˆ–ç½‘ç»œè¿æ¥: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc73c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. åˆå§‹åŒ–Tokenè®¡ç®—å™¨ ---\n",
    "# è¿™å°†å¸®åŠ©æˆ‘ä»¬é‡åŒ–â€œå‹ç¼©â€ç­–ç•¥å¸¦æ¥çš„æ•ˆæœ\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a80f1e5",
   "metadata": {},
   "source": [
    "## **ç­–ç•¥ä¸€ï¼šå†™å…¥ (Write) - æ„å»ºæ™ºèƒ½ä½“çš„â€œè‰ç¨¿çº¸â€**\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³:** ä¸æŠŠæ‰€æœ‰ä¸­é—´æ­¥éª¤å’Œæ€è€ƒéƒ½å¡è¿›ä¸»å¯¹è¯å†å²ï¼ˆ`messages`ï¼‰ï¼Œè€Œæ˜¯å°†å®ƒä»¬â€œå†™å…¥â€åˆ°ä¸€ä¸ªç‹¬ç«‹çš„â€œæš‚å­˜åŒºâ€ï¼ˆ`scratchpad`ï¼‰ã€‚è¿™å¯ä»¥ä¿æŒä¸»å¯¹è¯çš„æ¸…æ™°ï¼Œå¹¶ä¸ºæ™ºèƒ½ä½“æä¾›ä¸€ä¸ªå¯é çš„çŸ­æœŸè®°å¿†ï¼Œé˜²æ­¢åœ¨é•¿ä»»åŠ¡ä¸­â€œå¤±å¿†â€ã€‚\n",
    "\n",
    "**å®ç°:** æˆ‘ä»¬å°†åœ¨`AgentState`ä¸­å¢åŠ ä¸€ä¸ª`scratchpad`å­—æ®µï¼Œå¹¶é€šè¿‡æ·»åŠ `SystemMessage`æ¥æŒ‡å¯¼æ¨¡å‹çš„è¡Œä¸ºï¼Œé˜²æ­¢æ— é™å¾ªç¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63a46ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. å®šä¹‰çŠ¶æ€ ---\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List, Annotated\n",
    "import operator\n",
    "\n",
    "class ToolCallRecord(TypedDict):\n",
    "    step: int\n",
    "    tool_name: str\n",
    "    args: dict\n",
    "    result: str\n",
    "\n",
    "class WriteStrategyState(TypedDict):\n",
    "    messages: Annotated[list, operator.add]\n",
    "    # ç»“æ„åŒ– scratchpadï¼Œä¿ç•™å®Œæ•´å†å²\n",
    "    scratchpad: dict  # {\"history\": List[ToolCallRecord], \"final_answer\": str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "436e02ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. å®šä¹‰å·¥å…· ---\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def simple_calculator(operation: str, a: int, b: int) -> int:\n",
    "    \"\"\"ä¸€ä¸ªç®€å•çš„è®¡ç®—å™¨å·¥å…·ï¼Œæ‰§è¡ŒåŠ å‡ä¹˜é™¤ã€‚\"\"\"\n",
    "    if operation == \"add\":\n",
    "        return a + b\n",
    "    if operation == \"subtract\":\n",
    "        return a - b\n",
    "    if operation == \"multiply\":\n",
    "        return a * b\n",
    "    if operation == \"divide\" and b != 0:\n",
    "        return a // b\n",
    "    return \"æ— æ•ˆæ“ä½œ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7d01195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. å®šä¹‰å›¾çš„èŠ‚ç‚¹ ---\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import END\n",
    "\n",
    "tools = [simple_calculator]\n",
    "tool_node = ToolNode(tools)\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "def agent_with_scratchpad(state: WriteStrategyState):\n",
    "    \"\"\"\n",
    "    Agent èŠ‚ç‚¹ï¼šå†³å®šä¸‹ä¸€æ­¥åŠ¨ä½œï¼Œå¹¶æ›´æ–°æš‚å­˜åŒºã€‚\n",
    "    \"\"\"\n",
    "    print(\"---AGENT NODE---\")\n",
    "    response = model_with_tools.invoke(state['messages'])\n",
    "\n",
    "    if response.tool_calls:\n",
    "        # æš‚å­˜å½“å‰å¾…æ‰§è¡Œçš„å·¥å…·\n",
    "        state['scratchpad']['pending_tool'] = response.tool_calls[0]\n",
    "        print(f\"ğŸ§  Agent Action: Call tool `{response.tool_calls[0]['name']}` \"\n",
    "              f\"with arguments `{response.tool_calls[0]['args']}`\")\n",
    "    else:\n",
    "        # å…¨éƒ¨å®Œæˆï¼Œä¿å­˜æœ€ç»ˆç­”æ¡ˆ\n",
    "        state['scratchpad']['final_answer'] = response.content\n",
    "        print(f\"âœ… Final Answer: {response.content}\")\n",
    "\n",
    "    return {\"messages\": [response], \"scratchpad\": state['scratchpad']}\n",
    "\n",
    "def tool_node_with_scratchpad(state: WriteStrategyState):\n",
    "    \"\"\"\n",
    "    Tool èŠ‚ç‚¹ï¼šæ‰§è¡Œå·¥å…·ï¼Œå¹¶æŠŠç»“æœè®°å½•åˆ° historyã€‚\n",
    "    \"\"\"\n",
    "    print(\"---TOOL NODE---\")\n",
    "    last_message = state['messages'][-1]\n",
    "    tool_messages = tool_node.invoke([last_message])\n",
    "\n",
    "    # å–å‡ºå¾…å¤„ç†çš„å·¥å…·è°ƒç”¨\n",
    "    pending = state['scratchpad']['pending_tool']\n",
    "    record = ToolCallRecord(\n",
    "        step=len(state['scratchpad'].get(\"history\", [])) + 1,\n",
    "        tool_name=pending['name'],\n",
    "        args=pending['args'],\n",
    "        result=str(tool_messages[0].content)\n",
    "    )\n",
    "    # è¿½åŠ åˆ°å†å²\n",
    "    state['scratchpad'].setdefault(\"history\", []).append(record)\n",
    "    print(f\"ğŸ“ Recorded Tool Call: {record}\")\n",
    "    state['scratchpad'].pop(\"pending_tool\", None)  # æ¸…ç†\n",
    "\n",
    "    #print(f\"ğŸ› ï¸ Tool Result: `{record['result']}`\")\n",
    "    return {\"messages\": tool_messages, \"scratchpad\": state['scratchpad']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4be3a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. æ„å»ºå›¾ ---\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "write_graph_builder = StateGraph(WriteStrategyState)\n",
    "write_graph_builder.add_node(\"agent\", agent_with_scratchpad)\n",
    "write_graph_builder.add_node(\"action\", tool_node_with_scratchpad)\n",
    "write_graph_builder.set_entry_point(\"agent\")\n",
    "\n",
    "# æ¡ä»¶è¾¹ï¼šæ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªå®Œæˆçš„å·¥å…·\n",
    "def should_continue(state: WriteStrategyState) -> str:\n",
    "    # è‹¥æœ€ç»ˆç­”æ¡ˆå·²å­˜åœ¨ï¼Œç›´æ¥ç»“æŸ\n",
    "    if state['scratchpad'].get(\"final_answer\"):\n",
    "        return END\n",
    "    return \"action\"\n",
    "\n",
    "write_graph_builder.add_conditional_edges(\"agent\", should_continue, {\"action\": \"action\", END: END})\n",
    "write_graph_builder.add_edge(\"action\", \"agent\")\n",
    "write_graph = write_graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aa372ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### æ¼”ç¤ºâ€œå†™å…¥â€ç­–ç•¥ ###\n",
      "---AGENT NODE---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Agent Action: Call tool `simple_calculator` with arguments `{'a': 128, 'b': 72, 'operation': 'add'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "ğŸ“ Recorded Tool Call: {'step': 1, 'tool_name': 'simple_calculator', 'args': {'a': 128, 'b': 72, 'operation': 'add'}, 'result': '200'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "ğŸ§  Agent Action: Call tool `simple_calculator` with arguments `{'a': 200, 'b': 3, 'operation': 'multiply'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "ğŸ“ Recorded Tool Call: {'step': 2, 'tool_name': 'simple_calculator', 'args': {'a': 200, 'b': 3, 'operation': 'multiply'}, 'result': '600'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "ğŸ§  Agent Action: Call tool `simple_calculator` with arguments `{'a': 600, 'b': 100, 'operation': 'divide'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "ğŸ“ Recorded Tool Call: {'step': 3, 'tool_name': 'simple_calculator', 'args': {'a': 600, 'b': 100, 'operation': 'divide'}, 'result': '6'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "ğŸ§  Agent Action: Call tool `simple_calculator` with arguments `{'a': 6, 'b': 20, 'operation': 'multiply'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "ğŸ“ Recorded Tool Call: {'step': 4, 'tool_name': 'simple_calculator', 'args': {'a': 6, 'b': 20, 'operation': 'multiply'}, 'result': '120'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "ğŸ§  Agent Action: Call tool `simple_calculator` with arguments `{'a': 120, 'b': 222, 'operation': 'subtract'}`\n",
      "---\n",
      "---TOOL NODE---\n",
      "ğŸ“ Recorded Tool Call: {'step': 5, 'tool_name': 'simple_calculator', 'args': {'a': 120, 'b': 222, 'operation': 'subtract'}, 'result': '-102'}\n",
      "---\n",
      "---AGENT NODE---\n",
      "âœ… Final Answer: æœ€ç»ˆç»“æœï¼š-102\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# --- 5. æ¼”ç¤º ---\n",
    "print(\"### æ¼”ç¤ºâ€œå†™å…¥â€ç­–ç•¥ ###\")\n",
    "task = (\n",
    "    \"1) åˆå§‹ç°é‡‘æµ 128 å…ƒä¸é¢„ç®—è¿½åŠ  72 å…ƒå…ˆè¿›è¡Œåˆå¹¶ï¼›\\n\"\n",
    "    \"2) åˆå¹¶åçš„èµ„é‡‘æŒ‰å­£åº¦å¤åˆ© 3 å€æ æ†æ”¾å¤§ï¼›\\n\"\n",
    "    \"3) æ”¾å¤§åçš„èµ„é‡‘å› æ±‡ç‡æŠ˜ç®—éœ€é™¤ä»¥ 100 å¾—åˆ°åŸºå‡†å•ä½å€¼ï¼›\\n\"\n",
    "    \"4) åŸºå‡†å•ä½å€¼å†æŒ‰ 20 å€é£é™©ç³»æ•°æ”¾å¤§ï¼Œå½¢æˆé£é™©æ•å£ï¼›\\n\"\n",
    "    \"5) æœ€ç»ˆä»é£é™©æ•å£ä¸­ä¸€æ¬¡æ€§æ‰£é™¤ 222 å…ƒçš„å›ºå®šå‡†å¤‡é‡‘ã€‚\\n\"\n",
    "    \"è¯·åˆ—å‡ºæ¯ä¸€æ­¥çš„æ•°å€¼ç»“æœï¼Œå¹¶ä»¥ã€æœ€ç»ˆç»“æœï¼š{æ•°å€¼}ã€çš„æ ¼å¼ç»™å‡ºç­”æ¡ˆã€‚\"\n",
    ")\n",
    "\n",
    "system_prompt = (\n",
    "    \"ä½ æ˜¯ä¸€ä¸ªè®¡ç®—åŠ©æ‰‹ã€‚è¯·æŒ‰æ­¥éª¤ä½¿ç”¨ `simple_calculator` å·¥å…·æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚ \"\n",
    ")\n",
    "initial_messages = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(content=task)\n",
    "]\n",
    "initial_state = {\"messages\": initial_messages, \"scratchpad\": {\"history\": [], \"final_answer\": None}}\n",
    "\n",
    "# ä½¿ç”¨ .stream() è§‚å¯Ÿæ¯ä¸€æ­¥\n",
    "for step in write_graph.stream(initial_state, {\"recursion_limit\": 20}):\n",
    "    #print(step)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e126c53",
   "metadata": {},
   "source": [
    "## **ç­–ç•¥äºŒï¼šé€‰æ‹© (Select) - ç²¾å‡†çš„\"ä¿¡æ¯è°ƒå–\"**\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³ï¼š** ä½¿ç”¨RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æŠ€æœ¯ï¼Œä»å¤–éƒ¨çŸ¥è¯†åº“ä¸­ç²¾å‡†æ£€ç´¢æœ€ç›¸å…³çš„ä¿¡æ¯ç‰‡æ®µï¼Œåªå°†å¿…è¦ä¿¡æ¯æ³¨å…¥ä¸Šä¸‹æ–‡ã€‚\n",
    "\n",
    "**å®ç°æ­¥éª¤ï¼š**\n",
    "1. åˆ›å»ºäº§å“çŸ¥è¯†åº“ï¼ˆæ¨¡æ‹Ÿå‘é‡æ•°æ®åº“ï¼‰\n",
    "2. æ„å»ºRAGæ£€ç´¢å™¨\n",
    "3. è®¾è®¡æ™ºèƒ½ä½“æµç¨‹ï¼šé—®é¢˜ â†’ æ£€ç´¢ â†’ ç”Ÿæˆç­”æ¡ˆ\n",
    "4. å¯è§†åŒ–TokenèŠ‚çœæ•ˆæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d67324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. åˆ›å»ºæ¨¡æ‹Ÿäº§å“çŸ¥è¯†åº“ ---\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "\n",
    "# åˆ›å»ºåµŒå…¥æ¨¡å‹\n",
    "embeddings = DashScopeEmbeddings(model=\"text-embedding-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29f0b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# äº§å“çŸ¥è¯†æ–‡æ¡£ï¼ˆå®é™…åº”ç”¨ä¸­ä¼šä»æ•°æ®åº“åŠ è½½ï¼‰\n",
    "product_docs = [\n",
    "    Document(page_content=\"\"\"æœºæ¢°é”®ç›˜ X1 Pro æŠ€æœ¯è§„æ ¼ï¼š\n",
    "- è½´ä½“ï¼šå®šåˆ¶é’è½´ï¼Œ60gè§¦å‘å‹åŠ›\n",
    "- è¿æ¥ï¼šä¸‰æ¨¡ï¼ˆè“ç‰™5.1/2.4G/USB-Cï¼‰\n",
    "- ç”µæ± ï¼š4000mAhï¼Œç»­èˆª200å°æ—¶\n",
    "- ç‰¹ç‚¹ï¼šçƒ­æ’æ‹”è½´ä½“ï¼ŒPBTåŒè‰²é”®å¸½ï¼Œå…¨é”®æ— å†²\n",
    "- ä»·æ ¼ï¼š699å…ƒï¼ˆé™æ—¶ä¼˜æƒ 599å…ƒï¼‰\"\"\", \n",
    "             metadata={\"product\": \"æœºæ¢°é”®ç›˜ X1 Pro\", \"category\": \"é”®ç›˜\"}),\n",
    "    \n",
    "    Document(page_content=\"\"\"æ¸¸æˆé¼ æ ‡ M800 æ——èˆ°ç‰ˆï¼š\n",
    "- ä¼ æ„Ÿå™¨ï¼šåŸç›¸PAW3395ï¼Œ26000DPI\n",
    "- å¾®åŠ¨ï¼šæ¬§å§†é¾™å…‰å­¦å¾®åŠ¨ï¼Œ1äº¿æ¬¡å¯¿å‘½\n",
    "- é‡é‡ï¼š58gï¼ˆè¶…è½»é‡åŒ–è®¾è®¡ï¼‰\n",
    "- RGBï¼š1680ä¸‡è‰²ï¼Œ10åŒºåŸŸç‹¬ç«‹æ§å…‰\n",
    "- ä»·æ ¼ï¼š399å…ƒï¼ˆå¥—è£…ä¼˜æƒ ä»·ï¼‰\"\"\", \n",
    "             metadata={\"product\": \"æ¸¸æˆé¼ æ ‡ M800\", \"category\": \"é¼ æ ‡\"}),\n",
    "    \n",
    "    Document(page_content=\"\"\"ä¿ƒé”€é‚®ä»¶å†™ä½œæŒ‡å—ï¼š\n",
    "1. æ ‡é¢˜è¦å¸å¼•çœ¼çƒï¼ŒåŒ…å«ä¼˜æƒ ä¿¡æ¯\n",
    "2. å¼€å¤´ç”¨ç—›ç‚¹åœºæ™¯å¼•å‘å…±é¸£\n",
    "3. çªå‡ºäº§å“æ ¸å¿ƒä¼˜åŠ¿ï¼ˆæ€§èƒ½>å‚æ•°ï¼‰\n",
    "4. é™æ—¶ä¼˜æƒ åˆ¶é€ ç´§è¿«æ„Ÿ\n",
    "5. æ¸…æ™°çš„è¡ŒåŠ¨å¬å”¤æŒ‰é’®\"\"\", \n",
    "             metadata={\"doc_type\": \"writing_guide\"}),\n",
    "    \n",
    "    Document(page_content=\"\"\"ç”¨æˆ·åå¥½åˆ†æï¼š\n",
    "ç§‘æŠ€äº§å“æ¶ˆè´¹è€…æœ€å…³æ³¨ï¼š\n",
    "- æ€§èƒ½å‚æ•°ï¼ˆ75%ç”¨æˆ·ï¼‰\n",
    "- æ€§ä»·æ¯”ï¼ˆ68%ç”¨æˆ·ï¼‰\n",
    "- è€ç”¨æ€§ï¼ˆ52%ç”¨æˆ·ï¼‰\n",
    "- å¤–è§‚è®¾è®¡ï¼ˆ48%ç”¨æˆ·ï¼‰\"\"\", \n",
    "             metadata={\"doc_type\": \"user_insight\"}),\n",
    "]\n",
    "\n",
    "# åˆ›å»ºå‘é‡æ•°æ®åº“\n",
    "vector_db = FAISS.from_documents(product_docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "259408e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. æ„å»ºRAGæ£€ç´¢å™¨ ---\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# åˆ›å»ºæ£€ç´¢å™¨\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"æ ¼å¼åŒ–æ£€ç´¢åˆ°çš„æ–‡æ¡£\"\"\"\n",
    "    return \"\\n\\n\".join(f\"## æ¥æº {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(docs))\n",
    "\n",
    "# åˆ›å»ºRAGæç¤ºæ¨¡æ¿\n",
    "rag_template = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„äº§å“æ–‡æ¡ˆåŠ©æ‰‹ã€‚è¯·æ ¹æ®æä¾›çš„èƒŒæ™¯ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n",
    "\n",
    "<èƒŒæ™¯ä¿¡æ¯>\n",
    "{context}\n",
    "</èƒŒæ™¯ä¿¡æ¯>\n",
    "\n",
    "ç”¨æˆ·é—®é¢˜ï¼š{question}\n",
    "\n",
    "è¯·ç”¨ä¸“ä¸šã€ç®€æ´çš„è¯­è¨€å›ç­”ï¼Œçªå‡ºäº§å“æ ¸å¿ƒä¼˜åŠ¿ï¼š\n",
    "\"\"\"\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_template)\n",
    "\n",
    "# åˆ›å»ºRAGé“¾\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | RunnableLambda(format_docs), \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b04e7dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. è®¾è®¡æ™ºèƒ½ä½“æµç¨‹ ---\n",
    "class SelectStrategyState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    context: str  # å­˜å‚¨æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡\n",
    "\n",
    "def retrieve_context(state: SelectStrategyState):\n",
    "    \"\"\"æ£€ç´¢èŠ‚ç‚¹ï¼šä»çŸ¥è¯†åº“è·å–ç›¸å…³ä¿¡æ¯\"\"\"\n",
    "    print(\"\\n--- RETRIEVE CONTEXT ---\")\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    \n",
    "    # æ‰§è¡Œæ£€ç´¢\n",
    "    docs = retriever.invoke(last_message)\n",
    "    context = format_docs(docs)\n",
    "    \n",
    "    # è®¡ç®—TokenèŠ‚çœ\n",
    "    orig_token_count = sum(len(encoding.encode(doc.page_content)) for doc in docs)\n",
    "    context_token_count = len(encoding.encode(context))\n",
    "    savings = orig_token_count - context_token_count\n",
    "    \n",
    "    print(f\"ğŸ” æ£€ç´¢åˆ° {len(docs)} æ¡ç›¸å…³æ–‡æ¡£\")\n",
    "    print(f\"ğŸ“‰ TokenèŠ‚çœ: {savings} (åŸå§‹: {orig_token_count} -> å‹ç¼©: {context_token_count})\")\n",
    "    print(f\"ğŸ“ æ³¨å…¥ä¸Šä¸‹æ–‡:\\n{context[:300]}...\")\n",
    "    \n",
    "    return {\"context\": context}\n",
    "\n",
    "def generate_with_context(state: SelectStrategyState):\n",
    "    \"\"\"ç”ŸæˆèŠ‚ç‚¹ï¼šä½¿ç”¨æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ç”Ÿæˆå›ç­”\"\"\"\n",
    "    print(\"\\n--- GENERATE WITH CONTEXT ---\")\n",
    "    question = state[\"messages\"][-1].content\n",
    "    \n",
    "    # ä½¿ç”¨RAGé“¾ç”Ÿæˆå›ç­”\n",
    "    response = rag_chain.invoke(question)\n",
    "    \n",
    "    # åˆ›å»ºæ¶ˆæ¯å¯¹è±¡\n",
    "    response_message = HumanMessage(content=response)\n",
    "    \n",
    "    # è¾“å‡ºç»“æœ\n",
    "    print(f\"ğŸ’¡ ç”Ÿæˆçš„å›ç­”: {response}\")\n",
    "    return {\"messages\": [response_message]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c58e344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. æ„å»ºé€‰æ‹©ç­–ç•¥å›¾ ---\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# å®šä¹‰çŠ¶æ€\n",
    "class SelectState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    context: str\n",
    "\n",
    "# åˆ›å»ºå›¾\n",
    "select_graph = StateGraph(SelectState)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "select_graph.add_node(\"retrieve\", retrieve_context)\n",
    "select_graph.add_node(\"generate\", generate_with_context)\n",
    "\n",
    "# è®¾ç½®å…¥å£ç‚¹\n",
    "select_graph.set_entry_point(\"retrieve\")\n",
    "\n",
    "# æ·»åŠ è¾¹\n",
    "select_graph.add_edge(\"retrieve\", \"generate\")\n",
    "select_graph.add_edge(\"generate\", END)\n",
    "\n",
    "# ç¼–è¯‘å›¾\n",
    "select_workflow = select_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bd425e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### æ¼”ç¤º'é€‰æ‹©'ç­–ç•¥ ###\n",
      "\n",
      "--- RETRIEVE CONTEXT ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æ£€ç´¢åˆ° 2 æ¡ç›¸å…³æ–‡æ¡£\n",
      "ğŸ“‰ TokenèŠ‚çœ: -14 (åŸå§‹: 223 -> å‹ç¼©: 237)\n",
      "ğŸ“ æ³¨å…¥ä¸Šä¸‹æ–‡:\n",
      "## æ¥æº 1:\n",
      "æœºæ¢°é”®ç›˜ X1 Pro æŠ€æœ¯è§„æ ¼ï¼š\n",
      "- è½´ä½“ï¼šå®šåˆ¶é’è½´ï¼Œ60gè§¦å‘å‹åŠ›\n",
      "- è¿æ¥ï¼šä¸‰æ¨¡ï¼ˆè“ç‰™5.1/2.4G/USB-Cï¼‰\n",
      "- ç”µæ± ï¼š4000mAhï¼Œç»­èˆª200å°æ—¶\n",
      "- ç‰¹ç‚¹ï¼šçƒ­æ’æ‹”è½´ä½“ï¼ŒPBTåŒè‰²é”®å¸½ï¼Œå…¨é”®æ— å†²\n",
      "- ä»·æ ¼ï¼š699å…ƒï¼ˆé™æ—¶ä¼˜æƒ 599å…ƒï¼‰\n",
      "\n",
      "## æ¥æº 2:\n",
      "ä¿ƒé”€é‚®ä»¶å†™ä½œæŒ‡å—ï¼š\n",
      "1. æ ‡é¢˜è¦å¸å¼•çœ¼çƒï¼ŒåŒ…å«ä¼˜æƒ ä¿¡æ¯\n",
      "2. å¼€å¤´ç”¨ç—›ç‚¹åœºæ™¯å¼•å‘å…±é¸£\n",
      "3. çªå‡ºäº§å“æ ¸å¿ƒä¼˜åŠ¿ï¼ˆæ€§èƒ½>å‚æ•°ï¼‰\n",
      "4. é™æ—¶ä¼˜æƒ åˆ¶é€ ç´§è¿«æ„Ÿ\n",
      "5. æ¸…æ™°çš„è¡ŒåŠ¨å¬å”¤æŒ‰é’®...\n",
      "{'retrieve': {'context': '## æ¥æº 1:\\næœºæ¢°é”®ç›˜ X1 Pro æŠ€æœ¯è§„æ ¼ï¼š\\n- è½´ä½“ï¼šå®šåˆ¶é’è½´ï¼Œ60gè§¦å‘å‹åŠ›\\n- è¿æ¥ï¼šä¸‰æ¨¡ï¼ˆè“ç‰™5.1/2.4G/USB-Cï¼‰\\n- ç”µæ± ï¼š4000mAhï¼Œç»­èˆª200å°æ—¶\\n- ç‰¹ç‚¹ï¼šçƒ­æ’æ‹”è½´ä½“ï¼ŒPBTåŒè‰²é”®å¸½ï¼Œå…¨é”®æ— å†²\\n- ä»·æ ¼ï¼š699å…ƒï¼ˆé™æ—¶ä¼˜æƒ 599å…ƒï¼‰\\n\\n## æ¥æº 2:\\nä¿ƒé”€é‚®ä»¶å†™ä½œæŒ‡å—ï¼š\\n1. æ ‡é¢˜è¦å¸å¼•çœ¼çƒï¼ŒåŒ…å«ä¼˜æƒ ä¿¡æ¯\\n2. å¼€å¤´ç”¨ç—›ç‚¹åœºæ™¯å¼•å‘å…±é¸£\\n3. çªå‡ºäº§å“æ ¸å¿ƒä¼˜åŠ¿ï¼ˆæ€§èƒ½>å‚æ•°ï¼‰\\n4. é™æ—¶ä¼˜æƒ åˆ¶é€ ç´§è¿«æ„Ÿ\\n5. æ¸…æ™°çš„è¡ŒåŠ¨å¬å”¤æŒ‰é’®'}}\n",
      "---\n",
      "\n",
      "--- GENERATE WITH CONTEXT ---\n",
      "ğŸ’¡ ç”Ÿæˆçš„å›ç­”: **ä¸»é¢˜ï¼šé™æ—¶ç‰¹æƒ ï¼æ——èˆ°æœºæ¢°é”®ç›˜X1 Proï¼Œæ€§èƒ½å‡çº§ï¼Œä»…éœ€599å…ƒ**\n",
      "\n",
      "å°Šæ•¬çš„ç”¨æˆ·ï¼Œ\n",
      "\n",
      "ä½ æ˜¯å¦åœ¨å¯»æ‰¾ä¸€æ¬¾å…¼å…·ä¸“ä¸šæ€§èƒ½ä¸èˆ’é€‚ä½“éªŒçš„æœºæ¢°é”®ç›˜ï¼Ÿæ— è®ºæ˜¯é«˜å¼ºåº¦åŠå…¬ã€æ¸¸æˆç«æŠ€ï¼Œè¿˜æ˜¯é•¿æ—¶é—´æ‰“å­—ï¼ŒX1 Pro éƒ½èƒ½ä¸ºä½ å¸¦æ¥å“è¶Šçš„ä½¿ç”¨æ„Ÿå—ã€‚\n",
      "\n",
      "**X1 Pro æ ¸å¿ƒä¼˜åŠ¿ï¼š**  \n",
      "âœ… **å®šåˆ¶é’è½´è®¾è®¡**ï¼š60gè§¦å‘å‹åŠ›ï¼Œæ¸…æ™°å›å¼¹ï¼Œæ•²å‡»æ„Ÿç²¾å‡†æœ‰åŠ›ã€‚  \n",
      "âœ… **ä¸‰æ¨¡è¿æ¥æŠ€æœ¯**ï¼šæ”¯æŒè“ç‰™5.1/2.4G/USB-Cï¼Œå…¼å®¹å¤šç§è®¾å¤‡ï¼Œæ— ç¼åˆ‡æ¢ã€‚  \n",
      "âœ… **æŒä¹…ç»­èˆªèƒ½åŠ›**ï¼š4000mAhå¤§ç”µæ± ï¼Œç»­èˆªé•¿è¾¾200å°æ—¶ï¼Œå‘Šåˆ«é¢‘ç¹å……ç”µã€‚  \n",
      "âœ… **çƒ­æ’æ‹”è½´ä½“ + PBTåŒè‰²é”®å¸½**ï¼šè‡ªç”±æ›´æ¢è½´ä½“ï¼Œè€ç”¨æ€§å¼ºï¼Œè´¨æ„Ÿå‡ºä¼—ã€‚  \n",
      "âœ… **å…¨é”®æ— å†²**ï¼šæ¸¸æˆåœºæ™¯ä¸­ç²¾å‡†è¯†åˆ«å¤šé”®è¾“å…¥ï¼Œæå‡æ“ä½œç¨³å®šæ€§ã€‚\n",
      "\n",
      "**ç°åœ¨è´­ä¹°ï¼Œç«‹äº«é™æ—¶ä¼˜æƒ ä»·ï¼š599å…ƒï¼ˆåŸä»·699å…ƒï¼‰**  \n",
      "æœºä¼šæœ‰é™ï¼Œé”™è¿‡å†ç­‰ä¸€å¹´ï¼\n",
      "\n",
      "ğŸ‘‰ [ç«‹å³æŠ¢è´­]  \n",
      "\n",
      "è®©X1 Pro æˆä¸ºä½ å·¥ä½œä¸å¨±ä¹çš„æœ€ä½³æ­æ¡£ï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ï¼Œé©¬ä¸Šäº«å—è¶…å€¼ä¼˜æƒ ï¼\n",
      "{'generate': {'messages': [HumanMessage(content='**ä¸»é¢˜ï¼šé™æ—¶ç‰¹æƒ ï¼æ——èˆ°æœºæ¢°é”®ç›˜X1 Proï¼Œæ€§èƒ½å‡çº§ï¼Œä»…éœ€599å…ƒ**\\n\\nå°Šæ•¬çš„ç”¨æˆ·ï¼Œ\\n\\nä½ æ˜¯å¦åœ¨å¯»æ‰¾ä¸€æ¬¾å…¼å…·ä¸“ä¸šæ€§èƒ½ä¸èˆ’é€‚ä½“éªŒçš„æœºæ¢°é”®ç›˜ï¼Ÿæ— è®ºæ˜¯é«˜å¼ºåº¦åŠå…¬ã€æ¸¸æˆç«æŠ€ï¼Œè¿˜æ˜¯é•¿æ—¶é—´æ‰“å­—ï¼ŒX1 Pro éƒ½èƒ½ä¸ºä½ å¸¦æ¥å“è¶Šçš„ä½¿ç”¨æ„Ÿå—ã€‚\\n\\n**X1 Pro æ ¸å¿ƒä¼˜åŠ¿ï¼š**  \\nâœ… **å®šåˆ¶é’è½´è®¾è®¡**ï¼š60gè§¦å‘å‹åŠ›ï¼Œæ¸…æ™°å›å¼¹ï¼Œæ•²å‡»æ„Ÿç²¾å‡†æœ‰åŠ›ã€‚  \\nâœ… **ä¸‰æ¨¡è¿æ¥æŠ€æœ¯**ï¼šæ”¯æŒè“ç‰™5.1/2.4G/USB-Cï¼Œå…¼å®¹å¤šç§è®¾å¤‡ï¼Œæ— ç¼åˆ‡æ¢ã€‚  \\nâœ… **æŒä¹…ç»­èˆªèƒ½åŠ›**ï¼š4000mAhå¤§ç”µæ± ï¼Œç»­èˆªé•¿è¾¾200å°æ—¶ï¼Œå‘Šåˆ«é¢‘ç¹å……ç”µã€‚  \\nâœ… **çƒ­æ’æ‹”è½´ä½“ + PBTåŒè‰²é”®å¸½**ï¼šè‡ªç”±æ›´æ¢è½´ä½“ï¼Œè€ç”¨æ€§å¼ºï¼Œè´¨æ„Ÿå‡ºä¼—ã€‚  \\nâœ… **å…¨é”®æ— å†²**ï¼šæ¸¸æˆåœºæ™¯ä¸­ç²¾å‡†è¯†åˆ«å¤šé”®è¾“å…¥ï¼Œæå‡æ“ä½œç¨³å®šæ€§ã€‚\\n\\n**ç°åœ¨è´­ä¹°ï¼Œç«‹äº«é™æ—¶ä¼˜æƒ ä»·ï¼š599å…ƒï¼ˆåŸä»·699å…ƒï¼‰**  \\næœºä¼šæœ‰é™ï¼Œé”™è¿‡å†ç­‰ä¸€å¹´ï¼\\n\\nğŸ‘‰ [ç«‹å³æŠ¢è´­]  \\n\\nè®©X1 Pro æˆä¸ºä½ å·¥ä½œä¸å¨±ä¹çš„æœ€ä½³æ­æ¡£ï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ï¼Œé©¬ä¸Šäº«å—è¶…å€¼ä¼˜æƒ ï¼', additional_kwargs={}, response_metadata={})]}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# --- 5. æ¼”ç¤ºé€‰æ‹©ç­–ç•¥ ---\n",
    "print(\"\\n### æ¼”ç¤º'é€‰æ‹©'ç­–ç•¥ ###\")\n",
    "question = \"è¯·ä¸ºæˆ‘ä»¬çš„æ——èˆ°æœºæ¢°é”®ç›˜X1 Proå†™ä¸€å°ä¿ƒé”€é‚®ä»¶ï¼Œçªå‡ºå…¶æ ¸å¿ƒä¼˜åŠ¿\"\n",
    "\n",
    "# åˆå§‹çŠ¶æ€\n",
    "initial_state = SelectState(\n",
    "    messages=[HumanMessage(content=question)],\n",
    "    context=\"\"\n",
    ")\n",
    "\n",
    "# æ‰§è¡Œå·¥ä½œæµ\n",
    "for step in select_workflow.stream(initial_state):\n",
    "    if \"__end__\" not in step:\n",
    "        print(step)\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b78e84",
   "metadata": {},
   "source": [
    "## **ç­–ç•¥ä¸‰ï¼šå‹ç¼© (Compress) - ä¸ºä¸Šä¸‹æ–‡\"ç˜¦èº«å‡è´Ÿ\"**\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³ï¼š** ä½¿ç”¨æ€»ç»“(summarization)å’Œè£å‰ª(trimming)æŠ€æœ¯å‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦ï¼ŒèŠ‚çœTokenå¹¶æé«˜æ•ˆç‡ã€‚\n",
    "\n",
    "**å®ç°ä¸¤ç§å‹ç¼©æŠ€æœ¯ï¼š**\n",
    "1. **æ€»ç»“å‹ç¼©**ï¼šå°†é•¿æ–‡æœ¬æç‚¼ä¸ºç®€æ´æ‘˜è¦\n",
    "2. **è£å‰ªå‹ç¼©**ï¼šæ™ºèƒ½ä¿ç•™å¯¹è¯ä¸­æœ€ç›¸å…³çš„éƒ¨åˆ†\n",
    "\n",
    "**åœºæ™¯æ¼”ç¤ºï¼š** æ™ºèƒ½ä½“éœ€è¦é˜…è¯»ä¸€ç¯‡é•¿æ–‡ç« å¹¶å›ç­”é—®é¢˜ï¼Œæˆ‘ä»¬é€šè¿‡æ€»ç»“å‹ç¼©æ–‡ç« å†…å®¹ï¼›åŒæ—¶å±•ç¤ºå¯¹è¯å†å²è£å‰ªæŠ€æœ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1022bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. å‡†å¤‡é•¿æ–‡æœ¬ç¤ºä¾‹ ---\n",
    "long_article = \"\"\"\n",
    "åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‘å±•æ­£ä»¥å‰æ‰€æœªæœ‰çš„é€Ÿåº¦æ¨è¿›ã€‚2023å¹´ï¼ŒOpenAIå‘å¸ƒäº†GPT-4æ¨¡å‹ï¼Œå…¶ä¸Šä¸‹æ–‡çª—å£æ‰©å±•åˆ°32K tokensï¼Œå¤§å¤§å¢å¼ºäº†å¤„ç†é•¿æ–‡æ¡£çš„èƒ½åŠ›ã€‚éšåï¼ŒAnthropicæ¨å‡ºäº†Claude 2.1æ¨¡å‹ï¼Œæ”¯æŒ200K tokensçš„ä¸Šä¸‹æ–‡çª—å£ï¼Œåˆ›ä¸‹äº†å½“æ—¶çš„æ–°çºªå½•ã€‚\n",
    "\n",
    "ç„¶è€Œï¼Œ2024å¹´ï¼Œè¿™ä¸€çºªå½•è¢«ä¸­å›½ç§‘æŠ€å…¬å¸æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰æ‰“ç ´ã€‚ä»–ä»¬å‘å¸ƒäº†DeepSeek-R1æ¨¡å‹ï¼Œä¸ä»…æ”¯æŒ128K tokensçš„ä¸Šä¸‹æ–‡çª—å£ï¼Œè¿˜åˆ›æ–°æ€§åœ°å¼•å…¥äº†\"ä¸Šä¸‹æ–‡å‹ç¼©\"æŠ€æœ¯ã€‚è¯¥æŠ€æœ¯é€šè¿‡æ™ºèƒ½æ€»ç»“å’Œå…³é”®ä¿¡æ¯æå–ï¼Œå¯ä»¥å°†é•¿æ–‡æ¡£å‹ç¼©åˆ°åŸé•¿åº¦çš„20%-30%ï¼ŒåŒæ—¶ä¿ç•™95%ä»¥ä¸Šçš„æ ¸å¿ƒä¿¡æ¯ã€‚\n",
    "\n",
    "DeepSeek-R1çš„æŠ€æœ¯åˆ›æ–°ä¸»è¦ä½“ç°åœ¨ä¸‰ä¸ªæ–¹é¢ï¼š\n",
    "1. åˆ†å±‚æ€»ç»“æ¶æ„ï¼šæ¨¡å‹é¦–å…ˆå¯¹æ–‡æ¡£è¿›è¡Œåˆ†æ®µæ€»ç»“ï¼Œç„¶åå¯¹åˆ†æ®µæ‘˜è¦è¿›è¡ŒäºŒæ¬¡æ€»ç»“ï¼Œå½¢æˆå±‚æ¬¡åŒ–çš„å‹ç¼©ç»“æ„ã€‚\n",
    "2. è¯­ä¹‰å¯†åº¦ä¼˜åŒ–ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œæ¨¡å‹å­¦ä¼šè¯†åˆ«å¹¶ä¿ç•™ä¿¡æ¯å¯†åº¦æœ€é«˜çš„å†…å®¹ã€‚\n",
    "3. è‡ªé€‚åº”å‹ç¼©ç‡ï¼šæ ¹æ®ç”¨æˆ·ä»»åŠ¡ç±»å‹åŠ¨æ€è°ƒæ•´å‹ç¼©å¼ºåº¦ï¼Œå¹³è¡¡ä¿¡æ¯ä¿ç•™ä¸æ•ˆç‡ã€‚\n",
    "\n",
    "åœ¨å®é™…æµ‹è¯•ä¸­ï¼ŒDeepSeek-R1å¤„ç†ä¸€ç¯‡10,000å­—çš„ç§‘æŠ€è®ºæ–‡æ—¶ï¼Œå°†å…¶å‹ç¼©åˆ°1,500å­—çš„å…³é”®æ‘˜è¦ï¼ŒåŒæ—¶å‡†ç¡®å›ç­”äº†è®ºæ–‡ä¸­çš„æ ¸å¿ƒé—®é¢˜ã€‚æ›´ä»¤äººå°è±¡æ·±åˆ»çš„æ˜¯ï¼Œå‹ç¼©åçš„Tokenä½¿ç”¨é‡ä»…ä¸ºåŸå§‹çš„18%ï¼Œè€Œä»»åŠ¡å®Œæˆè´¨é‡ä»…ä¸‹é™2%ã€‚\n",
    "\n",
    "è¿™é¡¹æŠ€æœ¯çš„å•†ä¸šåº”ç”¨å‰æ™¯å¹¿é˜”ï¼š\n",
    "- æ³•å¾‹è¡Œä¸šï¼šå¿«é€Ÿåˆ†æå†—é•¿çš„æ³•å¾‹æ–‡ä»¶\n",
    "- é‡‘èé¢†åŸŸï¼šé«˜æ•ˆå¤„ç†å¹´åº¦è´¢æŠ¥å’Œæ‹›è‚¡ä¹¦\n",
    "- å­¦æœ¯ç ”ç©¶ï¼šåŠ é€Ÿæ–‡çŒ®ç»¼è¿°è¿‡ç¨‹\n",
    "- å®¢æˆ·æœåŠ¡ï¼šå¿«é€Ÿç†è§£é•¿ç¯‡å®¢æˆ·åé¦ˆ\n",
    "\n",
    "DeepSeekå›¢é˜Ÿè¡¨ç¤ºï¼Œä»–ä»¬ä¸‹ä¸€æ­¥å°†æ¢ç´¢\"åŠ¨æ€ä¸Šä¸‹æ–‡å‹ç¼©\"ï¼Œå³åœ¨å¯¹è¯è¿‡ç¨‹ä¸­å®æ—¶è°ƒæ•´å‹ç¼©ç‡ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–æ™ºèƒ½ä½“çš„é•¿æœŸè®°å¿†ç®¡ç†ã€‚\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e07de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. å®šä¹‰å‹ç¼©å·¥å…· ---\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# æ€»ç»“å‹ç¼©å·¥å…·\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"è¯·å°†ä»¥ä¸‹æ–‡æœ¬æ€»ç»“ä¸ºä¸è¶…è¿‡{max_words}å­—çš„å…³é”®è¦ç‚¹ï¼Œä¿ç•™æ‰€æœ‰æ ¸å¿ƒæŠ€æœ¯å’Œæ•°æ®ï¼š\\n\\n{text}\"\n",
    ")\n",
    "\n",
    "summarizer_chain = (\n",
    "    summary_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# è£å‰ªå‹ç¼©å‡½æ•°\n",
    "def trim_messages(messages: List[BaseMessage], max_messages=5) -> List[BaseMessage]:\n",
    "    \"\"\"è£å‰ªå¯¹è¯å†å²ï¼Œä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€æ–°çš„å‡ æ¡æ¶ˆæ¯\"\"\"\n",
    "    # å§‹ç»ˆä¿ç•™ç¬¬ä¸€æ¡ç³»ç»Ÿæ¶ˆæ¯\n",
    "    system_message = messages[0] if messages and isinstance(messages[0], SystemMessage) else None\n",
    "    \n",
    "    # ä¿ç•™æœ€è¿‘çš„max_messagesæ¡æ¶ˆæ¯ï¼ˆæ’é™¤ç³»ç»Ÿæ¶ˆæ¯ï¼‰\n",
    "    recent_messages = messages[-max_messages:] if len(messages) > 1 else messages\n",
    "    \n",
    "    # é‡æ–°ç»„åˆ\n",
    "    trimmed = []\n",
    "    if system_message:\n",
    "        trimmed.append(system_message)\n",
    "    trimmed.extend(recent_messages)\n",
    "    \n",
    "    return trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59937644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. å®šä¹‰çŠ¶æ€å’ŒèŠ‚ç‚¹ ---\n",
    "class CompressState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    original_text: str  # åŸå§‹é•¿æ–‡æœ¬\n",
    "    compressed_text: str  # å‹ç¼©åçš„æ–‡æœ¬\n",
    "    token_savings: int  # èŠ‚çœçš„Tokenæ•°é‡\n",
    "\n",
    "def compress_long_text(state: CompressState):\n",
    "    \"\"\"æ€»ç»“å‹ç¼©èŠ‚ç‚¹ï¼šå°†é•¿æ–‡æœ¬å‹ç¼©ä¸ºæ‘˜è¦\"\"\"\n",
    "    print(\"\\n--- COMPRESSING LONG TEXT ---\")\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # ä»ç”¨æˆ·æ¶ˆæ¯ä¸­æå–é—®é¢˜\n",
    "    question = last_message.content\n",
    "    \n",
    "    # å‹ç¼©é•¿æ–‡æœ¬\n",
    "    summary = summarizer_chain.invoke({\"text\": state[\"original_text\"], \"max_words\": 300})\n",
    "    \n",
    "    # è®¡ç®—TokenèŠ‚çœ\n",
    "    orig_tokens = len(encoding.encode(state[\"original_text\"]))\n",
    "    comp_tokens = len(encoding.encode(summary))\n",
    "    savings = orig_tokens - comp_tokens\n",
    "    \n",
    "    print(f\"ğŸ“‰ æ–‡æœ¬å‹ç¼©: {orig_tokens} tokens â†’ {comp_tokens} tokens (èŠ‚çœ {savings} tokens)\")\n",
    "    print(f\"ğŸ“ å‹ç¼©æ‘˜è¦:\\n{summary[:200]}...\")\n",
    "    \n",
    "    # æ›´æ–°çŠ¶æ€\n",
    "    return {\n",
    "        \"compressed_text\": summary,\n",
    "        \"token_savings\": savings,\n",
    "        \"messages\": [HumanMessage(content=f\"åŸºäºä»¥ä¸‹æ‘˜è¦å›ç­”é—®é¢˜:\\n{summary}\\n\\né—®é¢˜: {question}\")]\n",
    "    }\n",
    "\n",
    "def answer_with_compressed_text(state: CompressState):\n",
    "    \"\"\"å›ç­”èŠ‚ç‚¹ï¼šåŸºäºå‹ç¼©æ–‡æœ¬å›ç­”é—®é¢˜\"\"\"\n",
    "    print(\"\\n--- ANSWERING WITH COMPRESSED TEXT ---\")\n",
    "    \n",
    "    # è°ƒç”¨æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    answer = response.content\n",
    "    \n",
    "    print(f\"ğŸ’¡ ç”Ÿæˆçš„å›ç­”: {answer[:200]}...\")\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def trim_context(state: CompressState):\n",
    "    \"\"\"è£å‰ªèŠ‚ç‚¹ï¼šå‹ç¼©å¯¹è¯å†å²\"\"\"\n",
    "    print(\"\\n--- TRIMMING CONTEXT ---\")\n",
    "    \n",
    "    # è®¡ç®—è£å‰ªå‰çš„Token\n",
    "    all_messages = \"\".join(m.content for m in state[\"messages\"])\n",
    "    before_tokens = len(encoding.encode(all_messages))\n",
    "    \n",
    "    # æ‰§è¡Œè£å‰ª\n",
    "    trimmed_messages = trim_messages(state[\"messages\"], max_messages=3)\n",
    "    \n",
    "    # è®¡ç®—è£å‰ªåçš„Token\n",
    "    trimmed_content = \"\".join(m.content for m in trimmed_messages)\n",
    "    after_tokens = len(encoding.encode(trimmed_content))\n",
    "    savings = before_tokens - after_tokens\n",
    "    \n",
    "    print(f\"âœ‚ï¸ è£å‰ªå†å²: {len(state['messages'])}æ¡ â†’ {len(trimmed_messages)}æ¡æ¶ˆæ¯\")\n",
    "    print(f\"ğŸ“‰ TokenèŠ‚çœ: {savings} (åŸå§‹: {before_tokens} -> è£å‰ªå: {after_tokens})\")\n",
    "    \n",
    "    return {\"messages\": trimmed_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "047924db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. æ„å»ºå‹ç¼©ç­–ç•¥å›¾ ---\n",
    "compress_graph = StateGraph(CompressState)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "compress_graph.add_node(\"compress\", compress_long_text)\n",
    "compress_graph.add_node(\"answer\", answer_with_compressed_text)\n",
    "compress_graph.add_node(\"trim\", trim_context)\n",
    "\n",
    "# è®¾ç½®å…¥å£ç‚¹\n",
    "compress_graph.set_entry_point(\"compress\")\n",
    "\n",
    "# æ·»åŠ è¾¹\n",
    "compress_graph.add_edge(\"compress\", \"answer\")\n",
    "compress_graph.add_edge(\"answer\", END)\n",
    "\n",
    "# æ·»åŠ æ¡ä»¶è¾¹ç”¨äºè£å‰ª\n",
    "def should_trim(state: CompressState):\n",
    "    \"\"\"å½“æ¶ˆæ¯è¶…è¿‡5æ¡æ—¶è§¦å‘è£å‰ª\"\"\"\n",
    "    if len(state[\"messages\"]) > 5:\n",
    "        return \"trim\"\n",
    "    return END\n",
    "\n",
    "compress_graph.add_conditional_edges(\"answer\", should_trim, {\"trim\": \"trim\", END: END})\n",
    "compress_graph.add_edge(\"trim\", END)\n",
    "\n",
    "# ç¼–è¯‘å›¾\n",
    "compress_workflow = compress_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd584237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### æ¼”ç¤º'æ€»ç»“å‹ç¼©'æŠ€æœ¯ ###\n",
      "\n",
      "--- COMPRESSING LONG TEXT ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‰ æ–‡æœ¬å‹ç¼©: 682 tokens â†’ 225 tokens (èŠ‚çœ 457 tokens)\n",
      "ğŸ“ å‹ç¼©æ‘˜è¦:\n",
      "2023å¹´ï¼ŒGPT-4ä¸Claude 2.1åˆ†åˆ«å®ç°32Kå’Œ200K tokensä¸Šä¸‹æ–‡çª—å£ã€‚2024å¹´ï¼ŒDeepSeekå‘å¸ƒDeepSeek-R1ï¼Œæ”¯æŒ128K tokensï¼Œå¹¶å¼•å…¥â€œä¸Šä¸‹æ–‡å‹ç¼©â€æŠ€æœ¯ï¼Œå¯å°†é•¿æ–‡æ¡£å‹ç¼©è‡³åŸé•¿çš„20%-30%ï¼Œä¿ç•™95%ä»¥ä¸Šæ ¸å¿ƒä¿¡æ¯ã€‚å…¶æŠ€æœ¯åˆ›æ–°åŒ…æ‹¬åˆ†å±‚æ€»ç»“æ¶æ„ã€è¯­ä¹‰å¯†åº¦ä¼˜åŒ–åŠè‡ªé€‚åº”å‹ç¼©ç‡ã€‚æµ‹è¯•ä¸­ï¼Œ10,000å­—è®ºæ–‡å‹ç¼©è‡³1,500å­—ï¼Œä»»åŠ¡è´¨é‡ä»…ä¸‹é™2%ï¼ŒTokenä½¿...\n",
      "{'compress': {'compressed_text': '2023å¹´ï¼ŒGPT-4ä¸Claude 2.1åˆ†åˆ«å®ç°32Kå’Œ200K tokensä¸Šä¸‹æ–‡çª—å£ã€‚2024å¹´ï¼ŒDeepSeekå‘å¸ƒDeepSeek-R1ï¼Œæ”¯æŒ128K tokensï¼Œå¹¶å¼•å…¥â€œä¸Šä¸‹æ–‡å‹ç¼©â€æŠ€æœ¯ï¼Œå¯å°†é•¿æ–‡æ¡£å‹ç¼©è‡³åŸé•¿çš„20%-30%ï¼Œä¿ç•™95%ä»¥ä¸Šæ ¸å¿ƒä¿¡æ¯ã€‚å…¶æŠ€æœ¯åˆ›æ–°åŒ…æ‹¬åˆ†å±‚æ€»ç»“æ¶æ„ã€è¯­ä¹‰å¯†åº¦ä¼˜åŒ–åŠè‡ªé€‚åº”å‹ç¼©ç‡ã€‚æµ‹è¯•ä¸­ï¼Œ10,000å­—è®ºæ–‡å‹ç¼©è‡³1,500å­—ï¼Œä»»åŠ¡è´¨é‡ä»…ä¸‹é™2%ï¼ŒTokenä½¿ç”¨é‡å‡å°‘82%ã€‚è¯¥æŠ€æœ¯é€‚ç”¨äºæ³•å¾‹ã€é‡‘èã€å­¦æœ¯åŠå®¢æœç­‰é¢†åŸŸï¼Œæœªæ¥å°†æ¢ç´¢åŠ¨æ€ä¸Šä¸‹æ–‡å‹ç¼©ä»¥æå‡é•¿æœŸè®°å¿†ç®¡ç†èƒ½åŠ›ã€‚', 'token_savings': 457, 'messages': [HumanMessage(content='åŸºäºä»¥ä¸‹æ‘˜è¦å›ç­”é—®é¢˜:\\n2023å¹´ï¼ŒGPT-4ä¸Claude 2.1åˆ†åˆ«å®ç°32Kå’Œ200K tokensä¸Šä¸‹æ–‡çª—å£ã€‚2024å¹´ï¼ŒDeepSeekå‘å¸ƒDeepSeek-R1ï¼Œæ”¯æŒ128K tokensï¼Œå¹¶å¼•å…¥â€œä¸Šä¸‹æ–‡å‹ç¼©â€æŠ€æœ¯ï¼Œå¯å°†é•¿æ–‡æ¡£å‹ç¼©è‡³åŸé•¿çš„20%-30%ï¼Œä¿ç•™95%ä»¥ä¸Šæ ¸å¿ƒä¿¡æ¯ã€‚å…¶æŠ€æœ¯åˆ›æ–°åŒ…æ‹¬åˆ†å±‚æ€»ç»“æ¶æ„ã€è¯­ä¹‰å¯†åº¦ä¼˜åŒ–åŠè‡ªé€‚åº”å‹ç¼©ç‡ã€‚æµ‹è¯•ä¸­ï¼Œ10,000å­—è®ºæ–‡å‹ç¼©è‡³1,500å­—ï¼Œä»»åŠ¡è´¨é‡ä»…ä¸‹é™2%ï¼ŒTokenä½¿ç”¨é‡å‡å°‘82%ã€‚è¯¥æŠ€æœ¯é€‚ç”¨äºæ³•å¾‹ã€é‡‘èã€å­¦æœ¯åŠå®¢æœç­‰é¢†åŸŸï¼Œæœªæ¥å°†æ¢ç´¢åŠ¨æ€ä¸Šä¸‹æ–‡å‹ç¼©ä»¥æå‡é•¿æœŸè®°å¿†ç®¡ç†èƒ½åŠ›ã€‚\\n\\né—®é¢˜: DeepSeek-R1åœ¨æ–‡æœ¬å‹ç¼©æ–¹é¢æœ‰å“ªäº›æŠ€æœ¯åˆ›æ–°ï¼Ÿå‹ç¼©æ•ˆæœå¦‚ä½•ï¼Ÿ', additional_kwargs={}, response_metadata={})]}}\n",
      "---\n",
      "\n",
      "--- ANSWERING WITH COMPRESSED TEXT ---\n",
      "ğŸ’¡ ç”Ÿæˆçš„å›ç­”: DeepSeek-R1åœ¨æ–‡æœ¬å‹ç¼©æ–¹é¢çš„ä¸»è¦æŠ€æœ¯åˆ›æ–°åŒ…æ‹¬ï¼š\n",
      "\n",
      "1. **åˆ†å±‚æ€»ç»“æ¶æ„**ï¼šé€šè¿‡å¤šå±‚çº§çš„æ‘˜è¦æœºåˆ¶ï¼Œå¯¹æ–‡æœ¬å†…å®¹è¿›è¡Œç»“æ„åŒ–æç‚¼ï¼Œç¡®ä¿å…³é”®ä¿¡æ¯ä¸ä¸¢å¤±ã€‚\n",
      "2. **è¯­ä¹‰å¯†åº¦ä¼˜åŒ–**ï¼šæå‡å‹ç¼©è¿‡ç¨‹ä¸­å¯¹è¯­ä¹‰ä¿¡æ¯çš„ä¿ç•™èƒ½åŠ›ï¼Œä½¿å‹ç¼©åçš„æ–‡æœ¬ä»èƒ½ä¼ è¾¾åŸæ„ã€‚\n",
      "3. **è‡ªé€‚åº”å‹ç¼©ç‡**ï¼šæ ¹æ®æ–‡æœ¬å†…å®¹åŠ¨æ€è°ƒæ•´å‹ç¼©æ¯”ä¾‹ï¼Œå®ç°æ›´çµæ´»ã€é«˜æ•ˆçš„å‹ç¼©æ•ˆæœã€‚\n",
      "\n",
      "**å‹ç¼©æ•ˆæœ**æ–¹é¢ï¼ŒDeepSeek-R1èƒ½å¤Ÿå°†é•¿æ–‡æ¡£å‹...\n",
      "{'answer': {'messages': [AIMessage(content='DeepSeek-R1åœ¨æ–‡æœ¬å‹ç¼©æ–¹é¢çš„ä¸»è¦æŠ€æœ¯åˆ›æ–°åŒ…æ‹¬ï¼š\\n\\n1. **åˆ†å±‚æ€»ç»“æ¶æ„**ï¼šé€šè¿‡å¤šå±‚çº§çš„æ‘˜è¦æœºåˆ¶ï¼Œå¯¹æ–‡æœ¬å†…å®¹è¿›è¡Œç»“æ„åŒ–æç‚¼ï¼Œç¡®ä¿å…³é”®ä¿¡æ¯ä¸ä¸¢å¤±ã€‚\\n2. **è¯­ä¹‰å¯†åº¦ä¼˜åŒ–**ï¼šæå‡å‹ç¼©è¿‡ç¨‹ä¸­å¯¹è¯­ä¹‰ä¿¡æ¯çš„ä¿ç•™èƒ½åŠ›ï¼Œä½¿å‹ç¼©åçš„æ–‡æœ¬ä»èƒ½ä¼ è¾¾åŸæ„ã€‚\\n3. **è‡ªé€‚åº”å‹ç¼©ç‡**ï¼šæ ¹æ®æ–‡æœ¬å†…å®¹åŠ¨æ€è°ƒæ•´å‹ç¼©æ¯”ä¾‹ï¼Œå®ç°æ›´çµæ´»ã€é«˜æ•ˆçš„å‹ç¼©æ•ˆæœã€‚\\n\\n**å‹ç¼©æ•ˆæœ**æ–¹é¢ï¼ŒDeepSeek-R1èƒ½å¤Ÿå°†é•¿æ–‡æ¡£å‹ç¼©è‡³åŸé•¿åº¦çš„20%-30%ï¼ŒåŒæ—¶ä¿ç•™95%ä»¥ä¸Šçš„æ ¸å¿ƒä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œåœ¨æµ‹è¯•ä¸­ï¼Œ10,000å­—çš„è®ºæ–‡è¢«å‹ç¼©è‡³1,500å­—ï¼Œä»»åŠ¡è´¨é‡ä»…ä¸‹é™2%ï¼Œè€ŒTokenä½¿ç”¨é‡å‡å°‘äº†82%ã€‚è¿™è¡¨æ˜å…¶åœ¨ä¿æŒä¿¡æ¯å®Œæ•´æ€§çš„åŒæ—¶æ˜¾è‘—é™ä½äº†è®¡ç®—å’Œå­˜å‚¨æˆæœ¬ã€‚', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-30b-a3b'}, id='run--076fdcd4-d5c4-45a8-b187-706148a6a2fc-0', usage_metadata={'input_tokens': 222, 'output_tokens': 185, 'total_tokens': 407, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# --- 5. æ¼”ç¤ºæ€»ç»“å‹ç¼© ---\n",
    "print(\"\\n### æ¼”ç¤º'æ€»ç»“å‹ç¼©'æŠ€æœ¯ ###\")\n",
    "question = \"DeepSeek-R1åœ¨æ–‡æœ¬å‹ç¼©æ–¹é¢æœ‰å“ªäº›æŠ€æœ¯åˆ›æ–°ï¼Ÿå‹ç¼©æ•ˆæœå¦‚ä½•ï¼Ÿ\"\n",
    "\n",
    "# åˆå§‹çŠ¶æ€\n",
    "initial_state = CompressState(\n",
    "    messages=[SystemMessage(content=\"ä½ æ˜¯ä¸€ä¸ªAIæŠ€æœ¯åˆ†æå¸ˆ\"), HumanMessage(content=question)],\n",
    "    original_text=long_article,\n",
    "    compressed_text=\"\",\n",
    "    token_savings=0\n",
    ")\n",
    "\n",
    "# æ‰§è¡Œå·¥ä½œæµ\n",
    "for step in compress_workflow.stream(initial_state):\n",
    "    if \"__end__\" not in step:\n",
    "        print(step)\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77dc2c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### æ¼”ç¤º'è£å‰ªå‹ç¼©'æŠ€æœ¯ ###\n",
      "\n",
      "--- TRIMMING CONTEXT ---\n",
      "âœ‚ï¸ è£å‰ªå†å²: 10æ¡ â†’ 4æ¡æ¶ˆæ¯\n",
      "ğŸ“‰ TokenèŠ‚çœ: 92 (åŸå§‹: 150 -> è£å‰ªå: 58)\n",
      "\n",
      "è£å‰ªå‰æ¶ˆæ¯:\n",
      "ğŸ¤– ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—…è¡ŒåŠ©æ‰‹\n",
      "ğŸ‘¤ æˆ‘æƒ³è®¡åˆ’ä¸€æ¬¡å»æ—¥æœ¬çš„æ—…è¡Œ\n",
      "ğŸ‘¤ æ—¶é—´å¤§æ¦‚æ˜¯æ˜å¹´3æœˆä¸‹æ—¬ï¼Œ10å¤©å·¦å³\n",
      "ğŸ‘¤ æˆ‘å¯¹äº¬éƒ½çš„æ–‡åŒ–æ™¯ç‚¹ç‰¹åˆ«æ„Ÿå…´è¶£\n",
      "ğŸ‘¤ å¦å¤–ä¹Ÿæƒ³ä½“éªŒä¸€ä¸‹ä¸œäº¬çš„ç°ä»£åŒ–éƒ½å¸‚\n",
      "ğŸ‘¤ é¢„ç®—æ–¹é¢å¸Œæœ›æ§åˆ¶åœ¨2ä¸‡å…ƒä»¥å†…\n",
      "ğŸ‘¤ è¯·å¸®æˆ‘è§„åˆ’ä¸€ä¸ªè¡Œç¨‹\n",
      "ğŸ‘¤ å¯¹äº†ï¼Œæˆ‘è¿˜æƒ³ä½“éªŒä¸€æ¬¡æ¸©æ³‰æ—…é¦†\n",
      "ğŸ‘¤ æœ€å¥½æ˜¯é‚£ç§ä¼ ç»Ÿçš„æ—¥å¼æ—…é¦†\n",
      "ğŸ‘¤ ç°åœ¨è¯·ç»™æˆ‘å…·ä½“çš„è¡Œç¨‹å»ºè®®\n",
      "\n",
      "è£å‰ªåæ¶ˆæ¯:\n",
      "ğŸ¤– ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—…è¡ŒåŠ©æ‰‹\n",
      "ğŸ‘¤ å¯¹äº†ï¼Œæˆ‘è¿˜æƒ³ä½“éªŒä¸€æ¬¡æ¸©æ³‰æ—…é¦†\n",
      "ğŸ‘¤ æœ€å¥½æ˜¯é‚£ç§ä¼ ç»Ÿçš„æ—¥å¼æ—…é¦†\n",
      "ğŸ‘¤ ç°åœ¨è¯·ç»™æˆ‘å…·ä½“çš„è¡Œç¨‹å»ºè®®\n"
     ]
    }
   ],
   "source": [
    "# --- 6. æ¼”ç¤ºå¯¹è¯å†å²è£å‰ª ---\n",
    "print(\"\\n### æ¼”ç¤º'è£å‰ªå‹ç¼©'æŠ€æœ¯ ###\")\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªé•¿å¯¹è¯å†å²\n",
    "long_chat_history = [\n",
    "    SystemMessage(content=\"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—…è¡ŒåŠ©æ‰‹\"),\n",
    "    HumanMessage(content=\"æˆ‘æƒ³è®¡åˆ’ä¸€æ¬¡å»æ—¥æœ¬çš„æ—…è¡Œ\"),\n",
    "    HumanMessage(content=\"æ—¶é—´å¤§æ¦‚æ˜¯æ˜å¹´3æœˆä¸‹æ—¬ï¼Œ10å¤©å·¦å³\"),\n",
    "    HumanMessage(content=\"æˆ‘å¯¹äº¬éƒ½çš„æ–‡åŒ–æ™¯ç‚¹ç‰¹åˆ«æ„Ÿå…´è¶£\"),\n",
    "    HumanMessage(content=\"å¦å¤–ä¹Ÿæƒ³ä½“éªŒä¸€ä¸‹ä¸œäº¬çš„ç°ä»£åŒ–éƒ½å¸‚\"),\n",
    "    HumanMessage(content=\"é¢„ç®—æ–¹é¢å¸Œæœ›æ§åˆ¶åœ¨2ä¸‡å…ƒä»¥å†…\"),\n",
    "    HumanMessage(content=\"è¯·å¸®æˆ‘è§„åˆ’ä¸€ä¸ªè¡Œç¨‹\"),\n",
    "    HumanMessage(content=\"å¯¹äº†ï¼Œæˆ‘è¿˜æƒ³ä½“éªŒä¸€æ¬¡æ¸©æ³‰æ—…é¦†\"),\n",
    "    HumanMessage(content=\"æœ€å¥½æ˜¯é‚£ç§ä¼ ç»Ÿçš„æ—¥å¼æ—…é¦†\"),\n",
    "    HumanMessage(content=\"ç°åœ¨è¯·ç»™æˆ‘å…·ä½“çš„è¡Œç¨‹å»ºè®®\")\n",
    "]\n",
    "\n",
    "# åˆå§‹çŠ¶æ€ï¼ˆæ— æ–‡æœ¬å‹ç¼©ï¼‰\n",
    "trim_demo_state = CompressState(\n",
    "    messages=long_chat_history,\n",
    "    original_text=\"\",\n",
    "    compressed_text=\"\",\n",
    "    token_savings=0\n",
    ")\n",
    "\n",
    "# æ‰§è¡Œè£å‰ª\n",
    "trimmed_state = trim_context(trim_demo_state)\n",
    "\n",
    "# æ˜¾ç¤ºè£å‰ªæ•ˆæœ\n",
    "print(\"\\nè£å‰ªå‰æ¶ˆæ¯:\")\n",
    "for i, msg in enumerate(long_chat_history):\n",
    "    prefix = \"ğŸ¤–\" if isinstance(msg, SystemMessage) else \"ğŸ‘¤\"\n",
    "    print(f\"{prefix} {msg.content[:50]}{'...' if len(msg.content) > 50 else ''}\")\n",
    "\n",
    "print(\"\\nè£å‰ªåæ¶ˆæ¯:\")\n",
    "for i, msg in enumerate(trimmed_state['messages']):\n",
    "    prefix = \"ğŸ¤–\" if isinstance(msg, SystemMessage) else \"ğŸ‘¤\"\n",
    "    print(f\"{prefix} {msg.content[:50]}{'...' if len(msg.content) > 50 else ''}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa94b02",
   "metadata": {},
   "source": [
    "## **ç­–ç•¥å››ï¼šéš”ç¦» (Isolate) - \"åˆ†è€Œæ²»ä¹‹\"çš„æ¶æ„æ™ºæ…§**\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³ï¼š** å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼Œç”±ä¸“é—¨çš„æ™ºèƒ½ä½“åœ¨éš”ç¦»ç¯å¢ƒä¸­å¤„ç†ï¼Œé¿å…ä¸Šä¸‹æ–‡æ±¡æŸ“ã€‚\n",
    "\n",
    "**å®ç°å¤šæ™ºèƒ½ä½“æ¶æ„ï¼š** åˆ›å»ºä¸“å®¶æ™ºèƒ½ä½“å›¢é˜Ÿï¼ˆåˆ†æå¸ˆ+æ–‡æ¡ˆï¼‰\n",
    "\n",
    "**åœºæ™¯æ¼”ç¤ºï¼š** ç”¨æˆ·ä¸Šä¼ é”€å”®æ•°æ®CSVï¼Œè¦æ±‚åˆ†æé”€å”®å† å†›å¹¶æ’°å†™è¥é”€æ–‡æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca6ab70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. å‡†å¤‡æ•°æ® ---\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# åˆ›å»ºç¤ºä¾‹é”€å”®æ•°æ®CSV\n",
    "sales_data = \"\"\"\n",
    "æ—¥æœŸ,äº§å“,é”€å”®é¢,é”€å”®é‡\n",
    "2024-01-01,æœºæ¢°é”®ç›˜,12800,32\n",
    "2024-01-01,æ¸¸æˆé¼ æ ‡,9800,49\n",
    "2024-01-02,æœºæ¢°é”®ç›˜,14500,36\n",
    "2024-01-02,æ¸¸æˆé¼ æ ‡,10200,51\n",
    "2024-01-03,æœºæ¢°é”®ç›˜,16200,40\n",
    "2024-01-03,æ¸¸æˆé¼ æ ‡,10800,54\n",
    "2024-01-04,æœºæ¢°é”®ç›˜,13800,34\n",
    "2024-01-04,æ¸¸æˆé¼ æ ‡,11200,56\n",
    "2024-01-05,æœºæ¢°é”®ç›˜,17500,42\n",
    "2024-01-05,æ¸¸æˆé¼ æ ‡,11800,59\n",
    "\"\"\"\n",
    "\n",
    "# ä¿å­˜ä¸ºCSVæ–‡ä»¶\n",
    "with open(\"sales_data.csv\", \"w\") as f:\n",
    "    f.write(sales_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bcf219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. å®šä¹‰çŠ¶æ€ ---\n",
    "# å®šä¹‰å¤šæ™ºèƒ½ä½“åä½œçš„çŠ¶æ€\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    task: str\n",
    "    analysis_result: str\n",
    "    final_output: str\n",
    "    next_agent: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22cb0128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. å®šä¹‰å·¥å…· ---\n",
    "@tool\n",
    "def analyze_sales_data(question: str) -> str:\n",
    "    \"\"\"\n",
    "    åˆ†æé”€å”®æ•°æ®CSVæ–‡ä»¶ï¼Œæ‰¾å‡ºé”€å”®é¢æœ€é«˜çš„äº§å“åŠå…¶é”€å”®æ€»é¢ã€‚\n",
    "    å‚æ•°:\n",
    "        question (str): ç”¨æˆ·çš„åŸå§‹é—®é¢˜ï¼Œç”¨äºè®°å½•åˆ†æèƒŒæ™¯ã€‚\n",
    "    è¿”å›:\n",
    "        str: ä¸€ä¸ªé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²ï¼ŒåŒ…å«äº§å“åç§°å’Œæ€»é”€å”®é¢ï¼Œä¾‹å¦‚ \"äº§å“A,150000\"ã€‚\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- TOOL: ANALYZE SALES DATA ---\")\n",
    "    print(f\"ğŸ“ åˆ†æä»»åŠ¡: {question}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(\"sales_data.csv\")\n",
    "        product_sales = df.groupby(\"äº§å“\")[\"é”€å”®é¢\"].sum()\n",
    "        top_product = product_sales.idxmax()\n",
    "        top_sales = product_sales.max()\n",
    "        result = f\"{top_product},{top_sales}\"\n",
    "        print(f\"ğŸ† åˆ†æç»“æœ: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"åˆ†æå¤±è´¥: {e}\"\n",
    "\n",
    "@tool\n",
    "def write_marketing_copy(product: str, key_points: str) -> str:\n",
    "    \"\"\"\n",
    "    ä¸ºæŒ‡å®šäº§å“æ’°å†™è¥é”€æ–‡æ¡ˆã€‚\n",
    "    å‚æ•°:\n",
    "        product (str): éœ€è¦æ’°å†™æ–‡æ¡ˆçš„äº§å“åç§°ã€‚\n",
    "        key_points (str): æ–‡æ¡ˆéœ€è¦å›´ç»•çš„æ ¸å¿ƒå–ç‚¹ã€‚\n",
    "    è¿”å›:\n",
    "        str: ç”Ÿæˆçš„è¥é”€æ–‡æ¡ˆã€‚\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- TOOL: WRITE MARKETING COPY ---\")\n",
    "    print(f\"ğŸ“ æ’°å†™æ–‡æ¡ˆ: {product} - {key_points[:50]}...\")\n",
    "    \n",
    "    writer_prompt = ChatPromptTemplate.from_template(\n",
    "        \"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šè¥é”€æ–‡æ¡ˆã€‚è¯·åŸºäºä»¥ä¸‹äº§å“ä¿¡æ¯æ’°å†™ä¸€ç¯‡ä¸è¶…è¿‡150å­—çš„å¸å¼•äººçš„è¥é”€æ–‡æ¡ˆ:\\n\"\n",
    "        \"äº§å“åç§°: {product}\\n\"\n",
    "        \"æ ¸å¿ƒå–ç‚¹: {key_points}\\n\"\n",
    "        \"æ–‡æ¡ˆ:\"\n",
    "    )\n",
    "    writer_chain = writer_prompt | model | StrOutputParser()\n",
    "    \n",
    "    return writer_chain.invoke({\"product\": product, \"key_points\": key_points})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd1b3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. åˆ›å»ºæ™ºèƒ½ä½“ ---\n",
    "\n",
    "# Helper function to create a specialist agent\n",
    "def create_agent(system_prompt: str, tools: list):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ])\n",
    "    agent = prompt | model.bind_tools(tools)\n",
    "    return agent\n",
    "\n",
    "# åˆ†æå¸ˆæ™ºèƒ½ä½“\n",
    "analyst_agent = create_agent(\n",
    "    \"ä½ æ˜¯ä¸€åä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç»™å®šçš„æ•°æ®å¹¶è¿”å›å…³é”®ç»“æœã€‚è¯·ä½¿ç”¨`analyze_sales_data`å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚\",\n",
    "    [analyze_sales_data]\n",
    ")\n",
    "\n",
    "# æ–‡æ¡ˆæ™ºèƒ½ä½“\n",
    "writer_agent = create_agent(\n",
    "    \"ä½ æ˜¯ä¸€åä¸“ä¸šçš„è¥é”€æ–‡æ¡ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®åˆ†æç»“æœï¼Œä¸ºäº§å“æ’°å†™å¼•äººæ³¨ç›®çš„è¥é”€æ–‡æ¡ˆã€‚è¯·ä½¿ç”¨`write_marketing_copy`å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚\",\n",
    "    [write_marketing_copy]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5334c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. å®šä¹‰æ™ºèƒ½ä½“èŠ‚ç‚¹ ---\n",
    "\n",
    "def analyst_node(state: AgentState):\n",
    "    print(\"\\n--- CALLING ANALYST AGENT ---\")\n",
    "    result = analyst_agent.invoke({\"messages\": [HumanMessage(content=state['task'])]})\n",
    "    return {\"messages\": [result]}\n",
    "\n",
    "def writer_node(state: AgentState):\n",
    "    print(\"\\n--- CALLING WRITER AGENT ---\")\n",
    "    # ä»stateä¸­æå–åˆ†æç»“æœï¼Œå¹¶ä½œä¸ºè¾“å…¥ä¼ é€’ç»™æ–‡æ¡ˆæ™ºèƒ½ä½“\n",
    "    product, sales = state['analysis_result'].split(',')\n",
    "    prompt = f\"åˆ†æç»“æœï¼šé”€å”®å† å†›æ˜¯â€˜{product}â€™ï¼Œæ€»é”€å”®é¢ä¸º {sales} å…ƒã€‚è¯·ä¸ºæ­¤äº§å“æ’°å†™è¥é”€æ–‡æ¡ˆã€‚\"\n",
    "    result = writer_agent.invoke({\"messages\": [HumanMessage(content=prompt)]})\n",
    "    return {\"messages\": [result]}\n",
    "\n",
    "# å®šä¹‰å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹\n",
    "tool_node = ToolNode([analyze_sales_data, write_marketing_copy])\n",
    "\n",
    "def execute_tools(state: AgentState):\n",
    "    print(\"\\n--- EXECUTING TOOLS ---\")\n",
    "    last_message = state['messages'][-1]\n",
    "    tool_call = last_message.tool_calls[0]\n",
    "    \n",
    "    # æ‰§è¡Œå·¥å…·\n",
    "    tool_result = tool_node.invoke([last_message])\n",
    "    \n",
    "    # æ ¹æ®å·¥å…·æ›´æ–°çŠ¶æ€\n",
    "    if tool_call['name'] == 'analyze_sales_data':\n",
    "        return {\"messages\": tool_result, \"analysis_result\": tool_result[0].content}\n",
    "    elif tool_call['name'] == 'write_marketing_copy':\n",
    "        return {\"messages\": tool_result, \"final_output\": tool_result[0].content}\n",
    "    \n",
    "    return {\"messages\": tool_result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea160988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. æ„å»ºå›¾ (Supervisoræ¨¡å¼) ---\n",
    "\n",
    "def supervisor_router(state: AgentState):\n",
    "    \"\"\"è·¯ç”±ï¼šå†³å®šä¸‹ä¸€ä¸ªåº”è¯¥ç”±å“ªä¸ªæ™ºèƒ½ä½“æ¥å¤„ç†\"\"\"\n",
    "    print(\"\\n--- SUPERVISOR ---\")\n",
    "\n",
    "    # å¦‚æœåˆ†æç»“æœè¿˜æœªäº§ç”Ÿï¼Œåˆ™åˆ†é…ç»™åˆ†æå¸ˆ\n",
    "    if not state.get(\"analysis_result\"):\n",
    "        print(\"ğŸ“‹ ä»»åŠ¡åˆ†é…: åˆ†æå¸ˆ (Analyst)\")\n",
    "        return \"analyst\"\n",
    "        \n",
    "    # å¦‚æœåˆ†æå·²å®Œæˆä½†æ–‡æ¡ˆè¿˜æœªæ’°å†™ï¼Œåˆ™åˆ†é…ç»™æ–‡æ¡ˆ\n",
    "    if state.get(\"analysis_result\") and not state.get(\"final_output\"):\n",
    "        print(\"ğŸ“‹ ä»»åŠ¡åˆ†é…: æ–‡æ¡ˆæ’°å†™ (Writer)\")\n",
    "        return \"writer\"\n",
    "        \n",
    "    # å¦‚æœä¸€åˆ‡éƒ½å®Œæˆäº†\n",
    "    print(\"âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆ\")\n",
    "    return END\n",
    "\n",
    "# æ„å»ºå›¾\n",
    "isolate_graph = StateGraph(AgentState)\n",
    "\n",
    "isolate_graph.add_node(\"analyst\", analyst_node)\n",
    "isolate_graph.add_node(\"writer\", writer_node)\n",
    "isolate_graph.add_node(\"execute_tools\", execute_tools)\n",
    "\n",
    "# è®¾ç½®å…¥å£ç‚¹\n",
    "isolate_graph.set_entry_point(\"analyst\")\n",
    "\n",
    "# å®šä¹‰å›¾çš„è¾¹\n",
    "isolate_graph.add_edge(\"analyst\", \"execute_tools\")\n",
    "isolate_graph.add_edge(\"writer\", \"execute_tools\")\n",
    "isolate_graph.add_conditional_edges(\n",
    "    \"execute_tools\",\n",
    "    supervisor_router,\n",
    "    {\"analyst\": \"analyst\", \"writer\": \"writer\", END: END}\n",
    ")\n",
    "\n",
    "# ç¼–è¯‘å·¥ä½œæµ\n",
    "isolate_workflow = isolate_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e0bce9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### æ¼”ç¤ºå¤šæ™ºèƒ½ä½“åä½œ (Supervisoræ¨¡å¼) ###\n",
      "\n",
      "--- CALLING ANALYST AGENT ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [analyst] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- EXECUTING TOOLS ---\n",
      "\n",
      "--- TOOL: ANALYZE SALES DATA ---\n",
      "ğŸ“ åˆ†æä»»åŠ¡: åˆ†æé”€å”®æ•°æ®æ‰¾å‡ºé”€å”®é¢æœ€é«˜çš„äº§å“ï¼Œç„¶åä¸ºè¯¥äº§å“æ’°å†™ä¸€ç¯‡å¸å¼•äººçš„è¥é”€æ–‡æ¡ˆã€‚\n",
      "ğŸ† åˆ†æç»“æœ: æœºæ¢°é”®ç›˜,74800\n",
      "\n",
      "--- SUPERVISOR ---\n",
      "ğŸ“‹ ä»»åŠ¡åˆ†é…: æ–‡æ¡ˆæ’°å†™ (Writer)\n",
      "--- [execute_tools] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- CALLING WRITER AGENT ---\n",
      "--- [writer] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "--- EXECUTING TOOLS ---\n",
      "\n",
      "--- TOOL: WRITE MARKETING COPY ---\n",
      "ğŸ“ æ’°å†™æ–‡æ¡ˆ: æœºæ¢°é”®ç›˜ - é”€å”®å† å†›ï¼Œæ€»é”€å”®é¢ä¸º 74800 å…ƒ...\n",
      "\n",
      "--- SUPERVISOR ---\n",
      "âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆ\n",
      "--- [execute_tools] æ­¥éª¤å®Œæˆ ---\n",
      "\n",
      "ğŸ‰ æœ€ç»ˆæ–‡æ¡ˆ:\n",
      "é”€é‡å† å†›ï¼Œå£ç¢‘ä¹‹é€‰ï¼è¿™æ¬¾æœºæ¢°é”®ç›˜å‡­å€Ÿå“è¶Šæ€§èƒ½ä¸å‡ºè‰²æ‰‹æ„Ÿï¼Œçƒ­é”€è‡³ä»Šï¼Œæ€»é”€å”®é¢çªç ´74800å…ƒã€‚æ— è®ºæ˜¯æ¸¸æˆè¿˜æ˜¯åŠå…¬ï¼Œéƒ½èƒ½å¸¦æ¥ç•…å¿«ä½“éªŒï¼Œæ˜¯æ¯ä¸€ä½é”®ç›˜æ§çš„ä¸äºŒä¹‹é€‰ï¼\n"
     ]
    }
   ],
   "source": [
    "# --- 7. æ‰§è¡Œå¤šæ™ºèƒ½ä½“åä½œ ---\n",
    "print(\"\\n### æ¼”ç¤ºå¤šæ™ºèƒ½ä½“åä½œ (Supervisoræ¨¡å¼) ###\")\n",
    "task = (\n",
    "    \"åˆ†æé”€å”®æ•°æ®æ‰¾å‡ºé”€å”®é¢æœ€é«˜çš„äº§å“ï¼Œ\"\n",
    "    \"ç„¶åä¸ºè¯¥äº§å“æ’°å†™ä¸€ç¯‡å¸å¼•äººçš„è¥é”€æ–‡æ¡ˆã€‚\"\n",
    ")\n",
    "initial_state = AgentState(\n",
    "    messages=[],\n",
    "    task=task,\n",
    "    analysis_result=\"\",\n",
    "    final_output=\"\",\n",
    "    next_agent=\"analyst\"\n",
    ")\n",
    "\n",
    "# æ‰§è¡Œå·¥ä½œæµ\n",
    "for step in isolate_workflow.stream(initial_state, {\"recursion_limit\": 10}):\n",
    "    node = list(step.keys())[0]\n",
    "    state = step[node]\n",
    "    print(f\"--- [{node}] æ­¥éª¤å®Œæˆ ---\")\n",
    "    if \"final_output\" in state and state[\"final_output\"]:\n",
    "        print(f\"\\nğŸ‰ æœ€ç»ˆæ–‡æ¡ˆ:\\n{state['final_output']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
